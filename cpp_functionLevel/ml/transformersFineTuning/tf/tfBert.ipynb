{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e260120",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a7b4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import json, os\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import OrderedDict, defaultdict\n",
    "import time\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool1D\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification #, BertModel, BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import set_seed\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, \\\n",
    "roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906322c",
   "metadata": {},
   "source": [
    "Specify a constant seeder for processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663f78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400c5c2",
   "metadata": {},
   "source": [
    "Pre-trained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7aa5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variation = \"microsoft/codebert-base-mlm\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_variation, do_lower_case=True) #Tokenizer\n",
    "#bert-base-uncased #bert-base # roberta-base # distilbert-base-uncased #distilbert-base # microsoft/codebert-base-mlm\n",
    "# 'albert-base-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffcb9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define New tokens for string and numerical i.e., strId$ and numId$\n",
    "new_tokens = [\"strId$\", \"numId$\"]\n",
    "for new_token in new_tokens:\n",
    "    if new_token not in tokenizer.get_vocab().keys():\n",
    "        tokenizer.add_tokens(new_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9b166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f1 = 2*((prec*rec)/(prec+rec+K.epsilon()))\n",
    "    return f1\n",
    "\n",
    "def f2_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f2 = 5*((prec*rec)/(4*prec+rec+K.epsilon()))\n",
    "    return f2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c9fbd4",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "302c466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join('..', '..', '..')\n",
    "data = pd.read_csv(os.path.join(root_path, 'data', 'dataset.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56976661",
   "metadata": {},
   "source": [
    "Shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "654d03e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename  vul  \\\n",
      "0                                          uspses.py    0   \n",
      "1                  _src_modules_json_schemas_2564.py    1   \n",
      "2                                   cs_zone_facts.py    0   \n",
      "3  _invenio_modules_oauthclient_views_client_2636.py    1   \n",
      "4                                   test_builtins.py    0   \n",
      "\n",
      "                                                func  \n",
      "0  strId$ Copyright c numId$ numId$ sqlmap develo...  \n",
      "1  strId$ strId$ strId$ strId$ strId$ strId$ strI...  \n",
      "2  ANSIBLE_METADATA strId$ strId$ strId$ strId$ s...  \n",
      "3  strId$ strId$ strId$ make_handler disconnect_h...  \n",
      "4  class SimpleTestCase @setup strId$ strId$ def ...  \n",
      "4184\n"
     ]
    }
   ],
   "source": [
    "data = data.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "print(data.head())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac048926",
   "metadata": {},
   "source": [
    "Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9efebf6d-714e-4173-bd99-022cac3c47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=[\"func\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac7f783f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of words: 510\n"
     ]
    }
   ],
   "source": [
    "word_counts = data[\"func\"].apply(lambda x: len(x.split()))\n",
    "max_length = word_counts.max()\n",
    "print(\"Maximum number of words:\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aaeb669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vul\n",
      "0    3168\n",
      "1     997\n",
      "Name: count, dtype: int64\n",
      "Percentage:  31.470959595959595 %\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "vc = data[\"vul\"].value_counts()\n",
    "\n",
    "print(vc)\n",
    "\n",
    "print(\"Percentage: \", (vc[1] / vc[0])*100, '%')\n",
    "\n",
    "n_categories = len(vc)\n",
    "print(n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f80abd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strId$ Copyright c numId$ numId$ sqlmap develo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strId$ strId$ strId$ strId$ strId$ strId$ strI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANSIBLE_METADATA strId$ strId$ strId$ strId$ s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strId$ strId$ strId$ make_handler disconnect_h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class SimpleTestCase @setup strId$ strId$ def ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Labels\n",
       "0  strId$ Copyright c numId$ numId$ sqlmap develo...       0\n",
       "1  strId$ strId$ strId$ strId$ strId$ strId$ strI...       1\n",
       "2  ANSIBLE_METADATA strId$ strId$ strId$ strId$ s...       0\n",
       "3  strId$ strId$ strId$ make_handler disconnect_h...       1\n",
       "4  class SimpleTestCase @setup strId$ strId$ def ...       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(({'Text': data['func'], 'Labels': data['vul']}))\n",
    "#data = data[0:100]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b71280",
   "metadata": {},
   "source": [
    "Split to train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a08c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ac30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_seeders = [seed, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "shuffle_seeder = shuffle_seeders[0]\n",
    "\n",
    "train_val_data, test_data = train_test_split(data, test_size=val_ratio, random_state=shuffle_seeder, stratify=data['Labels'])\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=val_ratio, random_state=shuffle_seeder, stratify=train_val_data['Labels'])\n",
    "# print(len(data))\n",
    "# print(len(train_val_data))\n",
    "# print(len(test_data))\n",
    "# print(len(train_data))\n",
    "# print(len(val_data))\n",
    "# print(len(val_data)+len(train_data)+len(test_data))\n",
    "# print(len(val_data)+len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb67fb",
   "metadata": {},
   "source": [
    "Pre-processing step: Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce7014ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = True\n",
    "if n_categories == 2 and sampling == True:\n",
    "    # Apply under-sampling with the specified strategy\n",
    "    class_counts = pd.Series(train_data[\"Labels\"]).value_counts()\n",
    "    print(\"Class distribution \", class_counts)\n",
    "\n",
    "    majority_class = class_counts.idxmax()\n",
    "    print(\"Majority class \", majority_class)\n",
    "\n",
    "    minority_class = class_counts.idxmin()\n",
    "    print(\"Minority class \", minority_class)\n",
    "\n",
    "    target_count = 2 * class_counts[class_counts.idxmin()] # class_counts[class_counts.idxmin()] # int(class_counts.iloc[0] / 2)  \n",
    "    print(\"Targeted number of majority class\", target_count)\n",
    "\n",
    "    # under\n",
    "    sampling_strategy = {majority_class: target_count}        \n",
    "    rus = RandomUnderSampler(random_state=seed, sampling_strategy=sampling_strategy)\n",
    "\n",
    "    x_train_resampled, y_train_resampled = rus.fit_resample(np.array(train_data[\"Text\"]).reshape(-1, 1), train_data[\"Labels\"]) \n",
    "    print(\"Class distribution after augmentation\", pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "\n",
    "    # Shuffle the resampled data while preserving the correspondence between features and labels\n",
    "    x_train_resampled, y_train_resampled = shuffle(x_train_resampled, y_train_resampled, random_state=seed)\n",
    "\n",
    "    # rename\n",
    "    X_train = x_train_resampled\n",
    "    Y_train = y_train_resampled\n",
    "\n",
    "    X_train = pd.Series(X_train.reshape(-1))\n",
    "\n",
    "else:\n",
    "    X_train = train_data[\"Text\"]\n",
    "    Y_train = train_data[\"Labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a2fe8",
   "metadata": {},
   "source": [
    "Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af1a5dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base-mlm and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['RobertaForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/codebert-base-mlm', 'transformers_version': '4.37.2', 'model_type': 'roberta', 'output_past': True, 'vocab_size': 50265, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'type_vocab_size': 1, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'position_embedding_type': 'absolute', 'use_cache': True, 'classifier_dropout': None}\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_variation, num_labels=n_categories)\n",
    "\n",
    "config = model.get_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5f9eb",
   "metadata": {},
   "source": [
    "Resize model embedding to match new tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb3719d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.roberta.modeling_tf_roberta.TFRobertaEmbeddings at 0x25f9537be20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984c67f",
   "metadata": {},
   "source": [
    "Decide which pre-trained layers to freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef8fd2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb98e5a",
   "metadata": {},
   "source": [
    "Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f23d6181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_roberta_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " roberta (TFRobertaMainLayer  multiple                 124056576 \n",
      " )                                                               \n",
      "                                                                 \n",
      " classifier (TFRobertaClassi  multiple                 592130    \n",
      " ficationHead)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,648,706\n",
      "Trainable params: 124,648,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cade1df7",
   "metadata": {},
   "source": [
    "Compute maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5a623f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxLen(X):\n",
    "\n",
    "    # Code for identifying max length of the data samples after tokenization using transformer tokenizer\n",
    "    \n",
    "    max_length = 0\n",
    "    # Iterate over each sample in your dataset\n",
    "    for i, input_ids in enumerate(X['input_ids']):\n",
    "        # Calculate the length of the tokenized sequence for the current sample\n",
    "        length = tf.math.reduce_sum(tf.cast(input_ids != 1, tf.int32)).numpy()\n",
    "        # Update max_length and max_row if the current length is greater\n",
    "        if length > max_length:\n",
    "            max_length = length\n",
    "            max_row = i\n",
    "\n",
    "    print(\"Max length of tokenized data:\", max_length)\n",
    "    print(\"Row with max length:\", max_row)\n",
    "\n",
    "    #X['input_ids'] = np.delete(X['input_ids'], max_row, axis=0)\n",
    "    \n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b2b2c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of tokenized data: 512\n",
      "Row with max length: 19\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer(\n",
    "        text=X_train.tolist(),\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors='tf',\n",
    "        return_token_type_ids=False,\n",
    "        return_attention_mask=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "max_len = getMaxLen(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69398f9b",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b48ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(\n",
    "    text=X_train.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_len,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "X_val = tokenizer(\n",
    "    text=val_data['Text'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_len,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "X_test = tokenizer(\n",
    "    text=test_data['Text'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_len,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee16fc9",
   "metadata": {},
   "source": [
    "Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f7663f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 8\n",
    "lr = 5e-05\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49483ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(\n",
    "    learning_rate=lr, # HF recommendation\n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0\n",
    ")\n",
    "\n",
    "loss = CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3c589",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08dd3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[f1_metric]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429732da",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c44e7edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - ETA: 0s - loss: 0.3902 - f1_metric: 0.7088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\best_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\best_weights\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 154s 317ms/step - loss: 0.3902 - f1_metric: 0.7088 - val_loss: 0.2857 - val_f1_metric: 0.8253\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - ETA: 0s - loss: 0.2081 - f1_metric: 0.8857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\best_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\best_weights\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 131s 310ms/step - loss: 0.2081 - f1_metric: 0.8857 - val_loss: 0.2187 - val_f1_metric: 0.8841\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - ETA: 0s - loss: 0.1355 - f1_metric: 0.9323"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 423). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\best_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\best_weights\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 131s 309ms/step - loss: 0.1355 - f1_metric: 0.9323 - val_loss: 0.2493 - val_f1_metric: 0.9019\n",
      "Epoch 4/100\n",
      " 34/422 [=>............................] - ETA: 1:29 - loss: 0.0980 - f1_metric: 0.9592"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1_metric\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39mpatience)\n\u001b[0;32m      5\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints/best_weights\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1_metric\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m milli_sec2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining is completed after\u001b[39m\u001b[38;5;124m\"\u001b[39m, milli_sec2\u001b[38;5;241m-\u001b[39mmilli_sec1)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "milli_sec1 = int(round(time.time() * 1000))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_f1_metric', mode='max', patience=patience)\n",
    "model_checkpoint = ModelCheckpoint('./checkpoints/best_weights', monitor='val_f1_metric', mode='max', save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    x = {'input_ids':X_train['input_ids'], 'attention_mask':X_train['attention_mask']},\n",
    "    y = to_categorical(Y_train),\n",
    "    validation_data = ({'input_ids':X_val['input_ids'], 'attention_mask':X_val['attention_mask']},\n",
    "                        to_categorical(val_data['Labels'])),\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "milli_sec2 = int(round(time.time() * 1000))\n",
    "print(\"Training is completed after\", milli_sec2-milli_sec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a795c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['f1_metric'])\n",
    "plt.plot(history.history['val_f1_metric'])\n",
    "plt.ylabel('model f1_metric')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='best')\n",
    "#plt.savefig('train_history.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b16381",
   "metadata": {},
   "source": [
    "Load best model from checkpoint during training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "856c66f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x25f957f8640>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./checkpoints/best_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e619626",
   "metadata": {},
   "source": [
    "Classification report on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a838fda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 6s 270ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       285\n",
      "           1       0.78      0.87      0.82        90\n",
      "\n",
      "    accuracy                           0.91       375\n",
      "   macro avg       0.87      0.89      0.88       375\n",
      "weighted avg       0.91      0.91      0.91       375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_data['Labels'], np.argmax(model.predict({'input_ids': X_val['input_ids'], 'attention_mask': X_val['attention_mask']}).logits, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d4773f",
   "metadata": {},
   "source": [
    "Make predictions on the testing set and compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f164ddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 4s 257ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       317\n",
      "           1       0.85      0.82      0.84       100\n",
      "\n",
      "    accuracy                           0.92       417\n",
      "   macro avg       0.90      0.89      0.89       417\n",
      "weighted avg       0.92      0.92      0.92       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict({'input_ids': X_test['input_ids'], 'attention_mask': X_test['attention_mask']}).logits\n",
    "y_predicted = np.argmax(predicted, axis=1)\n",
    "\n",
    "targets = test_data['Labels']\n",
    "print(classification_report(targets, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2a8c40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP= 82\n",
      "TN= 303\n",
      "FP= 14\n",
      "FN= 18\n",
      "Accuracy:92.33%\n",
      "Precision:85.42%\n",
      "Recall:82.00%\n",
      "Roc_Auc score:88.79%\n",
      "F1 score:83.67%\n",
      "F2 score:82.66%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy=accuracy_score(targets, y_predicted)\n",
    "precision=precision_score(targets, y_predicted)\n",
    "recall=recall_score(targets, y_predicted)\n",
    "roc_auc=roc_auc_score(targets, y_predicted)\n",
    "f1=f1_score(targets, y_predicted)\n",
    "f2 = (5*precision*recall) / (4*precision+recall)\n",
    "\n",
    "conf_matrix = confusion_matrix(targets, y_predicted)\n",
    "sn.heatmap(conf_matrix, annot=True)\n",
    "\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "acc = ((tp+tn)/(tp+tn+fp+fn))\n",
    "print(\"TP=\",tp)\n",
    "print(\"TN=\",tn)\n",
    "print(\"FP=\",fp)\n",
    "print(\"FN=\",fn)\n",
    "\n",
    "print(\"Accuracy:%.2f%%\"%(accuracy*100))\n",
    "print(\"Precision:%.2f%%\"%(precision*100))\n",
    "print(\"Recall:%.2f%%\"%(recall*100))\n",
    "print(\"Roc_Auc score:%.2f%%\"%(roc_auc*100))\n",
    "print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "print(\"F2 score:%.2f%%\"%(f2*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b7c35c",
   "metadata": {},
   "source": [
    "Export classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c4115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"forSequence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9522a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the path\n",
    "path = os.path.join(root_path, 'results', model_variation.split(\"/\")[-1], method, str(shuffle_seeder))\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = os.path.join(path, f\"{shuffle_seeder}.csv\")\n",
    "\n",
    "# Write data to CSV\n",
    "data = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": f1,\n",
    "    \"f2\": f2,\n",
    "    \"roc_auc\": roc_auc\n",
    "}\n",
    "\n",
    "# Write to CSV\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=data.keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerow(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539bf67e",
   "metadata": {},
   "source": [
    "Compute the average values of the classication metrics considering the results for all different seeders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cfde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to store cumulative sum of metrics\n",
    "cumulative_metrics = defaultdict(float)\n",
    "count = 0  # Counter to keep track of number of CSV files\n",
    "\n",
    "# Iterate over all CSV files in the results folder\n",
    "results_folder = os.path.join(root_path, \"results\", model_variation.split(\"/\")[-1], method, str(shuffle_seeder))\n",
    "for filename in os.listdir(results_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        csv_file_path = os.path.join(results_folder, filename)\n",
    "        with open(csv_file_path, \"r\", newline=\"\") as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                for metric, value in row.items():\n",
    "                    cumulative_metrics[metric] += float(value)\n",
    "        count += 1\n",
    "        \n",
    "# Compute average values\n",
    "average_metrics = {metric: total / count for metric, total in cumulative_metrics.items()}\n",
    "\n",
    "# Print average values \n",
    "print(average_metrics)\n",
    "\n",
    "# Define the path for the average CSV file\n",
    "avg_csv_file_path = os.path.join(root_path, \"results\", model_variation.split(\"/\")[-1], method, \"avg.csv\")\n",
    "\n",
    "# Write average metrics to CSV\n",
    "with open(avg_csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=average_metrics.keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerow(average_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
