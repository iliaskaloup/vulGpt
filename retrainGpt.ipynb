{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e824ea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch, os, re, pandas as pd, json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DataCollatorForLanguageModeling, DataCollatorWithPadding, GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, AutoConfig\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# Initialize seeder and randomness\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cce3cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ModuleUtilsMixin.num_parameters of GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50001, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50001, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_or_path = 'microsoft/CodeGPT-small-py' # 'microsoft/CodeGPT-small-py' 'gpt2'\n",
    "base_tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path, do_lower_case = True)\n",
    "base_model = GPT2LMHeadModel.from_pretrained(model_name_or_path)\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "base_model.num_parameters\n",
    "# (wte): Embedding(50262, 768)\n",
    "#     (wpe): Embedding(1024, 768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12df7ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in vocabulary:  50000\n",
      "1007\n",
      "['for', 'Ġi', 'Ġin', 'Ġrange', '(', '0', ',', 'Ġ10', '):']\n",
      "tensor([[1007,  274,  292, 1016,   10,   18,   14, 2165,  298]])\n"
     ]
    }
   ],
   "source": [
    "print('Words in vocabulary: ', base_tokenizer.vocab_size)\n",
    "vocabulary = base_tokenizer.get_vocab()\n",
    "print(vocabulary['for'])\n",
    "\n",
    "example_text = \"for i in range(0, 10):\"\n",
    "print(base_tokenizer.tokenize(example_text))\n",
    "\n",
    "text_ids = base_tokenizer.encode(example_text, return_tensors = 'pt')\n",
    "print(text_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b0fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_text_samples(model, tokenizer, input_text, device, n_samples = 5):\n",
    "    text_ids = tokenizer.encode(input_text, return_tensors = 'pt')\n",
    "    text_ids = text_ids.to(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    generated_text_samples = model.generate(\n",
    "        text_ids, \n",
    "        max_length= 100,  \n",
    "        num_return_sequences= n_samples,\n",
    "        no_repeat_ngram_size= 2,\n",
    "        repetition_penalty= 1.5,\n",
    "        top_p= 0.92,\n",
    "        temperature= .85,\n",
    "        do_sample= True,\n",
    "        top_k= 125,\n",
    "        early_stopping= True\n",
    "    )\n",
    "    gen_text = []\n",
    "    for t in generated_text_samples:\n",
    "        text = tokenizer.decode(t, skip_special_tokens=True)\n",
    "        gen_text.append(text)\n",
    "\n",
    "    return gen_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df7dbc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for i in range(0, 10): # 5% of file size to read block = int((i * chunk_size) / (file.tell() + 1)) self._lastblocks[block].append([chunk]) ',\n",
       " 'for i in range(0, 10): for j in [i + 1] << (10 - x[j]) if abs_idx is True: # If not already done. return idx ',\n",
       " \"for i in range(0, 10): for j in reversed_range((i + 1) * 4 - 2): result[j] = (result[(m % m), int(((1 if num2and3 or n == 0 else 12)) / 32. ** 16)]) # Convert the first half of each byte into a sequence that has 8 bits shifted out by 6 bytes since this is not inclusive return tuple([int(''.join('{:02x}'.format(*val[:7])), ord\",\n",
       " \"for i in range(0, 10): r.save() print('Saving successful') \",\n",
       " 'for i in range(0, 10): for j in [1 + math.pow((i - 1) / float(\"inf\"), 2), (j-math.power(-2))]: if self._is_twopoint(*args[3]): yield Point({self: args[:4], \\'x\\': [], \\'y\\': []}) # no point else: raise ValueError(\\'unknown coordinate system\\') ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text generation example\n",
    "generated_text_samples = generate_n_text_samples(base_model, base_tokenizer, example_text, device)\n",
    "\n",
    "generated_text_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3176d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the eos and bos tokens are defined\n",
    "bos = '<|endoftext|>'\n",
    "eos = '<|EOS|>'\n",
    "pad = '<|pad|>'\n",
    "\n",
    "special_tokens_dict = {'eos_token': eos, 'bos_token': bos, 'pad_token': pad}\n",
    "\n",
    "# the new token is added to the tokenizer\n",
    "num_added_toks = base_tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# the model config to which we add the special tokens\n",
    "config = AutoConfig.from_pretrained(model_name_or_path, \n",
    "                                    bos_token_id=base_tokenizer.bos_token_id,\n",
    "                                    eos_token_id=base_tokenizer.eos_token_id,\n",
    "                                    pad_token_id=base_tokenizer.pad_token_id,\n",
    "                                    output_hidden_states=False)\n",
    "\n",
    "# the pre-trained model is loaded with the custom configuration\n",
    "base_model = GPT2LMHeadModel.from_pretrained(model_name_or_path, config=config)\n",
    "\n",
    "# Clear the pre-trained weights of the model for from scratch training\n",
    "base_model.init_weights()\n",
    "\n",
    "# the model embedding is resized\n",
    "base_model.resize_token_embeddings(len(base_tokenizer))\n",
    "\n",
    "base_model = base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b4d5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'max_length = 100\\n\\nfilepath= \\'articles1.csv\\'\\ndf = pd.read_csv(filepath, encoding = \\'utf-8\\', usecols=[\\'title\\', \\'publication\\'])                    .rename(columns={\\'title\\': \\'text\\'})\\n\\n\\npd.set_option(\"display.max_colwidth\", None)\\ndf.head(5)\\n\\ndef remove_publication_headline(headline, publication):\\n    # publication col doesn\\'t match exactly with newspaper in title col\\n    if str(publication) in str(headline):\\n        headline = headline.split(\\' - \\')[0]\\n    return headline\\n\\ndef process_headlines(df, text_colname):\\n  \\n    # Remove empty and null rows\\n    titulo_vacio = (df[\\'text\\'].str.len() == 0) | df[\\'text\\'].isna()\\n    df = df[~titulo_vacio]\\n\\n    # Remove publication name from title\\n    df[\\'text\\'] = df.apply(lambda row: remove_publication_headline(row[\\'text\\'], row[\\'publication\\']), axis = 1)\\n\\n    # Remove headlines with less than 8 words\\n    titlos_len_ge8 = (df[\\'text\\'].str.split().apply(lambda x: len(x)) >= 8)\\n    df = df[titlos_len_ge8]\\n\\n    # Drop duplicates\\n    text_df = df.drop_duplicates(subset = [text_colname])                [[text_colname]]\\n\\n    return text_df\\n    \\ndf = process_headlines(df, \\'text\\')\\ndf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''max_length = 100\n",
    "\n",
    "filepath= 'articles1.csv'\n",
    "df = pd.read_csv(filepath, encoding = 'utf-8', usecols=['title', 'publication'])\\\n",
    "                    .rename(columns={'title': 'text'})\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df.head(5)\n",
    "\n",
    "def remove_publication_headline(headline, publication):\n",
    "    # publication col doesn't match exactly with newspaper in title col\n",
    "    if str(publication) in str(headline):\n",
    "        headline = headline.split(' - ')[0]\n",
    "    return headline\n",
    "\n",
    "def process_headlines(df, text_colname):\n",
    "  \n",
    "    # Remove empty and null rows\n",
    "    titulo_vacio = (df['text'].str.len() == 0) | df['text'].isna()\n",
    "    df = df[~titulo_vacio]\n",
    "\n",
    "    # Remove publication name from title\n",
    "    df['text'] = df.apply(lambda row: remove_publication_headline(row['text'], row['publication']), axis = 1)\n",
    "\n",
    "    # Remove headlines with less than 8 words\n",
    "    titlos_len_ge8 = (df['text'].str.split().apply(lambda x: len(x)) >= 8)\n",
    "    df = df[titlos_len_ge8]\n",
    "\n",
    "    # Drop duplicates\n",
    "    text_df = df.drop_duplicates(subset = [text_colname])\\\n",
    "                [[text_colname]]\n",
    "\n",
    "    return text_df\n",
    "    \n",
    "df = process_headlines(df, 'text')\n",
    "df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d3d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "\n",
    "def dropEmpty(tokens0):\n",
    "    tokens = []\n",
    "    for i in range(0, len(tokens0)):\n",
    "        temp = tokens0[i]\n",
    "        if temp != []:\n",
    "            tokens.append(temp)\n",
    "    return tokens\n",
    "\n",
    "with open(\"pretraining_corpus.csv\", newline='', encoding='utf-8') as f:\n",
    "        reader = csv.reader(x.replace('\\0', '') for x in f)\n",
    "        #reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "data = dropEmpty(data)\n",
    "limit = int(len(data)/8)\n",
    "data = data[0:limit]\n",
    "# data = data[0:1000] # sub sample for checking\n",
    "\n",
    "# Creation of the dataset's structure\n",
    "text = []\n",
    "for item in data:\n",
    "    text.append(' '.join([str(token) for token in item[0:]]))\n",
    "\n",
    "# Convert to pandas\n",
    "df = pd.DataFrame({'text': text})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b547cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.iloc[21,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bad9889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86462 components for training and 9607 for validation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16731</th>\n",
       "      <td>&lt;|endoftext|&gt; test_singleton self ftype finfo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14209</th>\n",
       "      <td>&lt;|endoftext|&gt; __setitem__ self indx value stri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44094</th>\n",
       "      <td>&lt;|endoftext|&gt; setup self self exceptions got_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23896</th>\n",
       "      <td>&lt;|endoftext|&gt; ault a single value is returned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49166</th>\n",
       "      <td>&lt;|endoftext|&gt; ault database has lost the book ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63206</th>\n",
       "      <td>&lt;|endoftext|&gt; lda_plot lda x y y_pred fig_inde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61404</th>\n",
       "      <td>&lt;|endoftext|&gt; test_1d self data n random randn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>&lt;|endoftext|&gt; test_hermeone self assert_equal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28030</th>\n",
       "      <td>&lt;|endoftext|&gt; testexpiration self self cache s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15725</th>\n",
       "      <td>&lt;|endoftext|&gt; broadcast_arrays args strid$stri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86462 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "16731  <|endoftext|> test_singleton self ftype finfo ...\n",
       "14209  <|endoftext|> __setitem__ self indx value stri...\n",
       "44094  <|endoftext|> setup self self exceptions got_r...\n",
       "23896  <|endoftext|> ault a single value is returned ...\n",
       "49166  <|endoftext|> ault database has lost the book ...\n",
       "...                                                  ...\n",
       "63206  <|endoftext|> lda_plot lda x y y_pred fig_inde...\n",
       "61404  <|endoftext|> test_1d self data n random randn...\n",
       "17730  <|endoftext|> test_hermeone self assert_equal ...\n",
       "28030  <|endoftext|> testexpiration self self cache s...\n",
       "15725  <|endoftext|> broadcast_arrays args strid$stri...\n",
       "\n",
       "[86462 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = bos + ' ' + df['text'] + ' ' + eos\n",
    "\n",
    "df_train, df_val = train_test_split(df, train_size = 0.9, random_state = seed)\n",
    "print(f'There are {len(df_train)} components for training and {len(df_val)} for validation')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67321e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', '__index_level_0__'],\n",
       "    num_rows: 86462\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we load the datasets directly from a pandas df\n",
    "train_dataset = Dataset.from_pandas(df_train[['text']])\n",
    "val_dataset = Dataset.from_pandas(df_val[['text']])\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "220bf13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|> test_singleton self ftype finfo double ftype2 finfo double assert_equal id ftype id ftype2 class testlongdouble testcase <|EOS|>',\n",
       " '<|endoftext|> __setitem__ self indx value strid$strid$strid$ if self is masked raise maerror strid$ # if getmask indx is not nomask # msg strid$ # raise indexerror msg # if value is masked m self _mask if m is nomask m numpy zeros self shape dtype masktype m indx true self _mask m self _sharedmask false return # dval getdata value astype self dtype valmask getmask value if self _mask is nomask if valmask is not nomask self _mask numpy zeros self shape dtype masktype self _mask indx valmask elif not self _hardmask # unshare the mask if necessary to avoid propagation self unshare_mask self _mask indx valmask elif hasattr indx strid$ and indx dtype bool_ indx indx umath logical_not self _mask else mindx mask_or self _mask indx valmask copy true dindx self _data indx if dindx size numid$ dindx mindx dval elif mindx is nomask dindx dval dval dindx self _mask indx mindx # set data ndarray __setitem__ self _data indx dval # <|EOS|>',\n",
       " '<|endoftext|> setup self self exceptions got_request_exception connect self _on_request_exception self client handler load_middleware <|EOS|>',\n",
       " '<|endoftext|> ault a single value is returned if ``a`` is a scalar otherwise ``np array a size`` samples are drawn returns out ndarray or scalar drawn samples from the parameterized power distribution raises valueerror if a numid$ notes the probability density function is math p x a ax a numid$ numid$ le x le numid$ a numid$ the power function distribution is just the inverse of the pareto distribution it may also be seen as a special case of the beta distribution it is used for example in modeling the over reporting of insurance claims references numid$ christian kleiber samuel kotz strid$ wiley numid$ numid$ heckert n a and filliben james j strid$ national institute of standards and technology handbook series june numid$ https www itl nist gov div898 software dataplot refman2 auxillar powpdf pdf examples draw samples from the distribution a numid$ # shape samples numid$ s np random power a samples display the histogram of the samples along with the probability density function import matplotlib pyplot as plt count bins ignored plt hist s bins numid$ x np linspace numid$ numid$ numid$ y a x a numid$ normed_y samples np diff bins numid$ y plt plot x normed_y plt show compare the power function distribution to the inverse of the pareto from scipy import stats rvs np random power numid$ numid$ rvsp np random pareto numid$ numid$ xx np linspace numid$ numid$ numid$ powpdf stats powerlaw pdf xx numid$ plt figure plt hist rvs bins numid$ density true plt plot xx powpdf strid$ plt title strid$ plt figure plt hist numid$ numid$ rvsp bins numid$ density true plt plot xx powpdf strid$ plt title strid$ plt figure plt hist numid$ numid$ rvsp bins numid$ density true plt plot xx powpdf strid$ plt title strid$ strid$ return cont random_power self _brng size self lock numid$ a strid$ cons_positive numid$ numid$ strid$ cons_none numid$ numid$ strid$ cons_none none <|EOS|>',\n",
       " '<|endoftext|> ault database has lost the book self assertequal book objects using <|EOS|>',\n",
       " '<|endoftext|> test_duplicate_table_error self strid$strid$strid$ cursor connection cursor query strid$ models article _meta db_table with self assertraises databaseerror cursor execute query # we donstrid$t do # if sqlite3 if once we get #numid$ fixed has referential integrity turned # on or not something that would be controlled by runtime support and user # preference # verify if its type is django database db integrityerror class fkconstraintstests transactiontestcase <|EOS|>',\n",
       " '<|endoftext|> ault if `seed` is ``none`` then ``xorshift1024 randomstate`` will try to read data from `` dev urandom`` or the windows analog if available if unavailable a numid$ bit hash of the time and process id is used notes see ``xoroshiro128`` for a faster implementation that has a smaller period parallel features ``xorshift1024`` can be used in parallel applications by calling the method ``jump`` which advances the state as if math `numid$ numid$ ` random numbers have been generated this allows the original sequence to be split so that distinct segments can be used in each worker process all generators should be initialized with the same seed to ensure that the segments come from the same sequence from randomgen import randomgenerator xorshift1024 rg randomgenerator xorshift1024 numid$ for _ in range numid$ # advance rg i by i jumps for i in range numid$ rg i jump i state and seeding the ``xorshift1024`` state vector consists of a numid$ element array of numid$ bit unsigned integers ``xorshift1024`` is seeded using either a single numid$ bit unsigned integer or a vector of numid$ bit unsigned integers in either case the input seed is used as an input or inputs for another simple random number generator splitmix64 and the output of this prng function is used as the initial state using a single numid$ bit value for the seed can only initialize a small range of the possible initial state values when using an array the splitmix64 state for producing the ith component of the initial state is xord with the ith value of the seed array until the seed array is exhausted when using an array the initial state for the splitmix64 state is numid$ so that using a single element array and using the same value as a scalar will produce the same initial state examples from randomgen import randomgenerator xorshift1024 rg randomgenerator xorshift1024 numid$ rg standard_normal identical method using only xoroshiro128 rg xorshift10241234 generator rg standard_normal references numid$ strid$ http xorshift di unimi it numid$ marsaglia george strid$ journal of statistical software online numid$ numid$ pp numid$ numid$ numid$ numid$ sebastiano vigna strid$ corr abs numid$ numid$ numid$ numid$ sebastiano vigna strid$ corr abs numid$ numid$ numid$ strid$ c <|EOS|>',\n",
       " '<|endoftext|> average data data numeric array data return numeric add reduce data len data <|EOS|>',\n",
       " '<|endoftext|> write self message if not self data and not message startswith strid$ self stream write message self stream flush message strid$ self data append message <|EOS|>',\n",
       " '<|endoftext|> node select_child node node float numid$ pos long index nogil # find which sub node a position should go into # and return the appropriate node c <|EOS|>',\n",
       " '<|endoftext|> test_passwordinput self w passwordinput self asserthtmlequal w render strid$ strid$ strid$ self asserthtmlequal w render strid$ none strid$ self asserthtmlequal w render strid$ strid$ strid$ # the render_value argument lets you specify whether the widget should render # its value for security reasons this is off by <|EOS|>',\n",
       " '<|endoftext|> ault strid$ self assertequal <|EOS|>',\n",
       " '<|endoftext|> __radd__ self other return self array_like arraylike numid$ opt_out optout # supported operations assert_ array_like opt_out is opt_out assert_ opt_out array_like is opt_out # not supported with assert_raises typeerror # don t use the python <|EOS|>',\n",
       " '<|endoftext|> ault gstep tf contrib framework get_or_create_global_step do_step tf assign_add gstep numid$ session tf train monitoredsession with session self assertequal numid$ session run do_step self assertequal numid$ session run do_step self assertfalse session should_stop # should have closed self asserttrue session should_stop self asserttrue session _is_closed <|EOS|>',\n",
       " '<|endoftext|> ined abfunc x filly x for all x to enable reduce strid$strid$__doc__strid$__name__ str dbfunc ufunc_domain dbfunc domain ufunc_fills dbfunc fillx filly <|EOS|>',\n",
       " '<|endoftext|> get_manipulator_field_objs self return curry formfields floatfield max_digits self max_digits decimal_places self decimal_places class imagefield filefield <|EOS|>',\n",
       " '<|endoftext|> _log_variable variable if isinstance variable list for var in variable logging info strid$ var name var device else logging info strid$ variable name variable device <|EOS|>',\n",
       " '<|endoftext|> aults import patterns url urlpatterns patterns strid$ # view has erroneous import url rstrid$ strid$ # module has erroneous import url rstrid$ strid$ # view does not exist url rstrid$ strid$ # view is not callable url rstrid$ strid$ # module does not exist url rstrid$ strid$ import non_existent <|EOS|>',\n",
       " '<|endoftext|> test_render_none self self check_html self widget strid$ none html strid$ <|EOS|>',\n",
       " '<|endoftext|> graph self pass @abc abstractproperty <|EOS|>',\n",
       " '<|endoftext|> __getitem__ self key return self _session key <|EOS|>',\n",
       " '<|endoftext|> public object __core_prng c <|EOS|>',\n",
       " '<|endoftext|> __init__ self alpha numid$ numid$ fit_intercept false super lasso self __init__ alpha alpha rho numid$ numid$ fit_intercept fit_intercept strid$strid$strid$ import gc from time import time import sys import numpy as np from collections import <|EOS|>',\n",
       " '<|endoftext|> __init__ self eps strid$ self eps eps <|EOS|>',\n",
       " '<|endoftext|> ault is none in which case a single value is returned returns out float or ndarray drawn samples examples output a 3x8000 array n np random standard_exponential numid$ numid$ strid$ return cont legacy_standard_exponential self _aug_state size self lock numid$ none none cons_none none none cons_none none none cons_none none <|EOS|>',\n",
       " '<|endoftext|> test_get_for_models_partial_cache self # partial cache contenttype objects get_for_model contenttype with self assertnumqueries numid$ cts contenttype objects get_for_models contenttype foowithurl self assertequal cts contenttype contenttype objects get_for_model contenttype foowithurl contenttype objects get_for_model foowithurl <|EOS|>',\n",
       " '<|endoftext|> f2py_cb_returncomplex return_value #endif strid$strid$strid$ #ifn <|EOS|>',\n",
       " '<|endoftext|> testmasklogitsandtargets self strid$strid$strid$ batch_size numid$ padded_length numid$ num_classes numid$ np random seed numid$ sequence_length np random randint numid$ padded_length numid$ batch_size logits np random rand batch_size padded_length num_classes targets np random randint numid$ num_classes batch_size padded_length logits_masked_t targets_masked_t dynamic_rnn_estimator _mask_logits_and_targets tf constant logits dtype tf float32 tf constant targets dtype tf int32 tf constant sequence_length dtype tf int32 with tf session as sess logits_masked targets_masked sess run logits_masked_t targets_masked_t expected_logits_shape sum sequence_length num_classes np testing assert_equal expected_logits_shape logits_masked shape strid$ format expected_logits_shape logits_masked shape expected_targets_shape sum sequence_length np testing assert_equal expected_targets_shape targets_masked shape strid$ format expected_targets_shape targets_masked shape masked_index numid$ for i in range batch_size for j in range sequence_length i actual_logits logits_masked masked_index expected_logits logits i j np testing assert_almost_equal expected_logits actual_logits err_msg strid$ strid$ format i j expected_logits actual_logits actual_targets targets_masked masked_index expected_targets targets i j np testing assert_almost_equal expected_targets actual_targets err_msg strid$ strid$ format i j expected_targets actual_targets masked_index numid$ <|EOS|>',\n",
       " '<|endoftext|> test_builtin_command self strid$ args strid$ strid$ out err self run_manage args self assertnooutput out self assertoutput err strid$ <|EOS|>',\n",
       " '<|endoftext|> _validate_params self if not isinstance self max_iter int raise valueerror strid$ if self max_iter numid$ raise valueerror strid$ <|EOS|>',\n",
       " '<|endoftext|> unsigned int n_samples y shape numid$ c <|EOS|>',\n",
       " '<|endoftext|> inclusion_one_param_from_template arg strid$strid$strid$ return strid$ strid$ arg inclusion_one_param_from_template anything strid$ @register inclusion_tag strid$ takes_context false <|EOS|>',\n",
       " '<|endoftext|> test_both_date_objects self strid$strid$strid$ today datetime date today self assertequal timeuntil today self oneday today strid$ self assertequal timeuntil today self oneday today strid$ self assertequal timeuntil today self oneweek today strid$ <|EOS|>',\n",
       " '<|endoftext|> process_item self self expr self item get_line numid$ lstrip numid$ numid$ strip self name self item label return beginstatement process_item self <|EOS|>',\n",
       " '<|endoftext|> is_compatible_with self other strid$strid$strid$ other as_dtype other return self _type_enum in other as_datatype_enum other base_dtype as_datatype_enum <|EOS|>',\n",
       " '<|endoftext|> _scroll_output self direction strid$strid$strid$ curses_ui cursesui _scroll_output self direction self unwrapped_outputs append self _curr_unwrapped_output self wrapped_outputs append self _curr_wrapped_output self scroll_messages append self _scroll_info class cursestest test_util tensorflowtestcase _exit string_to_codes strid$ <|EOS|>',\n",
       " '<|endoftext|> testreuseargscope self func1_kwargs strid$ numid$ strid$ none strid$ numid$ key_op _key_op func1 current_scope key_op func1_kwargs copy with self test_session with tf contrib framework arg_scope func1 a numid$ b none c numid$ as scope1 pass with tf contrib framework arg_scope scope1 as scope self assertdictequal scope current_scope <|EOS|>',\n",
       " '<|endoftext|> ault sort over the last axis returns indices n ndarray of ints array of indices that sort the keys along the specified axis see also argsort indirect sort ndarray sort in place sort sort return a sorted copy of an array examples sort names first by surname then by name surnames strid$ strid$ strid$ first_names strid$ strid$ strid$ ind np lexsort first_names surnames ind array numid$ numid$ numid$ surnames i strid$ first_names i for i in ind strid$ strid$ strid$ sort two columns of numbers a numid$ numid$ numid$ numid$ numid$ numid$ numid$ # first column b numid$ numid$ numid$ numid$ numid$ numid$ numid$ # second column ind np lexsort b a # sort by a then by b print ind numid$ numid$ numid$ numid$ numid$ numid$ numid$ a i b i for i in ind numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ note that sorting is first according to the elements of ``a`` secondary sorting is according to the elements of ``b`` a normal ``argsort`` would have yielded a i b i for i in np argsort a numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ structured arrays are sorted lexically by ``argsort`` x np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ dtype np dtype strid$ int strid$ int np argsort x # or np argsort x order strid$ strid$ array numid$ numid$ numid$ numid$ numid$ numid$ numid$ strid$strid$strid$ can_cast from_ to casting strid$ returns true if cast between data types can occur according to the casting rule if from is a scalar or array scalar also returns true if the scalar value can be cast without overflow or truncation to an integer parameters from_ dtype dtype specifier scalar or array data type scalar or array to cast from to dtype or dtype specifier data type to cast to casting strid$ strid$ strid$ strid$ strid$ optional controls what kind of data casting may occur strid$ means the data types should not be cast at all strid$ means only byte order changes are allowed strid$ means only casts which can preserve values are allowed strid$ means only safe casts or casts within a kind like float64 to float32 are allowed strid$ means any data conversions may be done returns out bool true if cast can occur according to the casting rule notes starting in numpy numid$ numid$ can_cast function now returns false in strid$ casting mode for integer float dtype and string dtype if the string dtype length is not long enough to store the max integer float value converted to a string previously can_cast in strid$ mode returned true for integer float dtype and a string dtype of any length see also dtype result_type examples basic examples np can_cast np int32 np int64 true np can_cast np float64 complex true np can_cast complex float false np can_cast strid$ strid$ true np can_cast strid$ strid$ false np can_cast strid$ strid$ false casting scalars np can_cast numid$ strid$ true np can_cast numid$ strid$ false np can_cast numid$ strid$ true np can_cast numid$ 5e100 np float32 false np can_cast numid$ numid$ np float32 true array scalar checks the value array does not np can_cast np array numid$ numid$ np float32 true np can_cast np array numid$ numid$ np float32 false using the casting rules np can_cast strid$ strid$ strid$ true np can_cast strid$ strid$ strid$ false np can_cast strid$ strid$ strid$ true np can_cast strid$ strid$ strid$ false np can_cast strid$ strid$ strid$ true np can_cast strid$ strid$ strid$ false np can_cast strid$ strid$ strid$ true np can_cast strid$ strid$ strid$ false np can_cast strid$ strid$ strid$ true strid$strid$strid$ promote_types type1 type2 returns the data type with the smallest size and smallest scalar kind to which both ``type1`` and ``type2`` may be safely cast the returned data type is always in native byte order this function is symmetric but rarely associative parameters type1 dtype or dtype specifier first data type type2 dtype or dtype specifier second data type returns out dtype the promoted data type notes versionadded numid$ numid$ numid$ starting in numpy numid$ numid$ promote_types function now returns a valid string length when given an integer or float dtype as one argument and a string dtype as another argument previously it always returned the input string dtype even if it wasnstrid$f4strid$f8strid$float64strid$i8strid$f4strid$float64strid$ i8strid$ c8strid$complex128strid$i4strid$s8strid$s11strid$sstrid$i1strid$u1strid$s6strid$sstrid$i1strid$u1strid$s4strid$s dtype unmodified floating point values are not demoted to integers and complex values are not demoted to floats parameters a scalar or array_like the value whose minimal data type is to be found returns out dtype the minimal data type notes versionadded numid$ numid$ numid$ see also result_type promote_types dtype can_cast examples np min_scalar_type numid$ dtype strid$ np min_scalar_type numid$ dtype strid$ np min_scalar_type numid$ numid$ dtype strid$ np min_scalar_type 1e50 dtype strid$ np min_scalar_type np arange numid$ dtype strid$ dtype strid$ strid$strid$strid$ result_type arrays_and_dtypes returns the type that results from applying the numpy type promotion rules to the arguments type promotion in numpy works similarly to the rules in languages like c with some slight differences when both scalars and arrays are used the arraystrid$t convert losslessly into a numid$ bit float so a numid$ bit float should be the result type by examining the value of the constant strid$ we see that it fits in an numid$ bit integer which can be cast losslessly into the numid$ bit float parameters arrays_and_dtypes list of arrays and dtypes the operands of some operation whose result type is needed returns out dtype the result type see also dtype promote_types min_scalar_type can_cast notes versionadded numid$ numid$ numid$ the specific algorithm used is as follows categories are determined by first checking which of boolean integer int uint or floating point float complex the maximum kind of all the arrays and the scalars are if there are only scalars or the maximum category of the scalars is higher than the maximum category of the arrays the data types are combined with func `promote_types` to produce the return value otherwise `min_scalar_type` is called on each array and the resulting data types are all combined with func `promote_types` to produce the return value the set of int values is not a subset of the uint values for types with the same number of bits something not reflected in func `min_scalar_type` but handled as a special case in `result_type` examples np result_type numid$ np arange numid$ dtype strid$ dtype strid$ np result_type strid$ strid$ dtype strid$ np result_type numid$ numid$ numid$ dtype strid$ strid$strid$strid$ newbuffer size return a new uninitialized buffer object parameters size int size in bytes of returned buffer object returns newbuffer buffer object returned uninitialized buffer object of `size` bytes strid$strid$strid$ getbuffer obj offset size create a buffer object from the given object referencing a slice of length size starting at offset <|EOS|>',\n",
       " '<|endoftext|> double x_data_ptr double x_data data c <|EOS|>',\n",
       " '<|endoftext|> streaming_recall predictions labels ignore_mask none metrics_collections none updates_collections none name none strid$strid$strid$ with variable_scope variable_op_scope predictions labels name strid$ predictions labels _remove_squeezable_dimensions predictions labels predictions get_shape assert_is_compatible_with labels get_shape true_positives true_positives_update_op _streaming_true_positives predictions labels ignore_mask metrics_collections none updates_collections none name none false_negatives false_negatives_update_op _streaming_false_negatives predictions labels ignore_mask metrics_collections none updates_collections none name none <|EOS|>',\n",
       " '<|endoftext|> method_get_file_filename field self return os path join settings media_root getattr self field name <|EOS|>',\n",
       " '<|endoftext|> __unicode__ self return self headline class meta ordering strid$ class author models model author_id models autofield primary_key true db_column strid$ first_name models charfield max_length numid$ db_column strid$ last_name models charfield max_length numid$ db_column strid$ <|EOS|>',\n",
       " '<|endoftext|> protocol buffer and runs inference on an input jpeg image it outputs human readable strings of the top numid$ predictions along with their probabilities change the image_file argument to any jpg image to compute a classification of that image please see the tutorial and website for a detailed description of how to use this script to perform image recognition https tensorflow org tutorials image_recognition strid$ import os path import re import sys import tarfile # pylint disable unused import g bad import order import tensorflow python platform from six moves import urllib import numpy as np import tensorflow as tf # pylint enable unused import g bad import order from tensorflow python platform import gfile flags tf app flags flags # classify_image_graph_ <|EOS|>',\n",
       " '<|endoftext|> __init__ self base_tree n_trees bootstrap false random_state none self base_tree tree self n_trees n_trees self bootstrap bootstrap self random_state check_random_state random_state self forest <|EOS|>',\n",
       " '<|endoftext|> addvalue self val strid$strid$strid$ result val if val name not in self _values self _values add val name if self _outer_context is not none result self _outer_context addvalue val # create an enter that makes strid$ known to this context enter _enter result self _name is_constant true parallel_iterations self _parallel_iterations self _values add enter name self _external_values val name enter result enter else actual_val self _external_values get val name if actual_val is not none result actual_val return result <|EOS|>',\n",
       " '<|endoftext|> lon_lat self query strid$ return self coords query <|EOS|>',\n",
       " '<|endoftext|> test_get_input_output_ts self strid$strid$strid$ self assertequal len ge select _get_input_ts self graph numid$ self assertequal len ge select _get_output_ts self graph numid$ <|EOS|>',\n",
       " '<|endoftext|> commit_manually func strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> ault 1e numid$ if the gradient norm is below this threshold the optimization will be aborted min_error_diff float optional <|EOS|>',\n",
       " '<|endoftext|> ault <|EOS|>',\n",
       " '<|endoftext|> initions and conventions used examples a np mgrid numid$ numid$ numid$ numid$ np fft fftn a axes numid$ numid$ array numid$ numid$ j numid$ numid$ j numid$ numid$ j # may vary numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j np fft fftn a numid$ numid$ axes numid$ numid$ array numid$ numid$ j numid$ numid$ j numid$ numid$ j # may vary numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j import matplotlib pyplot as plt x y np meshgrid numid$ np pi np arange numid$ numid$ numid$ np pi np arange numid$ numid$ s np sin x np cos y np random uniform numid$ numid$ x shape fs np fft fftn s plt imshow np log np abs np fft fftshift fs numid$ matplotlib image axesimage object at 0x plt show strid$ return _raw_fftnd a s axes fft norm @array_function_dispatch _fftn_dispatcher <|EOS|>',\n",
       " '<|endoftext|> test_invalid_batch_size self msg strid$ with self assertraisesmessage valueerror msg note objects bulk_update fields strid$ batch_size numid$ <|EOS|>',\n",
       " '<|endoftext|> _test_dir self test_name strid$strid$strid$ test_dir os path join self get_temp_dir test_name if os path isdir test_dir for f in glob glob strid$ test_dir os remove f else os makedirs test_dir return test_dir <|EOS|>',\n",
       " '<|endoftext|> _str self t self _write repr t <|EOS|>',\n",
       " '<|endoftext|> isoptional var return var has_key strid$ and strid$ in var strid$ and strid$ not in var strid$ and isintent_nothide var <|EOS|>',\n",
       " '<|endoftext|> test_iter_nested_iters_basic # test nested iteration basic usage a arange numid$ reshape numid$ numid$ numid$ i j np nested_iters a numid$ numid$ numid$ vals for x in i vals append y for y in j assert_equal vals numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ i j np nested_iters a numid$ numid$ numid$ vals for x in i vals append y for y in j assert_equal vals numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ i j np nested_iters a numid$ numid$ numid$ vals for x in i vals append y for y in j assert_equal vals numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> parser path match re match strid$ base_dir strid$ path path if not match return none return path _replace export_version int match group numid$ path_list gc get_paths strid$ parser # contains all ten paths every_fifth gc mod_export_version numid$ print every_fifth path_list # shows strid$ strid$ largest_three gc largest_export_versions numid$ print largest_three all_paths # shows strid$ strid$ strid$ both gc union every_fifth largest_three print both all_paths # shows strid$ strid$ # strid$ strid$ strid$ # delete everything not in strid$ to_delete gc negation both for p in to_delete all_paths gfile deleterecursively p path # deletes strid$ strid$ # strid$ strid$ strid$ strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function import collections import heapq import math import os from six moves import xrange # pylint disable re <|EOS|>',\n",
       " '<|endoftext|> _testscorefunction self session losses expected xs sf_losses sg additional_score_function_losses losses n len expected self assertequal len expected len sf_losses values session run list expected sf_losses # test forward surrogate losses if isinstance expected set # hack sort the two halves of the values by norm and compare # those sorted_expected sorted values n key np linalg norm sorted_losses sorted values n key np linalg norm self assertallclose sorted_expected sorted_losses else # expected losses in a particular order self assertallclose values n values n # test backprop expected_grads tf gradients ys losses list expected xs xs sf_grads tf gradients ys losses sf_losses xs xs self assertequal len expected_grads len sf_grads n_grad len expected_grads grad_values session run expected_grads sf_grads self assertallclose grad_values n_grad grad_values n_grad <|EOS|>',\n",
       " '<|endoftext|> testinpolymorphictwice self self _add_op strid$ strid$ strid$ strid$ strid$ strid$ op self _lib apply_op strid$ a numid$ b numid$ numid$ numid$ name strid$ self assertprotoequals strid$strid$strid$ op node_ <|EOS|>',\n",
       " '<|endoftext|> test_explicitpk_unspecified self strid$strid$strid$ form explicitpkform strid$ strid$ strid$ strid$ self assertfalse form is_valid <|EOS|>',\n",
       " '<|endoftext|> testlaplacemode self with self test_session loc_v np array numid$ numid$ numid$ numid$ numid$ numid$ scale_v np array numid$ numid$ numid$ numid$ numid$ numid$ laplace tf contrib distributions laplace loc loc_v scale scale_v self assertequal laplace mode get_shape numid$ self assertallclose laplace mode eval loc_v <|EOS|>',\n",
       " '<|endoftext|> duration_string duration days duration days seconds duration seconds microseconds duration microseconds minutes seconds numid$ seconds seconds numid$ hours minutes numid$ minutes minutes numid$ string strid$ format hours minutes seconds if days string strid$ format days string if microseconds string strid$ format microseconds return string import datetime import json from django core import exceptions serializers from django db import models from django test import testcase from models import durationmodel class testsaveload testcase <|EOS|>',\n",
       " '<|endoftext|> double add double center_data_ptr double center_scale double x_data_ptr int x_indices_ptr int offset int xnnz double c strid$strid$strid$ c <|EOS|>',\n",
       " '<|endoftext|> _parse_entity self line m name_re line assert m `line self item self __class__ __name__` name line m end line line m end lstrip array_spec none item self item copy line line item get_line if line startswith strid$ i line find strid$ assert i numid$ `line` array_spec split_comma line numid$ i strip item line line i numid$ lstrip char_length none if line startswith strid$ i line find strid$ if i numid$ char_length item apply_map line numid$ lstrip line strid$ else char_length item apply_map line numid$ i strip line line i value none if line startswith strid$ value item apply_map line numid$ lstrip return name array_spec char_length value <|EOS|>',\n",
       " '<|endoftext|> api_get_area x return x area <|EOS|>',\n",
       " '<|endoftext|> ault_form render context context pop return output class commentcountnode template node <|EOS|>',\n",
       " '<|endoftext|> exponential self scale numid$ numid$ size none strid$ exponential scale numid$ numid$ size none draw samples from an exponential distribution its probability density function is math f x frac numid$ beta frac numid$ beta exp frac x beta for ``x numid$`` and numid$ elsewhere math ` beta` is the scale parameter which is the inverse of the rate parameter math ` lambda numid$ beta` the rate parameter is an alternative widely used parameterization of the exponential distribution numid$ _ the exponential distribution is a continuous analogue of the geometric distribution it describes many common situations such as the size of raindrops measured over many rainstorms numid$ _ or the time between page requests to wikipedia numid$ _ parameters scale float or array_like of floats the scale parameter math ` beta numid$ lambda` must be non negative size int or tuple of ints optional output shape if the given shape is e g `` m n k `` then ``m n k`` samples are drawn if size is ``none`` <|EOS|>',\n",
       " '<|endoftext|> ined as mul a_3 a_4 at each scope # nodes c_i are <|EOS|>',\n",
       " '<|endoftext|> as_mysql self compiler connection return super as_sql compiler connection function strid$ class lower transform function strid$ lookup_name strid$ class now func template strid$ <|EOS|>',\n",
       " '<|endoftext|> ault levels and level names these can be replaced with any positive set # of values having corresponding names there is a pseudo level all which # is only really there as a lower limit for user <|EOS|>',\n",
       " '<|endoftext|> aults to true num_threads the number of readers that will work in parallel queue_capacity capacity of the queue that will store parsed lines min_after_dequeue minimum number of elements that can be left by a dequeue operation only used if `shuffle` is true seed passed to random shuffle operations only used if `shuffle` is true returns a `dataframe` that has columns corresponding to `features` and is filled with `example`s from `filepatterns` raises valueerror no files match `filepatterns` valueerror `features` contains the reserved name strid$ strid$strid$no matching file names strid$if column_names is none has_header must be true strid$indexstrid$strid$ is reserved and can not be used for a column name strid$skip_header_lines numid$ if has_header else numid$ index value reader_source textfilesource filenames reader_kwargs reader_kwargs batch_size batch_size queue_capacity queue_capacity shuffle shuffle min_after_dequeue min_after_dequeue num_threads num_threads seed seed parser csv_parser csvparser column_names <|EOS|>',\n",
       " '<|endoftext|> _list_node_dumps self node_name strid$strid$strid$ lines lines append strid$ watch_keys self _debug_dump debug_watch_keys node_name dump_count numid$ for watch_key in watch_keys debug_tensor_data self _debug_dump watch_key_to_data watch_key for datum in debug_tensor_data dump_count numid$ lines append strid$ datum output_slot datum debug_op datum timestamp self _debug_dump t0 numid$ numid$ lines insert numid$ strid$ dump_count return lines # copyright numid$ the tensorflow authors all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # strid$strid$strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function import shutil import tempfile import numpy as np from six moves import xrange # pylint disable re <|EOS|>',\n",
       " '<|endoftext|> _load_post_and_files self strid$strid$strid$ if self method strid$ self _post self _files querydict strid$ encoding self _encoding multivaluedict return if self _read_started and not hasattr self strid$ self _mark_post_parse_error return if self meta get strid$ strid$ startswith strid$ if hasattr self strid$ # use already read data data bytesio self _body else data self try self _post self _files self parse_file_upload self meta data except # an error occured while parsing post data since when # formatting the error the request handler might access # self post set self _post and self _file to prevent # attempts to parse post data again # mark that an error occured this allows self __repr__ to # be explicit about it instead of simply representing an # empty post self _mark_post_parse_error raise elif self meta get strid$ strid$ startswith strid$ self _post self _files querydict self body encoding self _encoding multivaluedict else self _post self _files querydict strid$ encoding self _encoding multivaluedict ## file like and iterator interface ## ## expects self _stream to be set to an appropriate source of bytes by ## a corresponding request subclass e g wsgirequest ## also when request data has already been read by request post or ## request body self _stream points to a bytesio instance ## containing that data <|EOS|>',\n",
       " '<|endoftext|> ault none strid$ fetch a given key from the cache if the key does not exist return <|EOS|>',\n",
       " '<|endoftext|> initions strid$strid$ self _dispatch t expr <|EOS|>',\n",
       " '<|endoftext|> test_ <|EOS|>',\n",
       " '<|endoftext|> _formatarray a format_function rank max_line_len next_line_prefix separator edge_items summary_insert strid$strid$strid$ if rank numid$ return str a if summary_insert and numid$ edge_items len a leading_items trailing_items summary_insert1 edge_items edge_items summary_insert else leading_items trailing_items summary_insert1 numid$ len a strid$ if rank numid$ s strid$ line next_line_prefix for i in xrange leading_items word format_function a i separator s line _extendline s line word max_line_len next_line_prefix if summary_insert1 s line _extendline s line summary_insert1 max_line_len next_line_prefix for i in xrange trailing_items numid$ numid$ word format_function a i separator s line _extendline s line word max_line_len next_line_prefix word format_function a numid$ s line _extendline s line word max_line_len next_line_prefix s line strid$ s strid$ s len next_line_prefix else s strid$ sep separator rstrip for i in xrange leading_items if i numid$ s next_line_prefix s _formatarray a i format_function rank numid$ max_line_len strid$ next_line_prefix separator edge_items summary_insert s s rstrip sep rstrip strid$ max rank numid$ numid$ if summary_insert1 s next_line_prefix summary_insert1 strid$ for i in xrange trailing_items numid$ numid$ if leading_items or i trailing_items s next_line_prefix s _formatarray a i format_function rank numid$ max_line_len strid$ next_line_prefix separator edge_items summary_insert s s rstrip sep rstrip strid$ max rank numid$ numid$ if leading_items or trailing_items numid$ s next_line_prefix s _formatarray a numid$ format_function rank numid$ max_line_len strid$ next_line_prefix separator edge_items summary_insert rstrip strid$ return s <|EOS|>',\n",
       " '<|endoftext|> test_range_object self r numericrange numid$ numid$ instance rangesmodel ints r instance save loaded rangesmodel objects get self assertequal r loaded ints <|EOS|>',\n",
       " '<|endoftext|> test_seed_out_of_range_array self # gh #numid$ rs randomgenerator self prng self data1 strid$ assert_raises valueerror rs seed numid$ self bits numid$ assert_raises valueerror rs seed numid$ assert_raises typeerror rs seed numid$ numid$ self bits numid$ <|EOS|>',\n",
       " '<|endoftext|> fetch_california_housing data_home none download_if_missing true strid$ loader for the california housing dataset from statlib parameters data_home optional <|EOS|>',\n",
       " '<|endoftext|> n except ogrexception pass else # random access isnstrid$invalid feature id s feat_id #### layer properties #### @property <|EOS|>',\n",
       " '<|endoftext|> test_scalar self s randomgenerator mt19937 numid$ assert_equal s randint numid$ numid$ s1 np random randomstate numid$ assert_equal s1 randint numid$ numid$ assert_equal s1 randint numid$ s randint numid$ s randomgenerator mt19937 numid$ assert_equal s randint numid$ numid$ s1 np random randomstate numid$ assert_equal s1 randint numid$ numid$ assert_equal s1 randint numid$ s randint numid$ self rg seed numid$ self nprs seed numid$ self _is_state_common <|EOS|>',\n",
       " '<|endoftext|> __init__ self path match none recursive false required true widget select label none initial none help_text none args kwargs self path self match self recursive path match recursive super filepathfield self __init__ choices required required widget widget label label initial initial help_text help_text args kwargs self choices if self match is not none self match_re re compile self match if recursive for root dirs files in os walk self path for f in files if self match is none or self match_re search f f os path join root f self choices append f f replace path strid$ numid$ else try for f in os listdir self path full_file os path join self path f if os path isfile full_file and self match is none or self match_re search f self choices append full_file f except oserror pass self widget choices self choices class splitdatetimefield multivaluefield <|EOS|>',\n",
       " '<|endoftext|> struct char data s s strid$#include string h strid$strid$ depends pyobj_to_string_len c static int pyobj_to_ ctype s pyobject obj ctype s value return pyobj_to_string_len obj f2py_string value ctype_bytes s strid$strid$strid$ static char f2py_doc_ function_name s strid$ static pyobject f2py_ function_name s pyobject capi_self pyobject capi_args pyobject capi_keywds pyobject volatile capi_buildvalue null volatile int f2py_success numid$ decl_list s static char capi_kwlist keyword_clist optkw_clist extrakw_clist strid$ s if pyarg_parsetupleandkeywords capi_args capi_keywds strid$ strid$ pyarg_obj_clist s return null frompyobj_list s call_list s f2py_success pyerr_occurred if f2py_success pyobjfrom_list s capi_buildvalue py_buildvalue buildvalue_clist s clean_pyobjfrom_list s clean_frompyobj_list s return capi_buildvalue strid$ pymethod <|EOS|>',\n",
       " '<|endoftext|> testmessage self self assertall strid$ self assertall strid$ self assertall strid$ self assertall strid$ self assertall strid$ self assertsamenotequal strid$ strid$ self assertsamenotequal strid$ strid$ self assertsameexceptnumber strid$ strid$ self assertsameexceptnumber strid$ strid$ self assertnone strid$ strid$ strid$strid$xstrid$strid$ self assertnone strid$ strid$ strid$strid$xstrid$strid$ self assertnone strid$ strid$ strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> test_should_be_able_to_edit_related_objects_on_add_view self post strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ response self client post strid$ post self assertequal numid$ parent objects count self assertequal numid$ child objects count children_names list child objects order_by strid$ values_list strid$ flat true self assertequal strid$ parent objects latest strid$ name self assertequal strid$ strid$ children_names <|EOS|>',\n",
       " '<|endoftext|> check_new_complex_int self level numid$ key val numid$ 1j numid$ self generic_new key val <|EOS|>',\n",
       " '<|endoftext|> log_post_delete sender kwargs pre_delete_order append sender kwargs strid$ pk <|EOS|>',\n",
       " '<|endoftext|> _makeresult self return _scipytexttestresult self stream self descriptions self verbosity class scipytest strid$ scipy tests site manager usage scipytest package test level numid$ verbosity numid$ package is package name or its module object package is supposed to contain a directory tests with test_ py files where refers to the names of submodules test_ py files are supposed to <|EOS|>',\n",
       " '<|endoftext|> _verifyvalues self tensor_in_sizes glimpse_sizes offsets expected_rows expected_cols strid$strid$strid$ rows tensor_in_sizes numid$ cols tensor_in_sizes numid$ # row tensor with entries by row # numid$ numid$ numid$ # numid$ numid$ numid$ # numid$ numid$ numid$ # # t_rows tf tile numid$ numid$ r for r in range numid$ rows numid$ numid$ cols name strid$ # shuffle to switch to a convention of batch_size height width depth t_rows_4d tf transpose tf expand_dims tf expand_dims t_rows numid$ numid$ numid$ numid$ numid$ numid$ # column tensor with entries by column # numid$ numid$ numid$ numid$ # numid$ numid$ numid$ numid$ # numid$ numid$ numid$ numid$ # # t_cols tf tile numid$ numid$ r for r in range numid$ cols numid$ rows numid$ name strid$ # shuffle to switch to a convention of batch_size height width depth t_cols_4d tf transpose tf expand_dims tf expand_dims t_cols numid$ numid$ numid$ numid$ numid$ numid$ # extract_glimpses from row and column tensor respectively # switch order for glimpse_sizes and offsets to switch from row col # convention to tensorflows height width convention t1 tf constant glimpse_sizes numid$ glimpse_sizes numid$ shape numid$ t2 tf constant offsets numid$ offsets numid$ shape numid$ numid$ glimpse_rows tf transpose attention_ops extract_glimpse t_rows_4d t1 t2 numid$ numid$ numid$ numid$ glimpse_cols tf transpose attention_ops extract_glimpse t_cols_4d t1 t2 numid$ numid$ numid$ numid$ # evaluate the tensorflow graph with self test_session as sess value_rows value_cols sess run glimpse_rows glimpse_cols # check dimensions of returned glimpse self assertequal value_rows shape numid$ glimpse_sizes numid$ self assertequal value_rows shape numid$ glimpse_sizes numid$ self assertequal value_cols shape numid$ glimpse_sizes numid$ self assertequal value_cols shape numid$ glimpse_sizes numid$ # check entries min_random_val numid$ max_random_val max rows cols for i in range numid$ glimpse_sizes numid$ for j in range numid$ glimpse_sizes numid$ if expected_rows i is none or expected_cols j is none self assertgreaterequal value_rows numid$ i j numid$ min_random_val self assertlessequal value_rows numid$ i j numid$ max_random_val self assertgreaterequal value_cols numid$ i j numid$ min_random_val self assertlessequal value_cols numid$ i j numid$ max_random_val else self assertequal value_rows numid$ i j numid$ expected_rows i self assertequal value_cols numid$ i j numid$ expected_cols j <|EOS|>',\n",
       " '<|endoftext|> ault does not use random starting point random_start numid$ returns agaussianprocessmodel self a gaussian process model object awaiting data to be fitted to strid$strid$the strid$ storage mode is not supported yet please contribute strid$storage mode should either be strid$ or strid$ unknown storage mode strid$theta0 thetal and thetau must have the same lengthstrid$the bounds must satisfy o thetal thetaustrid$theta0 must be strictly positivestrid$thetal and thetau should either be both or neither specified # store other parameters self normalize normalize self nugget nugget self optimizer optimizer self random_start int random_start <|EOS|>',\n",
       " '<|endoftext|> test_hidden_widget self # hiddeninput widgets are displayed differently in the as_table as_ul # and as_p output of a form their verbose names are not displayed and a # separate row is not displayed theystrid$s form element class person form first_name charfield last_name charfield hidden_text charfield widget hiddeninput birthday datefield p person auto_id false self assertequal p as_table strid$strid$textstrid$first_namestrid$textstrid$last_namestrid$textstrid$birthdaystrid$hiddenstrid$hidden_textstrid$strid$ self assertequal p as_ul strid$strid$textstrid$first_namestrid$textstrid$last_namestrid$textstrid$birthdaystrid$hiddenstrid$hidden_textstrid$strid$ self assertequal p as_p strid$strid$textstrid$first_namestrid$textstrid$last_namestrid$textstrid$birthdaystrid$hiddenstrid$hidden_textstrid$strid$ # with auto_id set a hiddeninput still gets an id but it doesnstrid$id_ sstrid$s order in the form p person strid$ strid$ strid$ strid$ strid$ strid$ auto_id false self assertequal p as_table strid$strid$numid$strid$errorliststrid$textstrid$first_namestrid$johnstrid$textstrid$last_namestrid$lennonstrid$textstrid$birthdaystrid$numid$ numid$ numid$strid$hiddenstrid$hidden_textstrid$strid$ self assertequal p as_ul strid$strid$errorliststrid$textstrid$first_namestrid$johnstrid$textstrid$last_namestrid$lennonstrid$textstrid$birthdaystrid$numid$ numid$ numid$strid$hiddenstrid$hidden_textstrid$strid$ self assertequal p as_p strid$strid$errorliststrid$textstrid$first_namestrid$johnstrid$textstrid$last_namestrid$lennonstrid$textstrid$birthdaystrid$numid$ numid$ numid$strid$hiddenstrid$hidden_textstrid$strid$ # a corner case itstrid$ input type strid$ name strid$ input type strid$ name strid$ strid$ input type strid$ name strid$ input type strid$ name strid$ strid$ input type strid$ name strid$ input type strid$ name strid$ <|EOS|>',\n",
       " '<|endoftext|> ault_none delete a a objects get pk a pk self assertequal none a set <|EOS|>',\n",
       " '<|endoftext|> __init__ self n_neighbors numid$ radius numid$ numid$ algorithm strid$ leaf_size numid$ self _init_params n_neighbors n_neighbors radius radius algorithm algorithm leaf_size leaf_size from sklearn externals joblib import strid$strid$strid$ # author gael varoquaux gael varoquaux@normalesup org # license bsd style import copy import inspect import numpy as np from scipy import sparse import warnings from metrics import r2_score ############################################################################### <|EOS|>',\n",
       " '<|endoftext|> ault_db_alias index_sql connection creation sql_indexes_for_model article no_style self assertequal len index_sql numid$ @skipunless connections <|EOS|>',\n",
       " '<|endoftext|> test_simple self for note in self notes note note strid$ note id with self assertnumqueries numid$ note objects bulk_update self notes strid$ self assertcountequal note objects values_list strid$ flat true cat note for cat in self notes <|EOS|>',\n",
       " '<|endoftext|> length_is value arg strid$ return len value int arg <|EOS|>',\n",
       " '<|endoftext|> simplify self tolerance numid$ numid$ preserve_topology false strid$ returns the geometry simplified using the douglas peucker algorithm to the specified tolerance higher tolerance less points if no tolerance provided <|EOS|>',\n",
       " '<|endoftext|> coerce_text v if not isinstance v basestring_ if sys version_info numid$ numid$ attr strid$ else attr strid$ if hasattr v attr return unicode v else return bytes v return v # usr bin env python # encoding utf numid$ strid$ script to generate contribor and pull request lists this script generates contributor and pull request lists for release announcements using github v3 protocol use requires an authentication token in order to have sufficient bandwidth you can get one following the directions at ` https help github com articles creating an access token for command line use _ don t add any scope as the <|EOS|>',\n",
       " '<|endoftext|> add self args kwargs raise notimplementederror strid$ <|EOS|>',\n",
       " '<|endoftext|> __init__ self x y none z none srid none strid$strid$strid$ if isinstance x tuple list # here a tuple or list was passed in under the `x` parameter ndim len x coords x elif isinstance x int float long and isinstance y int float long # here x y and optionally z were passed in individually as parameters if isinstance z int float long ndim numid$ coords x y z else ndim numid$ coords x y else raise typeerror strid$ point self _create_point ndim coords # initializing using the address returned from the geos # createpoint factory super point self __init__ point srid srid @classmethod <|EOS|>',\n",
       " '<|endoftext|> add_session_cookie_message message return message strid$ strid$ w010 warning add_session_cookie_message strid$ strid$ id strid$ w011 warning add_session_cookie_message strid$ strid$ strid$ id strid$ w012 warning add_session_cookie_message strid$ id strid$ <|EOS|>',\n",
       " '<|endoftext|> __init__ self vars_to_resolve self vars_to_resolve map variable vars_to_resolve <|EOS|>',\n",
       " '<|endoftext|> s_r123array4x64 r123array4x64 ctype <|EOS|>',\n",
       " '<|endoftext|> ault inp constant numid$ numid$ shape numid$ numid$ name strid$ out array_ops stop_gradient inp igrad gradients gradients out inp numid$ assert igrad is none class hessianvectorproducttest test_util tensorflowtestcase <|EOS|>',\n",
       " '<|endoftext|> ine __docformat__ strid$ at the top level in accordance with pep numid$ note that the __docformat__ variable in a package s __init__ py file does not apply to objects <|EOS|>',\n",
       " '<|endoftext|> setup self name items name split name items pop numid$ params float x for x in items self func getattr np random name self params tuple params numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> testpmfcountsstretchedinbroadcastwhensamerank self with self test_session p numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ counts numid$ numid$ pmf tf contrib distributions multinomial n numid$ p p pmf counts self assertallclose pmf eval numid$ numid$ numid$ numid$ self assertequal numid$ pmf get_shape <|EOS|>',\n",
       " '<|endoftext|> er to the actual field <|EOS|>',\n",
       " '<|endoftext|> ault inner 5c$ strid$testapp urlobject special view <|EOS|>',\n",
       " '<|endoftext|> test_non_nullable_blank self class model models model field models genericipaddressfield null false blank true field model _meta get_field strid$ errors field check expected error strid$ strid$ hint none obj field id strid$ self assertequal errors expected class imagefieldtests isolatedmodelstestcase <|EOS|>',\n",
       " '<|endoftext|> with self assertraises valueerror as cm self _lib apply_op strid$ a numid$ numid$ numid$ b strid$ self assertequal str cm exception strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> ault try to guess it or set it to none if <|EOS|>',\n",
       " '<|endoftext|> test_nonexistent_field self with self assertraisesmessage fielddoesnotexist strid$ note objects bulk_update strid$ pk_fields_error strid$ <|EOS|>',\n",
       " '<|endoftext|> test_user_switch_forces_new_login self strid$strid$strid$ user objects create username strid$ # known user authenticates response self client get strid$ self header self known_user self assertequal response context strid$ username strid$ # during the session the remote_user changes to a different user response self client get strid$ self header strid$ # ensure that the current user is not the prior remote_user # in backends that create a new user username is strid$ # in backends that do not create new users it is strid$ anonymous user self assertnotequal response context strid$ username strid$ class remoteusernocreatebackend remoteuserbackend strid$strid$strid$ create_unknown_user false class remoteusernocreatetest remoteusertest strid$strid$strid$ backend strid$ <|EOS|>',\n",
       " '<|endoftext|> vstack tup strid$strid$strid$ return numeric concatenate atleast_2d tup numid$ <|EOS|>',\n",
       " '<|endoftext|> itype_t i1 i2 c <|EOS|>',\n",
       " '<|endoftext|> annotation self return self _annotation @property <|EOS|>',\n",
       " '<|endoftext|> make_data num_vectors strid$strid$strid$ vectors classes for _ in xrange num_vectors if np random random numid$ numid$ vectors append np random normal numid$ numid$ numid$ numid$ np random normal numid$ numid$ numid$ numid$ classes append numid$ else vectors append np random normal numid$ numid$ numid$ numid$ np random normal numid$ numid$ numid$ numid$ classes append numid$ return np asarray vectors classes @staticmethod <|EOS|>',\n",
       " '<|endoftext|> aultstrid$contenttypes_testsstrid$foostrid$contenttypes_testsstrid$renamedfoostrid$migratestrid$contenttypes_testsstrid$zerostrid$ <|EOS|>',\n",
       " '<|endoftext|> ` protobuf data structure strid$ accumulator self _getaccumulator run return accumulator graph <|EOS|>',\n",
       " '<|endoftext|> __eq__ self other return self __class__ other __class__ and self deconstruct other deconstruct <|EOS|>',\n",
       " '<|endoftext|> test_cache_versioning_get_set self # set using <|EOS|>',\n",
       " '<|endoftext|> __new__ cls args kwargs return _param __new__ cls args kwargs @classmethod <|EOS|>',\n",
       " '<|endoftext|> testmeanabsolutelossgradient self with self test_session target predicted _ self _gettestvectors result tf contrib layers mean_absolute_loss predicted target x_shape numid$ numid$ result_shape numid$ err tf test compute_gradient_error target x_shape result result_shape err_tolerance 1e numid$ self assertless err err_tolerance class meansquaredlosstest tf test testcase <|EOS|>',\n",
       " '<|endoftext|> ault strid$ type str help strid$ <|EOS|>',\n",
       " '<|endoftext|> gfile_copy_callback files_to_copy export_dir_path strid$ callback to copy files using `gfile copy` to an export directory this method is used as the <|EOS|>',\n",
       " '<|endoftext|> decision_function self x strid$strid$strid$ x np atleast_2d np asanyarray x scores np dot x self coef_ t self intercept_ if self classes shape numid$ numid$ return np ravel scores else return scores <|EOS|>',\n",
       " '<|endoftext|> secure_view request return httpresponse strid$ request post from django db import models class country models model name models charfield max_length numid$ iso_two_letter models charfield max_length numid$ class place models model name models charfield max_length numid$ class meta abstract true class restaurant place pass class pizzeria restaurant pass class state models model two_letter_code models charfield max_length numid$ primary_key true class twofields models model f1 models integerfield unique true f2 models integerfield unique true from django core cache backends locmem import locmemcache class closehookmixin object closed false <|EOS|>',\n",
       " '<|endoftext|> check_testufuncregression self strid$ for f in strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ # strid$ strid$ strid$ strid$ # strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ #print f try uf getattr umath f except attributeerror uf getattr fromnumeric f mf getattr coremodule f args self d uf nin ur uf args mr mf args assert_equal ur filled numid$ mr filled numid$ f assert_mask_equal ur mask mr mask # <|EOS|>',\n",
       " '<|endoftext|> testlearnlinearextrapolation self strid$strid$strid$ batch_size numid$ sequence_length numid$ train_steps numid$ eval_steps numid$ cell_size numid$ learning_rate numid$ numid$ loss_threshold numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> _buildsmallplaceholderlmodel self a tf placeholder tf int32 numid$ numid$ b tf placeholder tf int32 numid$ numid$ y tf matmul a b return a b y <|EOS|>',\n",
       " '<|endoftext|> test_annotate_values self books list book objects filter pk numid$ annotate mean_age avg strid$ values self assertequal books strid$ numid$ strid$ numid$ strid$ strid$ strid$ numid$ numid$ strid$ the <|EOS|>',\n",
       " '<|endoftext|> setup self from django core urlresolvers import regexurlresolver urlconf strid$ urlconf_callables strid$ self resolver regexurlresolver rstrid$ urlconf self callable_resolver regexurlresolver rstrid$ urlconf_callables <|EOS|>',\n",
       " '<|endoftext|> testdeconv2dsame self with self test_session strides numid$ numid$ numid$ numid$ # input output batch height width depth x_shape numid$ numid$ numid$ numid$ y_shape numid$ numid$ numid$ numid$ # filter kernel_height kernel_width output_depth input_depth f_shape numid$ numid$ numid$ numid$ x constant_op constant numid$ numid$ shape x_shape name strid$ dtype types float32 f constant_op constant numid$ numid$ shape f_shape name strid$ dtype types float32 output nn deconv2d x f y_shape strides strides padding strid$ value output eval for n in xrange x_shape numid$ for k in xrange f_shape numid$ for w in xrange y_shape numid$ for h in xrange y_shape numid$ target numid$ numid$ # we add a case for locations divisible by the stride h_in h strides numid$ numid$ and h numid$ and h y_shape numid$ numid$ w_in w strides numid$ numid$ and w numid$ and w y_shape numid$ numid$ if h_in and w_in target numid$ numid$ elif h_in or w_in target numid$ numid$ self assertallclose target value n h w k <|EOS|>',\n",
       " '<|endoftext|> test_localized_formats self with self settings use_l10n true translation override strid$ self assertequal filesizeformat numid$ strid$ self assertequal filesizeformat numid$ strid$ self assertequal filesizeformat numid$ numid$ strid$ self assertequal filesizeformat numid$ numid$ numid$ strid$ self assertequal filesizeformat numid$ numid$ strid$ self assertequal filesizeformat numid$ numid$ numid$ strid$ self assertequal filesizeformat numid$ numid$ numid$ numid$ strid$ self assertequal filesizeformat numid$ numid$ numid$ strid$ self assertequal filesizeformat numid$ numid$ numid$ numid$ strid$ self assertequal filesizeformat numid$ numid$ numid$ numid$ numid$ strid$ self assertequal filesizeformat numid$ numid$ numid$ numid$ numid$ numid$ strid$ self assertequal filesizeformat complex numid$ numid$ strid$ self assertequal filesizeformat strid$ strid$ self assertequal filesizeformat strid$ strid$ from django template <|EOS|>',\n",
       " '<|endoftext|> ine two skippers because python doesn t allow both # return with value and yield inside the same function <|EOS|>',\n",
       " '<|endoftext|> fit self x y strid$strid$strid$ n_features_total x shape numid$ estimator self estimator support_ np ones n_features_total dtype np bool ranking_ np ones n_features_total dtype np int while np sum support_ self n_features estimator fit x support_ y # rank features based on coef_ handle multi class abs_coef_ np sum estimator coef_ numid$ axis numid$ sorted_abs_coef_ np sort abs_coef_ threshold sorted_abs_coef_ np int np sum support_ self percentage support_ support_ abs_coef_ threshold ranking_ support_ numid$ self support_ support_ self ranking_ ranking_ return self <|EOS|>',\n",
       " '<|endoftext|> int len_w problem csr_set_problem x_values data x_indices shape x_indices data x_indptr shape x_indptr data y data n_features bias param set_parameter solver_type eps c weight shape numid$ weight_label data weight data error_msg check_parameter problem param if error_msg free_problem problem free_parameter param raise valueerror error_msg # early return model train problem param c <|EOS|>',\n",
       " '<|endoftext|> check_ex1 self level numid$ ex1 <|EOS|>',\n",
       " '<|endoftext|> ault strid$strid$passwordstrid$passwordstrid$passwordstrid$passwordstrid$passwordstrid$passwordstrid$test@example com from django forms import radioselect from base import widgettest class radioselecttest widgettest widget radioselect <|EOS|>',\n",
       " '<|endoftext|> test_intcomma self test_list strid$ strid$ strid$ strid$ strid$ result_list strid$ strid$ strid$ strid$ strid$ self humanize_tester test_list result_list strid$ <|EOS|>',\n",
       " '<|endoftext|> __init__ self root strid$strid$strid$ self root root self disable numid$ self emittednohandlerwarning numid$ self loggerdict <|EOS|>',\n",
       " '<|endoftext|> size_t i numid$ c <|EOS|>',\n",
       " '<|endoftext|> clone self strid$strid$strid$ new ga_list ga_list data_clone self new stats new stats update self stats return new <|EOS|>',\n",
       " '<|endoftext|> ault none if int random_state is the seed used by the random number generator if randomstate instance random_state is the random number generator if none the random number generator is the randomstate instance used by `np random` returns out array of size n_samples the sampled subsets of integer the order of the items is not necessarily random use a random permutation of the array if the order of the items has to be randomized strid$ _sample_without_replacement_check_input n_population n_samples c <|EOS|>',\n",
       " '<|endoftext|> ault_batch_size none tf tfrecordreader false none num_threads name self assertraisesregexp valueerror strid$ tf contrib learn io read_batch_features _valid_file_pattern <|EOS|>',\n",
       " '<|endoftext|> ine_macros <|EOS|>',\n",
       " '<|endoftext|> unsigned int n_samples x shape numid$ c <|EOS|>',\n",
       " '<|endoftext|> get_libraries self key strid$ return self get_libs key strid$ <|EOS|>',\n",
       " '<|endoftext|> __getstate__ self strid$ state numid$ self shape self dtype self flags fnc self _data tostring getmaskarray self tostring self _fill_value return state # <|EOS|>',\n",
       " '<|endoftext|> get_accessor_name self # this method encapsulates the logic that decides what name to give an # accessor descriptor that retrieves related many to one or # many to many objects it uses the lower cased object_name strid$ # but this can be overridden with the strid$ option if self field rel multiple return self field rel related_name or self opts object_name lower strid$ else return self field rel related_name or self opts object_name lower class_prepared object pre_init object post_init object pre_save object post_save object pre_delete object post_delete object post_syncdb object strid$ this module implements a transaction manager that can be used to <|EOS|>',\n",
       " '<|endoftext|> test_prefixed self with translation override strid$ self assertequal reverse strid$ strid$ with translation override strid$ self assertequal reverse strid$ strid$ @override_settings root_urlconf strid$ <|EOS|>',\n",
       " '<|endoftext|> testinversegammaentropy self with self test_session alpha_v np array numid$ numid$ numid$ numid$ numid$ numid$ beta_v np array numid$ numid$ numid$ numid$ numid$ numid$ expected_entropy stats invgamma entropy alpha_v scale beta_v inv_gamma tf contrib distributions inversegamma alpha alpha_v beta beta_v self assertequal inv_gamma entropy get_shape numid$ self assertallclose inv_gamma entropy eval expected_entropy <|EOS|>',\n",
       " '<|endoftext|> render self data output strid$ self ul_class and strid$ self ul_class or strid$ str_data_list map str data # normalize to strings for value choice in self choices checked_html strid$ if str value in str_data_list checked_html strid$ field_name strid$ self field_name value output append strid$ self get_id escape value self __class__ __name__ field_name checked_html self get_id escape value choice output append strid$ return strid$ join output #################### # file uploads # #################### class fileuploadfield formfield <|EOS|>',\n",
       " '<|endoftext|> view_with_secure request strid$ response httpresponse response test_was_secure_request request is_secure return response <|EOS|>',\n",
       " '<|endoftext|> check_continue self assert_equal parse continue strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> test_multiple_ordering self strid$strid$strid$ qs employee objects annotate sum window expression sum strid$ partition_by strid$ order_by f strid$ asc f strid$ asc order_by strid$ strid$ self assertquerysetequal qs strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ strid$ numid$ strid$ datetime date numid$ numid$ numid$ numid$ transform lambda row row name row salary row department row hire_date row sum @skipif connection vendor strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> seed self seed none counter none key none strid$strid$strid$ if seed is not none and key is not none raise valueerror strid$ ub numid$ numid$ if key is none if seed is none try state random_entropy numid$ except runtimeerror state random_entropy numid$ strid$ state state view np uint64 else state seed_by_array seed numid$ for i in range numid$ self rng_state key v i state i else key int_to_array key strid$ numid$ numid$ for i in range numid$ self rng_state key v i key i counter numid$ if counter is none else counter counter int_to_array counter strid$ numid$ numid$ for i in range numid$ self rng_state ctr v i counter i self _reset_state_variables @property <|EOS|>',\n",
       " '<|endoftext|> __exit__ self type value traceback locale setlocale locale lc_numeric locale self cur_locale strid$strid$strid$ import sys import numpy as np from numpy testing import run_module_suite assert_ assert_equal dec # pep3118 format strings for native standard alignment and byteorder types scalars_and_codes np bool_ strid$ np byte strid$ np short strid$ np intc strid$ np int_ strid$ np longlong strid$ np ubyte strid$ np ushort strid$ np uintc strid$ np uint strid$ np ulonglong strid$ np half strid$ np single strid$ np double strid$ np longdouble strid$ np csingle strid$ np cdouble strid$ np clongdouble strid$ class testscalarpep3118 object skip_if_no_buffer_interface dec skipif sys version_info major numid$ strid$ @skip_if_no_buffer_interface <|EOS|>',\n",
       " '<|endoftext|> __array_function__ self func types args kwargs if func not in handled_functions return notimplemented # note this allows subclasses that don t override # __array_function__ to handle diagonalarray objects if not all issubclass t self __class__ for t in types return notimplemented return handled_functions func args kwargs a convenient pattern is to <|EOS|>',\n",
       " '<|endoftext|> iter_indices i ret while not i finished ret append i index i iternext return ret <|EOS|>',\n",
       " '<|endoftext|> _fullpath self path strid$strid$strid$ splitpath path split self _baseurl numid$ if len splitpath numid$ result os path join self _baseurl path else result path # path contains baseurl already return result <|EOS|>',\n",
       " '<|endoftext|> test_weibull self self _set_common_state self _is_state_common compare_1_input self nprs weibull self rg weibull self _is_state_common <|EOS|>',\n",
       " '<|endoftext|> test_deprecated assert_warns_message deprecationwarning strid$ mockclass1 assert_warns_message deprecationwarning strid$ mockclass2 method assert_warns_message deprecationwarning strid$ mockclass3 val assert_warns_message deprecationwarning strid$ mock_function assert val numid$ <|EOS|>',\n",
       " '<|endoftext|> __init__ self self connection none self queries <|EOS|>',\n",
       " '<|endoftext|> test_flatatt self ########### # flatatt # ########### self assertequal flatatt strid$ strid$ strid$ self assertequal flatatt strid$ strid$ strid$ strid$ strid$ self assertequal flatatt strid$ <|EOS|>',\n",
       " '<|endoftext|> ined by `a ss t` where `s m vdv t` for `operatorpd` `m` this provides efficient low rank updates of arbitrary `operatorpd` some math given positive <|EOS|>',\n",
       " '<|endoftext|> spatial_lookup_sql self lvalue lookup_type value field qn alias col db_type lvalue geo_col strid$ qn alias qn col lookup_info self geometry_functions get lookup_type false if lookup_info return strid$ lookup_info geo_col self get_geom_placeholder value field srid # todo is this really necessary mysql canstrid$isnullstrid$not strid$ raise typeerror strid$ repr lookup_type from cx_oracle import clob from django contrib gis db backends adapter import wktadapter class oraclespatialadapter wktadapter input_size clob from django db backends oracle base import from django db backends oracle base import databasewrapper as oracledatabasewrapper from django contrib gis db backends oracle creation import oraclecreation from django contrib gis db backends oracle operations import oracleoperations class databasewrapper oracledatabasewrapper <|EOS|>',\n",
       " '<|endoftext|> spatial_aggregate_sql self agg raise notimplementederror strid$ # routines for getting the ogc compliant models <|EOS|>',\n",
       " '<|endoftext|> inedsplit can reproduce a split generated by kfold folds numid$ np ones numid$ kf_train kf_test for i train_ind test_ind in enumerate kfold numid$ shuffle true split x kf_train append train_ind kf_test append test_ind folds test_ind i ps_train ps_test ps pre <|EOS|>',\n",
       " '<|endoftext|> test_randint_broadcast self dtype if dtype np bool upper numid$ lower numid$ else info np iinfo dtype upper int info max numid$ lower info min self _reset_state a self rg randint lower upper numid$ dtype dtype self _reset_state b self rg randint lower numid$ upper dtype dtype assert_equal a b self _reset_state c self rg randint lower upper size numid$ dtype dtype assert_equal a c self _reset_state d self rg randint np array lower numid$ np array upper dtype np object size numid$ dtype dtype assert_equal a d self _reset_state e self rg randint np array lower numid$ np array upper numid$ size numid$ dtype dtype assert_equal a e self _reset_state a self rg randint numid$ upper size numid$ dtype dtype self _reset_state b self rg randint upper numid$ dtype dtype assert_equal a b <|EOS|>',\n",
       " '<|endoftext|> __init__ self n_components numid$ scale true max_iter numid$ tol 1e numid$ copy true warnings warn strid$ strid$ _cca __init__ self n_components n_components scale scale max_iter max_iter tol tol copy copy class plssvd baseestimator transformermixin strid$ partial least square svd simply perform a svd on the crosscovariance matrix x y there are no iterative <|EOS|>',\n",
       " '<|endoftext|> svm_parameter param c <|EOS|>',\n",
       " '<|endoftext|> _setupsparse self is_distributed dtype with self _maybewithdevice strid$ if is_distributed else none var0 tf variable numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ dtype dtype var1 tf variable numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ dtype dtype with self _maybewithdevice strid$ if is_distributed else none grads tf indexedslices tf constant numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ dtype dtype numid$ numid$ numid$ numid$ sgd tf train gradientdescentoptimizer numid$ numid$ clip_opt tf contrib opt variableclippingoptimizer sgd var0 numid$ var1 numid$ numid$ numid$ update_op clip_opt apply_gradients list zip grads grads var0 var1 tf initialize_all_variables run return var0 var1 update_op <|EOS|>',\n",
       " '<|endoftext|> np ndarray np float64_t ndim numid$ mode strid$ intercept intercept np empty n_class n_class numid$ numid$ dtype np float64 copy_intercept intercept data model intercept shape c <|EOS|>',\n",
       " '<|endoftext|> __str__ self return self name class jobresponsibilities models model job models foreignkey job to_field strid$ responsibility models foreignkey strid$ to_field strid$ @python_2_unicode_compatible class responsibility models model description models charfield max_length numid$ unique true jobs models manytomanyfield job through jobresponsibilities related_name strid$ <|EOS|>',\n",
       " '<|endoftext|> aultstrid$ load custom assignment_one_ <|EOS|>',\n",
       " '<|endoftext|> test_app_locales self strid$strid$strid$ filenames list gen_filenames self assertin os path join locale_path strid$ strid$ strid$ filenames from django test import testcase override_settings client from django utils translation import override class csrfviewtests testcase urls strid$ @override_settings use_i18n true middleware_classes strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> cluster_spec as_cluster_ <|EOS|>',\n",
       " '<|endoftext|> _find_binning_thresholds data max_bins subsample random_state strid$strid$strid$ if not numid$ max_bins numid$ raise valueerror strid$ strid$ format max_bins rng check_random_state random_state if subsample is not none and data shape numid$ subsample subset rng choice np arange data shape numid$ subsample replace false data data take subset axis numid$ percentiles np linspace numid$ numid$ num max_bins numid$ percentiles percentiles numid$ numid$ binning_thresholds for f_idx in range data shape numid$ col_data np ascontiguousarray data f_idx dtype x_dtype distinct_values np unique col_data if len distinct_values max_bins midpoints distinct_values numid$ distinct_values numid$ midpoints numid$ else # we sort again the data in this case we could compute # approximate midpoint percentiles using the output of # np unique col_data return_counts instead but this is more # work and the performance benefit will be limited because we # work on a fixed size subsample of the full data midpoints np percentile col_data percentiles interpolation strid$ astype x_dtype binning_thresholds append midpoints return binning_thresholds class _binmapper baseestimator transformermixin strid$ transformer that maps a dataset into integer valued bins the bins are created in a feature wise fashion using quantiles so that each bins contains approximately the same number of samples for large datasets quantiles are computed on a subset of the data to speed up the binning but the quantiles should remain stable if the number of unique values for a given feature is less than ``max_bins`` then the unique values of this feature are used instead of the quantiles parameters max_bins int optional <|EOS|>',\n",
       " '<|endoftext|> content_test self ua ua_scalar nbytes # check the length of the unicode base type self assert_ int ua dtype str numid$ self ulen # check the length of the data buffer self assert_ len ua data nbytes # small check that data in array element is ok self assert_ ua_scalar self ucs_value self ulen # encode to utf numid$ and double check self assert_ ua_scalar encode strid$ self ucs_value self ulen encode strid$ # check buffer lengths for scalars if ucs4 self assert_ len buffer ua_scalar numid$ self ulen else if self ucs_value ucs4_value # in ucs2 the u0010ffff will be represented using a # surrogate pair self assert_ len buffer ua_scalar numid$ numid$ self ulen else # in ucs2 the uffff will be represented using a # regular numid$ byte word self assert_ len buffer ua_scalar numid$ self ulen <|EOS|>',\n",
       " '<|endoftext|> double dloss self double p double y c <|EOS|>',\n",
       " '<|endoftext|> setup self super realisticeventaccumulatortest self setup <|EOS|>',\n",
       " '<|endoftext|> _num_fromflags flaglist num numid$ for val in flaglist num _flagdict val return num <|EOS|>',\n",
       " '<|endoftext|> check_multi_functions self mod ext_tools ext_module strid$ var_specs code strid$ test ext_tools ext_function_from_specs strid$ code var_specs mod add_function test test2 ext_tools ext_function_from_specs strid$ code var_specs mod add_function test2 mod compile location build_dir import module_multi_function module_multi_function test module_multi_function test2 <|EOS|>',\n",
       " '<|endoftext|> test_mysql_extended self # inner skip to avoid module level query for mysql version if not connection features needs_explain_extended raise unittest skiptest strid$ qs tag objects filter name strid$ with capturequeriescontext connection as captured_queries qs explain format strid$ self assertequal len captured_queries numid$ self assertnotin strid$ captured_queries numid$ strid$ with capturequeriescontext connection as captured_queries qs explain format strid$ self assertequal len captured_queries numid$ self assertnotin strid$ captured_queries numid$ strid$ @skipifdbfeature strid$ class explainunsupportedtests testcase <|EOS|>',\n",
       " '<|endoftext|> ault time zone is different than # the time zone in new_connection settings_dict we can # get the <|EOS|>',\n",
       " '<|endoftext|> int x_indptr_ptr int x_indptr data c <|EOS|>',\n",
       " '<|endoftext|> main unused_argv global n_words # prepare training and testing data dbpedia learn datasets load_dataset strid$ test_with_fake_data flags test_with_fake_data x_train pandas dataframe dbpedia train data numid$ y_train pandas series dbpedia train target x_test pandas dataframe dbpedia test data numid$ y_test pandas series dbpedia test target # process vocabulary vocab_processor learn preprocessing vocabularyprocessor max_document_length x_train np array list vocab_processor fit_transform x_train x_test np array list vocab_processor transform x_test n_words len vocab_processor vocabulary_ print strid$ n_words # build model a single direction gru with a single layer classifier learn tensorflowrnnclassifier rnn_size embedding_size n_classes numid$ cell_type strid$ input_op_fn input_op_fn num_layers numid$ bidirectional false sequence_length none steps numid$ optimizer strid$ learning_rate numid$ numid$ continue_training true # train and predict classifier fit x_train y_train steps numid$ y_predicted classifier predict x_test score metrics accuracy_score y_test y_predicted print strid$ format score if __name__ strid$ parser argparse argumentparser parser add_argument strid$ <|EOS|>',\n",
       " '<|endoftext|> __init__ self appname dllname none logtype strid$ handler __init__ self try import win32evtlogutil win32evtlog self appname appname self _welu win32evtlogutil if not dllname import os dllname os path split self _welu __file__ dllname os path split dllname numid$ dllname os path join dllname numid$ rstrid$ self dllname dllname self logtype logtype self _welu addsourcetoregistry appname dllname logtype self <|EOS|>',\n",
       " '<|endoftext|> ine rank var var ## _rank # <|EOS|>',\n",
       " '<|endoftext|> _floatformat data precision suppress_small sign numid$ exp_format numid$ non_zero _uf absolute _ogen compress _uf not_equal data numid$ data ##non_zero _numeric_compress data ## if len non_zero numid$ max_val numid$ min_val numid$ else max_val max_reduce non_zero min_val min_reduce non_zero if max_val numid$ e8 exp_format numid$ if not suppress_small and min_val numid$ numid$ or max_val min_val numid$ exp_format numid$ if exp_format large_exponent numid$ min_val 1e numid$ or max_val 1e100 max_str_len numid$ precision large_exponent if sign format strid$ else format strid$ format format str max_str_len strid$ str precision strid$ if large_exponent format format strid$ else format strid$ str precision strid$ precision min precision max tuple map lambda x p precision f format _digits x p f data max_str_len len str int max_val precision numid$ if sign format strid$ else format strid$ format format str max_str_len strid$ str precision strid$ return format <|EOS|>',\n",
       " '<|endoftext|> handle_uncaught_exception self request resolver exc_info strid$strid$strid$ # therestrid$internal server errorstrid$text plain async <|EOS|>',\n",
       " '<|endoftext|> strid$unexpected sstrid$for strid$ <|EOS|>',\n",
       " '<|endoftext|> double impurity_improvement self double impurity nogil strid$strid$strid$ c <|EOS|>',\n",
       " '<|endoftext|> ault numid$ numid$ the initial learning rate used it controls the step size in updating the weights attributes learning_rate float the current learning rate strid$ <|EOS|>',\n",
       " '<|endoftext|> _multiarraymodule type <|EOS|>',\n",
       " '<|endoftext|> test_insert_returning self with capturequeriescontext connection as captured_queries dumbcategory objects create self assertin strid$ connection ops quote_name dumbcategory _meta db_table connection ops quote_name dumbcategory _meta get_field strid$ column captured_queries numid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> test_related_objects_local self result_key strid$ for model expected in test_results result_key items objects field self _model model field for field in model _meta get_fields include_parents false if field auto_created and not field concrete self assertequal self _map_related_query_names objects expected <|EOS|>',\n",
       " '<|endoftext|> withattribute args attrdict strid$strid$customerstrid$rightstrid$ns1 classstrid$customerstrid$ns2 alignstrid$rightstrid$strid$ if args attrs args else attrs attrdict items attrs k v for k v in attrs <|EOS|>',\n",
       " '<|endoftext|> add_graph self graph_ <|EOS|>',\n",
       " '<|endoftext|> ault ``out none`` then the elements where the values are false will remain uninitialized kwargs for other keyword only arguments see the ref `ufunc docs ufuncs kwargs ` returns r ndarray or tuple of ndarray `r` will have the shape that the arrays in `x` broadcast to if `out` is provided it will be returned if not `r` will be allocated and may contain uninitialized values if the function has more than one output then the result will be a tuple of arrays strid$strid$strid$ the identity value data attribute containing the identity element for the ufunc if it has one if it does not the attribute value is none examples np add identity numid$ np multiply identity numid$ np power identity numid$ print np exp identity none strid$strid$strid$ the number of arguments data attribute containing the number of arguments the ufunc takes including optional ones notes typically this value will be one more than what you might expect because all ufuncs take the optional strid$ argument examples np add nargs numid$ np multiply nargs numid$ np power nargs numid$ np exp nargs numid$ strid$strid$strid$ the number of inputs data attribute containing the number of arguments the ufunc treats as input examples np add nin numid$ np multiply nin numid$ np power nin numid$ np exp nin numid$ strid$strid$strid$ the number of outputs data attribute containing the number of arguments the ufunc treats as output notes since all ufuncs can take output arguments this will always be at least numid$ examples np add nout numid$ np multiply nout numid$ np power nout numid$ np exp nout numid$ strid$strid$strid$ the number of types the number of numerical numpy types of which there are numid$ total on which the ufunc can operate see also numpy ufunc types examples np add ntypes numid$ np multiply ntypes numid$ np power ntypes numid$ np exp ntypes numid$ np remainder ntypes numid$ strid$strid$strid$ returns a list with types grouped input output data attribute listing the data type strid$ groupings the ufunc can deliver the data types are given using the character codes see also numpy ufunc ntypes examples np add types strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ np multiply types strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ np power types strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ np exp types strid$ strid$ strid$ strid$ strid$ strid$ strid$ np remainder types strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> placeholder_inputs batch_size strid$strid$strid$ # note that the shapes of the placeholders match the shapes of the full # image and label tensors except the first dimension is now batch_size # rather than the full size of the train or test data sets images_placeholder tf placeholder tf float32 shape batch_size mnist image_pixels labels_placeholder tf placeholder tf int32 shape batch_size return images_placeholder labels_placeholder <|EOS|>',\n",
       " '<|endoftext|> inition strid$for model first_m2m or model second_m2m strid$first_m2mstrid$e016strid$clash between accessors for model second_m2m and model first_m2m strid$add or change a related_name argument to the <|EOS|>',\n",
       " '<|endoftext|> test_phone2numeric03 self output render strid$ strid$ strid$ self assertequal output strid$ from django test import simpletestcase from django utils safestring import mark_safe from utils import render setup class randomtests simpletestcase @setup strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> ault_initializer list_genome_ <|EOS|>',\n",
       " '<|endoftext|> test_with_m2m_multijoin self qs author objects annotate favorite_books_written_by_jane filteredrelation strid$ condition q favorite_books__author self author2 filter favorite_books_written_by_jane__editor__name strid$ distinct self assertsequenceequal qs self author1 <|EOS|>',\n",
       " '<|endoftext|> from_filename cls filename namespace none encoding none <|EOS|>',\n",
       " '<|endoftext|> _test_confirm_start self # start by creating the email response self client post strid$ strid$ strid$ self assertequal len mail outbox numid$ return self _read_signup_email mail outbox numid$ <|EOS|>',\n",
       " '<|endoftext|> svm_model model c <|EOS|>',\n",
       " '<|endoftext|> state_size self return numid$ <|EOS|>',\n",
       " '<|endoftext|> ghijklmnopstrid$numid$strid$numid$strid$numid$strid$t day numid$ strid$ wrong_location # 2nd gen numid$ is invalid strid$ wrong_bday # 2nd gen numid$ is invalid date strid$ wrong_checksum #2nd gen self assertfieldoutput cnidcardfield valid invalid <|EOS|>',\n",
       " '<|endoftext|> resize_image_with_crop_or_pad image target_height target_width strid$strid$strid$ _check3dimage image original_height original_width _ _imagedimensions image if target_width numid$ raise valueerror strid$ if target_height numid$ raise valueerror strid$ offset_crop_width numid$ offset_pad_width numid$ if target_width original_width offset_crop_width int original_width target_width numid$ elif target_width original_width offset_pad_width int target_width original_width numid$ offset_crop_height numid$ offset_pad_height numid$ if target_height original_height offset_crop_height int original_height target_height numid$ elif target_height original_height offset_pad_height int target_height original_height numid$ # maybe crop if needed cropped crop_to_bounding_box image offset_crop_height offset_crop_width min target_height original_height min target_width original_width # maybe pad if needed resized pad_to_bounding_box cropped offset_pad_height offset_pad_width target_height target_width if resized get_shape ndims is none raise valueerror strid$ if not resized get_shape numid$ is_compatible_with target_height raise valueerror strid$ if not resized get_shape numid$ is_compatible_with target_width raise valueerror strid$ return resized class resizemethod object bilinear numid$ nearest_neighbor numid$ bicubic numid$ area numid$ <|EOS|>',\n",
       " '<|endoftext|> _check_inputs self features targets if self _features_info is not none if not tensor_signature tensors_compatible features self _features_info raise valueerror strid$ strid$ str features str self _features_info else self _features_info tensor_signature create_signatures features if self _targets_info is not none if not tensor_signature tensors_compatible targets self _targets_info raise valueerror strid$ strid$ str targets str self _targets_info else self _targets_info tensor_signature create_signatures targets <|EOS|>',\n",
       " '<|endoftext|> join_tokens tokens trim false message strid$ join tokens if trim message trim_whitespace message return message for t in lexer src tokenize if incomment if t token_type token_block and t contents strid$ content strid$ join comment translators_comment_start none for lineno line in enumerate content splitlines true if line lstrip startswith translator_comment_mark translators_comment_start lineno for lineno line in enumerate content splitlines true if translators_comment_start is not none and lineno translators_comment_start out write strid$ line else out write strid$ incomment false comment else comment append t contents elif intrans if t token_type token_block endbmatch endblock_re match t contents pluralmatch plural_re match t contents if endbmatch if inplural if message_context out write strid$ format message_context join_tokens singular trimmed join_tokens plural trimmed p raw_prefix else out write strid$ format join_tokens singular trimmed join_tokens plural trimmed p raw_prefix for part in singular out write blankout part strid$ for part in plural out write blankout part strid$ else if message_context out write strid$ format message_context join_tokens singular trimmed p raw_prefix else out write strid$ format join_tokens singular trimmed p raw_prefix for part in singular out write blankout part strid$ message_context none intrans false inplural false singular plural elif pluralmatch inplural true else filemsg strid$ if origin filemsg strid$ origin raise syntaxerror strid$ strid$ t contents filemsg t lineno elif t token_type token_var if inplural plural append strid$ t contents else singular append strid$ t contents elif t token_type token_text contents t contents replace strid$ strid$ if inplural plural append contents else singular append contents else # handle comment tokens ` # # ` plus other constructs on # the same line if comment_lineno_cache is not none cur_lineno t lineno t contents count strid$ if comment_lineno_cache cur_lineno if t token_type token_comment for c in lineno_comment_map comment_lineno_cache filemsg strid$ if origin filemsg strid$ origin warn_msg strid$ strid$ strid$ c filemsg comment_lineno_cache warnings warn warn_msg translatorcommentwarning lineno_comment_map comment_lineno_cache else out write strid$ strid$ join lineno_comment_map comment_lineno_cache comment_lineno_cache none if t token_type token_block imatch inline_re match t contents bmatch block_re match t contents cmatches constant_re findall t contents if imatch g imatch group numid$ if g numid$ strid$ elif g numid$ strid$ g g strip strid$ g g replace strid$ strid$ if imatch group numid$ # a context is provided context_match context_re match imatch group numid$ message_context context_match group numid$ if message_context numid$ strid$ elif message_context numid$ strid$ message_context message_context strip strid$ out write strid$ format message_context g p raw_prefix message_context none else out write strid$ format g p raw_prefix elif bmatch for fmatch in constant_re findall t contents out write strid$ fmatch if bmatch group numid$ # a context is provided context_match context_re match bmatch group numid$ message_context context_match group numid$ if message_context numid$ strid$ elif message_context numid$ strid$ message_context message_context strip strid$ intrans true inplural false trimmed strid$ in t split_contents singular plural elif cmatches for cmatch in cmatches out write strid$ cmatch elif t contents strid$ incomment true else out write blankout t contents strid$ elif t token_type token_var parts t contents split strid$ cmatch constant_re match parts numid$ if cmatch out write strid$ cmatch group numid$ for p in parts numid$ if p find strid$ numid$ out write strid$ p split strid$ numid$ numid$ else out write blankout p strid$ elif t token_type token_comment if t contents lstrip startswith translator_comment_mark lineno_comment_map set <|EOS|>',\n",
       " '<|endoftext|> __str__ self return repr self pk class foo models model bar models foreignkey bar # coding utf numid$ from __future__ import unicode_literals from django db import transaction integrityerror from django test import testcase skipifdbfeature from django utils import six from models import employee business bar foo class custompktests testcase <|EOS|>',\n",
       " '<|endoftext|> add_item self title link description author_email none author_name none pubdate none comments none unique_id none enclosure none strid$strid$strid$ self items append strid$ title strid$ link strid$ description strid$ author_email strid$ author_name strid$ pubdate strid$ comments strid$ unique_id strid$ enclosure <|EOS|>',\n",
       " '<|endoftext|> _generate_sample_from_state self state random_state none pass <|EOS|>',\n",
       " '<|endoftext|> object discrete_broadcast_d void func void state object size object lock np ndarray a_arr object a_name constraint_type a_constraint c <|EOS|>',\n",
       " '<|endoftext|> ault supervisor supervisor graph init_op init_op or supervisor use_ <|EOS|>',\n",
       " '<|endoftext|> test_escapejs02 self output render strid$ strid$ strid$ self assertequal output strid$ strid$ strid$ from django test import simpletestcase from django utils safestring import mark_safe from utils import render setup class firsttests simpletestcase @setup strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> testbasic self with self test_session as sess # countupto will raise out_of_range when it reaches the count zero64 tf constant numid$ dtype tf int64 var tf variable zero64 count_up_to var count_up_to numid$ queue tf fifoqueue numid$ tf float32 tf initialize_all_variables run qr tf train queuerunner queue count_up_to threads qr create_threads sess for t in threads t start for t in threads t join self assertequal numid$ len qr exceptions_raised # the variable should be numid$ self assertequal numid$ var eval <|EOS|>',\n",
       " '<|endoftext|> itype_t i1 i2 if x shape numid$ y shape numid$ raise valueerror strid$ c <|EOS|>',\n",
       " '<|endoftext|> exclude self args kwargs strid$ return self _filter_or_exclude qnot args kwargs <|EOS|>',\n",
       " '<|endoftext|> collect_members module_to_name strid$strid$strid$ members for module module_name in module_to_name items all_names getattr module strid$ none for name member in inspect getmembers module if inspect isfunction member or inspect isclass member and not _always_drop_symbol_re match name and all_names is none or name in all_names fullname strid$ module_name name if name in members other_fullname other_member members name if member is not other_member raise runtimeerror strid$ fullname other_fullname if len fullname len other_fullname raise runtimeerror strid$ strid$ fullname other_fullname name len fullname if len fullname len other_fullname continue # use the shorter full name members name fullname member return members <|EOS|>',\n",
       " '<|endoftext|> __setstate__ self state self state state <|EOS|>',\n",
       " '<|endoftext|> ault graph args file_pattern list of files or pattern of file paths containing `example` records see `tf gfile glob` for pattern rules batch_size an int or scalar `tensor` specifying the batch size to use features a `dict` mapping feature keys to `fixedlenfeature` or `varlenfeature` values reader a function or class that returns an object with `read` method filename tensor example tensor randomize_input whether the input should be randomized queue_capacity capacity for input queue num_threads the number of threads enqueuing examples name name of resulting op returns a dict of `tensor` or `sparsetensor` objects for each in `features` raises valueerror for invalid inputs strid$ examples read_batch_examples file_pattern batch_size reader randomize_input queue_capacity num_threads name name # parse features into tensors return parsing_ops parse_example examples features <|EOS|>',\n",
       " '<|endoftext|> input_op_fn x # convert indexes of words into embeddings # this creates embeddings matrix of n_words embedding_size and then # maps word indexes of the sequence into batch_size sequence_length # embedding_size word_vectors skflow ops categorical_variable x n_classes n_words embedding_size embedding_size name strid$ # split into list of embedding per word while removing doc length dim # word_list results to be a list of tensors batch_size embedding_size word_list skflow ops split_squeeze numid$ max_document_length word_vectors return word_list # single direction gru with a single layer classifier skflow tensorflowrnnclassifier rnn_size embedding_size n_classes numid$ cell_type strid$ input_op_fn input_op_fn num_layers numid$ bidirectional false sequence_length none steps numid$ optimizer strid$ learning_rate numid$ numid$ continue_training true # continously train for numid$ steps predict on test set while true classifier fit x_train y_train logdir strid$ score metrics accuracy_score y_test classifier predict x_test print strid$ format score # copyright numid$ present scikit flow authors all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license strid$strid$character level convolutional networks for text classificationstrid$strid$ import numpy as np from sklearn import metrics import pandas import tensorflow as tf from tensorflow contrib import skflow ### training data # download dbpedia_csv tar gz from # https drive google com folderview id 0bz8a_dbh9qhbfll6bvpmnutucfdjymf2sepmzuzucvnimuw1twn6rdv3a0jht3kxlvhvr2m # unpack tar xvf dbpedia_csv tar gz train pandas read_csv strid$ header none x_train y_train train numid$ train numid$ test pandas read_csv strid$ header none x_test y_test test numid$ test numid$ ### process vocabulary max_document_length numid$ char_processor skflow preprocessing byteprocessor max_document_length x_train np array list char_processor fit_transform x_train x_test np array list char_processor transform x_test ### models n_filters numid$ filter_shape1 numid$ numid$ filter_shape2 numid$ n_filters pooling_window numid$ pooling_stride numid$ <|EOS|>',\n",
       " '<|endoftext|> test_query_filter self dt1 datetime datetime numid$ numid$ numid$ numid$ numid$ numid$ tzinfo eat dt2 datetime datetime numid$ numid$ numid$ numid$ numid$ numid$ tzinfo eat event objects create dt dt1 event objects create dt dt2 self assertequal event objects filter dt__gte dt1 count numid$ self assertequal event objects filter dt__gt dt1 count numid$ self assertequal event objects filter dt__gte dt2 count numid$ self assertequal event objects filter dt__gt dt2 count numid$ @skipif pytz is none strid$ <|EOS|>',\n",
       " '<|endoftext|> test_has_changed_last_widget self strid$strid$strid$ self asserttrue self field has_changed strid$ strid$ strid$ strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> ault_db_alias <|EOS|>',\n",
       " '<|endoftext|> aultstrid$loaddatastrid$db_fixture_2strid$ <|EOS|>',\n",
       " '<|endoftext|> keys self strid$strid$strid$ return self __tokdict keys <|EOS|>',\n",
       " '<|endoftext|> np ndarray alpha_arr val_arr c <|EOS|>',\n",
       " '<|endoftext|> mth self return numid$ a a r t a assert r numid$ `r` r t a mth assert r numid$ `r` if __name__ strid$ #import libwadpy status numid$ try repeat f2py_opts f2py2e f2py_testing cmdline test_functions build f2py_opts f2py2e f2py_testing run runtest test_functions repeat print strid$ status numid$ finally if status print strid$ numid$ print strid$ import f2py2e diagnose f2py2e diagnose run __usage__ strid$strid$strid$ import sys import f2py2e from numeric import array <|EOS|>',\n",
       " '<|endoftext|> test_boolean_field_doesnt_accept_empty_input self f models booleanfield with self assertraises validationerror f clean none none <|EOS|>',\n",
       " '<|endoftext|> input_fn return strid$ tf constant strid$ strid$ strid$ strid$ tf constant numid$ numid$ numid$ numid$ numid$ numid$ strid$ tf constant numid$ numid$ numid$ numid$ numid$ numid$ strid$ tf sparsetensor values strid$ strid$ strid$ indices numid$ numid$ numid$ numid$ numid$ numid$ shape numid$ numid$ strid$ tf constant numid$ numid$ numid$ numid$ numid$ numid$ tf constant numid$ numid$ numid$ price tf contrib layers real_valued_column strid$ sq_footage_bucket tf contrib layers bucketized_column tf contrib layers real_valued_column strid$ boundaries numid$ numid$ numid$ numid$ country tf contrib layers sparse_column_with_hash_bucket strid$ hash_bucket_size numid$ sq_footage_country tf contrib layers crossed_column sq_footage_bucket country hash_bucket_size numid$ svm_classifier tf contrib learn svm feature_columns price sq_footage_bucket country sq_footage_country example_id_column strid$ weight_column_name strid$ l1_regularization numid$ numid$ l2_regularization numid$ numid$ svm_classifier fit input_fn input_fn steps numid$ accuracy svm_classifier evaluate input_fn input_fn steps numid$ strid$ self assertalmostequal accuracy numid$ numid$ places numid$ if __name__ strid$ tf test main # copyright numid$ the tensorflow authors all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # strid$strid$strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function import numpy as np import tensorflow as tf class atrousconv2dtest tf test testcase <|EOS|>',\n",
       " '<|endoftext|> run_once self strid$strid$strid$ return list self run num_batches numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> ault_val shared_name # initialize with keys and values tensors keys tf constant strid$ strid$ strid$ values tf constant numid$ numid$ numid$ tf int64 init table initialize_from keys values init run input_string tf constant numid$ numid$ numid$ tf int64 with self assertraises typeerror table lookup input_string with self assertraises typeerror tf hashtable tf string tf int64 strid$ shared_name <|EOS|>',\n",
       " '<|endoftext|> test_lagone self assert_equal lag lagone numid$ <|EOS|>',\n",
       " '<|endoftext|> proto dest_nodes a list of strings specifying the destination node names returns the graph <|EOS|>',\n",
       " '<|endoftext|> cluster cluster_ <|EOS|>',\n",
       " '<|endoftext|> _get_frame level numid$ try return sys _getframe level numid$ except attributeerror # python numid$ numid$ support frame sys exc_info numid$ tb_frame for i in range level numid$ frame frame f_back return frame <|EOS|>',\n",
       " '<|endoftext|> initions on second level strid$ strid$ strid$ # two level with double quotes instead of single quotes strid$ strid$ strid$ # three level with variable parent template name strid$ strid$ strid$ strid$ strid$ # two level with one block <|EOS|>',\n",
       " '<|endoftext|> test_path_reverse_with_parameter self url reverse strid$ kwargs strid$ numid$ strid$ numid$ strid$ numid$ self assertequal url strid$ @override_settings root_urlconf strid$ <|EOS|>',\n",
       " '<|endoftext|> render self data output strid$ str_data_list map str data # normalize to strings for value choice in self choices checked_html strid$ if str value in str_data_list checked_html strid$ field_name strid$ self field_name value output append strid$ form_field_id_prefix field_name self __class__ __name__ field_name checked_html form_field_id_prefix field_name choice output append strid$ return strid$ join output #################### # file uploads # #################### class fileuploadfield formfield <|EOS|>',\n",
       " '<|endoftext|> inition e g strid$ for this field field_output style sql_field qn f column style sql_coltype col_type # oracle treats the empty string strid$ as null so coerce the null # option whenever strid$ is a possible value null f null if f empty_strings_allowed and not f primary_key and self connection features interprets_empty_strings_as_nulls null true if not null field_output append style sql_keyword strid$ if f primary_key field_output append style sql_keyword strid$ elif f unique field_output append style sql_keyword strid$ if tablespace and f unique # we must specify the index tablespace inline because we # won t be generating a create index statement for this field tablespace_sql self connection ops tablespace_sql tablespace inline true if tablespace_sql field_output append tablespace_sql if f rel and f db_constraint ref_output pending self sql_for_inline_foreign_key_references model f known_models style if pending pending_references set <|EOS|>',\n",
       " '<|endoftext|> testirissummaries self iris datasets load_iris classifier learn tensorflowlinearclassifier n_classes numid$ classifier fit iris data iris target logdir strid$ score accuracy_score iris target classifier predict iris data self assertgreater score numid$ numid$ strid$ format score <|EOS|>',\n",
       " '<|endoftext|> __init__ self # list of formfield objects self fields <|EOS|>',\n",
       " '<|endoftext|> testmonomp3 self self _loadfileandtest strid$ strid$ numid$ numid$ numid$ numid$ self _loadfileandtest strid$ strid$ numid$ numid$ numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> __str__ self return self title strid$strid$strid$ __all__ strid$ try from base import geoip2 geoip2exception has_geoip2 true __all__ strid$ strid$ except importerror has_geoip2 false import os import socket import geoip2 database from django conf import settings from django core validators import ipv4_re from django utils import six from django utils ipv6 import is_valid_ipv6_address from resources import city country # creating the settings dictionary with any settings if needed geoip_settings strid$ getattr settings strid$ none strid$ getattr settings strid$ strid$ strid$ getattr settings strid$ strid$ class geoip2exception exception pass class geoip2 object # the flags for geoip memory caching # try mode_mmap_ext mode_mmap mode_file in that order mode_auto numid$ # use the c extension with memory map mode_mmap_ext numid$ # read from memory map pure python mode_mmap numid$ # read database as standard file pure python mode_file numid$ # load database into memory pure python mode_memory numid$ cache_options opt none for opt in numid$ numid$ numid$ numid$ numid$ # paths to the city country binary databases _city_file strid$ _country_file strid$ # initially pointers to geoip file references are null _city none _country none <|EOS|>',\n",
       " '<|endoftext|> main _ print strid$ print strid$ print strid$ print strid$ print strid$ print strid$ strid$ for thresh in numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ for n in numid$ numid$ numid$ for use_gpu in true false for m in numid$ numid$ for k in numid$ numid$ sparse_tensor_dense_vs_dense_matmul_benchmark thresh m k n false false use_gpu use_gpu # enable for large scale benchmarks these ones take a long time to run # # for use_gpu in true false # sparse_tensor_dense_vs_dense_matmul_benchmark # thresh numid$ numid$ m numid$ k numid$ n numid$ adjoint_a false # adjoint_b false use_gpu use_gpu skip_dense true if __name__ strid$ if strid$ in sys argv sys argv remove strid$ tf app run else tf test main # copyright numid$ google inc all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # strid$strid$strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function import csv import gzip import imghdr import json import mimetypes import os from six import bytesio from six moves import basehttpserver from six moves import urllib from six moves import xrange # pylint disable re <|EOS|>',\n",
       " '<|endoftext|> test_join02 self output render strid$ strid$ strid$ strid$ self assertequal output strid$ @setup strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> lmvnpdf obs means covars cvtype strid$ strid$ compute the log probability under a multivariate gaussian distribution parameters obs array_like shape o d list of d dimensional data points each row corresponds to a single data point means array_like shape c d list of d dimensional mean vectors for c gaussians each row corresponds to a single mean vector covars array_like list of c covariance parameters for each gaussian the shape depends on `cvtype` c if strid$ d d if strid$ c d if strid$ c d d if strid$ cvtype string type of the covariance parameters must be one of strid$ strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> alt_nnmf v r cost strid$ max_iter numid$ tol 1e numid$ r none strid$strid$norm2strid$s algorithm parameters v numid$ ndarray input matrix r integer nr of latent features cost one of strid$ minimise x as _2 <|EOS|>',\n",
       " '<|endoftext|> ault class mywidget8 mywidget1 class media css strid$ strid$ strid$ js strid$ strid$ w8 mywidget8 self assertequal str w8 media strid$strid$http media example com media path to css1strid$text cssstrid$allstrid$stylesheetstrid$ path to css2strid$text cssstrid$allstrid$stylesheetstrid$ path to css3strid$text cssstrid$allstrid$stylesheetstrid$text javascriptstrid$ path to js1strid$text javascriptstrid$http media other com path to js2strid$text javascriptstrid$https secure other com path to js3strid$text javascriptstrid$ path to js4strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> int j for j from numid$ j n_features sum w_data_ptr j x_data_ptr offset j return sum c <|EOS|>',\n",
       " '<|endoftext|> deserializer object_list options strid$strid$strid$ models get_apps for d in object_list # look up the model and starting build a dict of data for it model _get_model d strid$ data model _meta pk name d strid$ m2m_data # handle each field for field_name field_value in d strid$ iteritems if isinstance field_value unicode field_value field_value encode options get strid$ settings <|EOS|>',\n",
       " '<|endoftext|> _index_param_value x v indices strid$strid$strid$ if not _is_arraylike v or _num_samples v _num_samples x # pass through skip indexing return v if sp issparse v v v tocsr return safe_indexing v indices <|EOS|>',\n",
       " '<|endoftext|> encode_multipart boundary data strid$strid$strid$ lines for key value in data items if isinstance value file lines extend strid$ boundary strid$ key strid$ strid$ boundary strid$ key value name strid$ strid$ value read else lines extend strid$ boundary strid$ key strid$ str value lines extend strid$ boundary strid$ strid$ return strid$ join lines class client strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> ined by the strid$ clause syntax get_comment_count for pkg py_module_name context_var_containing_obj_id as varname example usage get_comment_count for lcom eventtimes event id as comment_count note context_var_containing_obj_id can also be a hard coded integer like this get_comment_count for lcom eventtimes numid$ as comment_count strid$ <|EOS|>',\n",
       " '<|endoftext|> save self name content strid$strid$strid$ # check for old style usage warn here first since there are multiple # locations where we need to support both new and old usage if isinstance content basestring import warnings warnings warn message strid$ strid$ category deprecationwarning stacklevel numid$ from django core files base import contentfile content contentfile content # get the proper name for the file as it will actually be saved if name is none name content name name self get_available_name name self _save name content # store filenames with forward slashes even on windows return force_unicode name replace strid$ strid$ # these methods are part of the public api with <|EOS|>',\n",
       " '<|endoftext|> current self strid$strid$strid$ return self _wizard storage current_step or self first @property <|EOS|>',\n",
       " '<|endoftext|> ault if `seed` is ``none`` then ``dsfmt`` will try to read entropy from `` dev urandom`` or the windows analog if available to produce a numid$ bit seed if unavailable a numid$ bit hash of the time and process id is used raises valueerror if seed values are out of range for the prng strid$ c <|EOS|>',\n",
       " '<|endoftext|> ault this verifies that the url is live on the internet and doesnstrid$http www google comstrid$s no internet connection ustrid$ f clean strid$ traceback most recent call last validationerror ustrid$ f clean strid$ # bad domain traceback most recent call last validationerror ustrid$ f clean strid$ # good domain bad page traceback most recent call last validationerror ustrid$ f urlfield verify_exists true required false f clean strid$ ustrid$ f clean strid$ # this will fail if therestrid$http www google comstrid$http f comstrid$ensure this value has at least numid$ characters it has numid$ strid$http example comstrid$http example comstrid$http abc <|EOS|>',\n",
       " '<|endoftext|> ppimport_attr module name strid$strid$strid$ if not isinstance module _moduleloader return getattr module name return _attrloader module name class _attrloader <|EOS|>',\n",
       " '<|endoftext|> _screen_draw_text_line self row line attr curses a_normal color none strid$strid$strid$ if not isinstance row int raise typeerror strid$ if len line self _max_x line line self _max_x if color is none self _stdscr addstr row numid$ line attr else self _stdscr addstr row numid$ line self _color_pairs color self _screen_refresh <|EOS|>',\n",
       " '<|endoftext|> test_view_flatpage self strid$ response self client get strid$ self assertequals response status_code numid$ self assertcontains response strid$ <|EOS|>',\n",
       " '<|endoftext|> test_float self floatmodel objects create f1 numid$ numid$ f2 numid$ numid$ obj floatmodel objects annotate f1_sqrt sqrt strid$ f2_sqrt sqrt strid$ first self assertisinstance obj f1_sqrt float self assertisinstance obj f2_sqrt float self assertalmostequal obj f1_sqrt math sqrt obj f1 self assertalmostequal obj f2_sqrt math sqrt obj f2 <|EOS|>',\n",
       " '<|endoftext|> convert_empty_values self value expression context # oracle stores empty strings as null we need to undo this in # order to adhere to the django convention of using the empty # string instead of null but only if the field accepts the # empty string field expression output_field if value is none and field empty_strings_allowed value strid$ if field get_internal_type strid$ value bstrid$ return value <|EOS|>',\n",
       " '<|endoftext|> render self context # build a unicode key for this fragment and all vary onstrid$ join self fragment_name force_unicode resolve_variable var context for var in self vary_on value cache get cache_key if value is none value self nodelist render context cache set cache_key value self expire_time return value <|EOS|>',\n",
       " '<|endoftext|> ghijklmnopqrstuvwxyz0123456789_strid$strid$ strid$ uppered s translate upper_table return uppered <|EOS|>',\n",
       " '<|endoftext|> test_lefthand_addition self # lh addition of floats and integers number objects filter pk self n pk update integer f strid$ numid$ float f strid$ numid$ numid$ self assertequal number objects get pk self n pk integer numid$ self assertequal number objects get pk self n pk float approximate numid$ numid$ places numid$ <|EOS|>',\n",
       " '<|endoftext|> __init__ self depth sample_indices sum_gradients sum_hessians parent none self depth depth self sample_indices sample_indices self n_samples sample_indices shape numid$ self sum_gradients sum_gradients self sum_hessians sum_hessians self parent parent <|EOS|>',\n",
       " '<|endoftext|> test_predict_on_toy_problem strid$strid$strid$ clf1 logisticregression random_state numid$ clf2 randomforestclassifier random_state numid$ clf3 gaussiannb x np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ y np array numid$ numid$ numid$ numid$ numid$ numid$ assert_equal all clf1 fit x y predict x all numid$ numid$ numid$ numid$ numid$ numid$ assert_equal all clf2 fit x y predict x all numid$ numid$ numid$ numid$ numid$ numid$ assert_equal all clf3 fit x y predict x all numid$ numid$ numid$ numid$ numid$ numid$ eclf votingclassifier estimators strid$ clf1 strid$ clf2 strid$ clf3 voting strid$ weights numid$ numid$ numid$ assert_equal all eclf fit x y predict x all numid$ numid$ numid$ numid$ numid$ numid$ eclf votingclassifier estimators strid$ clf1 strid$ clf2 strid$ clf3 voting strid$ weights numid$ numid$ numid$ assert_equal all eclf fit x y predict x all numid$ numid$ numid$ numid$ numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> testgetbad4 self strid$ self assertraises indexerror self array __getitem__ numid$ self ncols numid$ <|EOS|>',\n",
       " '<|endoftext|> __init__ self field self field field <|EOS|>',\n",
       " '<|endoftext|> ault strid$ type str choices strid$ strid$ help strid$ strid$ parser add_argument strid$ nargs strid$ <|EOS|>',\n",
       " '<|endoftext|> set self key value timeout numid$ self _cache set key value timeout <|EOS|>',\n",
       " '<|endoftext|> test_laplace self vals self rg laplace numid$ numid$ numid$ numid$ numid$ assert_ len vals numid$ <|EOS|>',\n",
       " '<|endoftext|> run verbosity numid$ strid$ texttestrunner verbosity verbosity run suite if __name__ strid$ run numid$ from django contrib gis geos import from random import random seq_length numid$ seq_range numid$ seq_length seq_length seq_bounds numid$ seq_length numid$ numid$ seq_length numid$ seq_out_of_bounds numid$ seq_length numid$ seq_length <|EOS|>',\n",
       " '<|endoftext|> stripped_op_list op numid$ meta_graph_ <|EOS|>',\n",
       " '<|endoftext|> aults_no_variables self with tf graph as_ <|EOS|>',\n",
       " '<|endoftext|> test_randint_broadcast self dtype if dtype np bool upper numid$ lower numid$ else info np iinfo dtype upper int info max numid$ lower info min self _reset_state a self rg randint lower upper numid$ dtype dtype self _reset_state b self rg randint lower numid$ upper dtype dtype assert_equal a b self _reset_state c self rg randint lower upper size numid$ dtype dtype assert_equal a c self _reset_state d self rg randint np array lower numid$ np array upper dtype np object size numid$ dtype dtype assert_equal a d self _reset_state e self rg randint np array lower numid$ np array upper numid$ size numid$ dtype dtype assert_equal a e self _reset_state a self rg randint numid$ upper size numid$ dtype dtype self _reset_state b self rg randint upper numid$ dtype dtype assert_equal a b <|EOS|>',\n",
       " '<|endoftext|> __getattr__ self name if name numid$ strid$ if hasattr self strid$ name attr getattr self strid$ name if type attr is types methodtype return lambda func self _try_call attr attr func attr else return lambda none raise attributeerror name <|EOS|>',\n",
       " '<|endoftext|> op_type name device none attrs none strid$ create a node <|EOS|>',\n",
       " '<|endoftext|> int void numid$ c <|EOS|>',\n",
       " '<|endoftext|> ine_string strid$ strid$ strid$ path to classify_image_graph_ <|EOS|>',\n",
       " '<|endoftext|> _dense_to_sparse dense dtype indices values max_row_len numid$ for row in dense max_row_len max max_row_len len row shape len dense max_row_len row_ix numid$ for row in dense col_ix numid$ for cell in row indices append row_ix col_ix values append str cell if dtype tf string else cell col_ix numid$ row_ix numid$ return tf sparsetensor tf constant indices tf int64 tf constant values dtype tf constant shape tf int64 class setopstest test_util tensorflowtestcase <|EOS|>',\n",
       " '<|endoftext|> createfuncwrapper rout signature numid$ assert isfunction rout ret strid$ <|EOS|>',\n",
       " '<|endoftext|> __init__ self alpha strict true strict_statistics true name strid$ strid$ initialize a batch of dirichlet distributions args alpha positive `float` or `double` tensor with shape broadcastable to ` n1 nm k ` `m numid$` <|EOS|>',\n",
       " '<|endoftext|> node self assertdeviceequal node device strid$ <|EOS|>',\n",
       " '<|endoftext|> inline dtype_t dist self dtype_t x1 dtype_t x2 itype_t size c <|EOS|>',\n",
       " '<|endoftext|> ined as a consequence # @override_settings doesn t work and the tests depend <|EOS|>',\n",
       " '<|endoftext|> test_builtin_command_with_attribute_error self strid$strid$strid$ self write_settings strid$ sdict strid$ strid$ args strid$ strid$ out err self run_manage args self assertnooutput out self assertoutput err strid$ class managevalidate adminscripttestcase <|EOS|>',\n",
       " '<|endoftext|> fadd line s fwrap s numid$ strid$ s numid$ line chooks strid$ <|EOS|>',\n",
       " '<|endoftext|> pk self return self instance _get_pk_val <|EOS|>',\n",
       " '<|endoftext|> ault none strid$ <|EOS|>',\n",
       " '<|endoftext|> int len_w problem csr_set_problem x_values data x_indices shape x_indices data x_indptr shape x_indptr data y data n_features bias param set_parameter solver_type eps c weight shape numid$ weight_label data weight data error_msg check_parameter problem param if error_msg free_problem problem free_parameter param raise valueerror error_msg # early return model train problem param # fortran order since that s what liblinear does c <|EOS|>',\n",
       " '<|endoftext|> inition for strid$ invalid_models target2 accessor for m2m field strid$ clashes with related field strid$ add a related_name argument to the <|EOS|>',\n",
       " '<|endoftext|> file parse_cmd #if <|EOS|>',\n",
       " '<|endoftext|> add_dependency self child parent self nodes child none self nodes parent none self dependencies set <|EOS|>',\n",
       " '<|endoftext|> shortdescription self if self _description is not none return self _description doc self _testfunc __doc__ return doc and doc split strid$ numid$ strip or none import os import sys from django utils unittest loader import <|EOS|>',\n",
       " '<|endoftext|> int maxd numid$ int log n introsort xf samples n maxd c <|EOS|>',\n",
       " '<|endoftext|> check_foo_string1 self level numid$ i string0 strid$ e string0 strid$ func m foostring1 assert isinstance i string0 `type i ` r func i assert isinstance r string0 `type r ` assert i is not r `id i id r ` assert_equal r e r func strid$ assert isinstance r string0 `type r ` assert_equal r e r func strid$ assert isinstance r string0 `type r ` assert_equal r e <|EOS|>',\n",
       " '<|endoftext|> initive guide to django web development done rightstrid$artificial intelligence a modern approachstrid$friends__idstrid$pkstrid$brad dayleystrid$book__idstrid$pkstrid$apressstrid$prentice hallstrid$numid$ numid$strid$book__idstrid$apressstrid$authors__idstrid$norvigstrid$artificial intelligence a modern approach lambda b b name <|EOS|>',\n",
       " '<|endoftext|> test_emailfield_not_required self f emailfield required false self assertequal strid$ f clean strid$ self assertequal strid$ f clean none self assertequal strid$ f clean strid$ self assertequal strid$ f clean strid$ self assertraisesmessage validationerror strid$ f clean strid$ <|EOS|>',\n",
       " '<|endoftext|> int num_points c <|EOS|>',\n",
       " '<|endoftext|> corriid theta d strid$strid$strid$ theta np asanyarray theta dtype np float d np asanyarray d dtype np float n_eval d shape numid$ r np zeros n_eval # the ones on the diagonal of the correlation matrix are enforced within # the krigingmodel instanciation to allow multiple design sites in this # ordinary least squares context return r <|EOS|>',\n",
       " '<|endoftext|> test_urlfield_5 self f urlfield min_length numid$ max_length numid$ self assertwidgetrendersto f strid$ self assertraisesmessage validationerror strid$ f clean strid$ self assertequal strid$ f clean strid$ self assertraisesmessage validationerror strid$ f clean http abc <|EOS|>',\n",
       " '<|endoftext|> ault min_samples_leaf int optional <|EOS|>',\n",
       " '<|endoftext|> inition and conventions used zero padding analogously with `ifft` is performed by appending zeros to the input along the specified dimension although this is the common approach it might lead to surprising results if another form of zero padding is desired it must be performed before `ifft2` is called examples a numid$ np eye numid$ np fft ifft2 a array numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j # may vary numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j numid$ numid$ j strid$ return _raw_fftnd a s axes ifft norm @array_function_dispatch _fftn_dispatcher <|EOS|>',\n",
       " '<|endoftext|> isunsigned var if not isscalar var return numid$ if var get strid$ strid$ return numid$ return get_kind var strid$ <|EOS|>',\n",
       " '<|endoftext|> ault is none returns out ndarray the truncated or zero padded input transformed along the axis indicated by `axis` or the last one if `axis` is not specified the length of the transformed axis is `n` or if `n` is not given ``numid$ m numid$ `` where ``m`` is the length of the transformed axis of the input to get an odd number of output points `n` must be specified raises indexerror if `axis` is larger than the last axis of `a` see also numpy fft for <|EOS|>',\n",
       " '<|endoftext|> ine f_wrappedfunc f f _f2pywrap##f##_ #endif #endif #else #if <|EOS|>',\n",
       " '<|endoftext|> check_lrap_error_raised lrap_score # raise value error if not appropriate format assert_raises valueerror lrap_score numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ assert_raises valueerror lrap_score numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ assert_raises valueerror lrap_score numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ # check that that y_true shape y_score shape raise the proper exception assert_raises valueerror lrap_score numid$ numid$ numid$ numid$ numid$ numid$ assert_raises valueerror lrap_score numid$ numid$ numid$ numid$ numid$ numid$ assert_raises valueerror lrap_score numid$ numid$ numid$ numid$ numid$ numid$ assert_raises valueerror lrap_score numid$ numid$ numid$ numid$ numid$ numid$ assert_raises valueerror lrap_score numid$ numid$ numid$ numid$ numid$ numid$ assert_raises valueerror lrap_score numid$ numid$ numid$ numid$ numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> assert_rank x rank data none summarize none name none strid$ assert `x` has rank equal to `rank` args x numeric `tensor` rank scalar `tensor` data the tensors to print out if the condition is false <|EOS|>',\n",
       " '<|endoftext|> test_einsum_sums_uint16 self self check_einsum_sums strid$ <|EOS|>',\n",
       " '<|endoftext|> strid$ strid$ device pydev device job strid$ self assertprotoequals strid$ node <|EOS|>',\n",
       " '<|endoftext|> floatformat text _ strid$strid$strid$ from math import modf if not text return strid$ if modf float text numid$ numid$ numid$ return text return strid$ float text <|EOS|>',\n",
       " '<|endoftext|> _set_post self post self _post post <|EOS|>',\n",
       " '<|endoftext|> execute self args strid$strid$strid$ if not args raise valueerror strid$ self info self generate dry_run false cmd sys executable strid$ list args self info strid$ self path self info strid$ strid$ join cmd r exec_command cmd execute_in self path use_tee false self info strid$ self path return r <|EOS|>',\n",
       " '<|endoftext|> test_template_loader_postmortem self response self client get reverse strid$ template_path os path join strid$ strid$ self assertcontains response template_path status_code numid$ class exceptionreportertests testcase rf requestfactory <|EOS|>',\n",
       " '<|endoftext|> iterkeys self return self _index iterkeys __iter__ iterkeys <|EOS|>',\n",
       " '<|endoftext|> test_circular_graph self strid$strid$strid$ # build graph graph migrationsgraph graph add_dependency strid$ strid$ strid$ strid$ graph add_dependency strid$ strid$ strid$ strid$ graph add_dependency strid$ strid$ strid$ strid$ graph add_dependency strid$ strid$ strid$ strid$ graph add_dependency strid$ strid$ strid$ strid$ # test whole graph self assertraises circulardependencyexception graph forwards_plan strid$ strid$ import os from django utils importlib import import_module from django db models loading import cache from django db migrations recorder import migrationrecorder from django db migrations graph import migrationgraph class migrationloader object strid$strid$migrationsstrid$replacingstrid$strid$ <|EOS|>',\n",
       " '<|endoftext|> __pos__ self return self <|EOS|>',\n",
       " '<|endoftext|> ined first_line int the first line of the code in the source file notes this function does a bit more magic than inspect and is thus more robust strid$ source_file none try # try to retrieve the source code source_file func func_code co_filename source_file_obj file source_file first_line func func_code co_firstlineno # all the lines after the function <|EOS|>',\n",
       " '<|endoftext|> check_index_split_simple self a arange numid$ indices numid$ numid$ numid$ res array_split a indices axis numid$ desired arange numid$ numid$ arange numid$ numid$ arange numid$ numid$ arange numid$ numid$ compare_results res desired <|EOS|>',\n",
       " '<|endoftext|> test_wrong_email_value_raises_error self mtv modeltovalidate number numid$ name strid$ email strid$ self assertfailsvalidation mtv full_validate strid$ <|EOS|>',\n",
       " '<|endoftext|> ined and backwards compatibility is not guaranteed references numid$ papoulis a strid$ 3rd ed new york mcgraw hill numid$ numid$ duda r o hart p e and stork d g strid$ 2nd ed new york wiley numid$ examples mean numid$ numid$ cov numid$ numid$ numid$ numid$ x randomgen multivariate_normal mean cov numid$ numid$ x shape numid$ numid$ numid$ the following is probably true given that numid$ numid$ is roughly twice the standard deviation list x numid$ numid$ mean numid$ numid$ true true strid$strid$mean must be numid$ dimensionalstrid$cov must be numid$ dimensional and squarestrid$mean and cov must have same length # compute shape of output and create a matrix of independent # standard normally distributed random numbers the matrix has rows # with the same length as mean and as many rows are necessary to # form a matrix of shape final_shape final_shape list shape final_shape append mean shape numid$ x self standard_normal final_shape reshape numid$ mean shape numid$ # transform matrix of standard normals into matrix where each row # contains multivariate normals with the desired covariance # compute a such that dot transpose a a cov # then the matrix products of the rows of x and a has the desired # covariance note that sqrt s v where u s v is the singular value # decomposition of cov is such an a # # also check that cov is positive semi <|EOS|>',\n",
       " '<|endoftext|> check_false self a none res inline_tools inline strid$ strid$ assert res numid$ class test_object_is_true unittest testcase <|EOS|>',\n",
       " '<|endoftext|> c_type sample_weight # helper variable for indexes c <|EOS|>',\n",
       " '<|endoftext|> _getsvdoptest dtype_ shape_ <|EOS|>',\n",
       " '<|endoftext|> ining parse actions that require matching at a specific column in the input text strid$ <|EOS|>',\n",
       " '<|endoftext|> check_1d self assert_array_equal r_ numid$ numid$ numid$ numid$ numid$ numid$ array numid$ numid$ numid$ numid$ numid$ numid$ b ones numid$ c r_ b numid$ numid$ b assert_array_equal c numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ c c_ b numid$ numid$ b assert_array_equal c numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> teardown self if self _sess is not none self _sess run self _close_op self _coord request_stop self _coord join self _threads <|EOS|>',\n",
       " '<|endoftext|> test_filter_varargs yield nose tools assert_equal filter_args h numid$ strid$ numid$ strid$ numid$ strid$ strid$ yield nose tools assert_equal filter_args h numid$ numid$ numid$ numid$ strid$ numid$ strid$ numid$ strid$ numid$ numid$ strid$ yield nose tools assert_equal filter_args h numid$ numid$ ee numid$ strid$ numid$ strid$ numid$ strid$ strid$ strid$ numid$ yield nose tools assert_equal filter_args h strid$ numid$ numid$ numid$ ee numid$ strid$ numid$ strid$ numid$ strid$ strid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> git_get_keywords versionfile_abs strid$strid$strid$ # the code embedded in _version py can just fetch the value of these # keywords when used from setup py we donstrid$ s strid$strid$ s strid$strid$ s strid$ line if mo keywords strid$ mo group numid$ f close except environmenterror pass return keywords @register_vcs_handler strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> s strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function import copy import tensorflow as tf from google protobuf import text_format from tensorflow python framework import graph_util <|EOS|>',\n",
       " '<|endoftext|> ault_manager count numid$ self assertin strid$ out getvalue <|EOS|>',\n",
       " '<|endoftext|> test_no_context self strid$ response self client get strid$ # check that the no template case doesnstrid$get templatestrid$get templatestrid$get templatestrid$abc except assertionerror as e self assertin strid$ str e <|EOS|>',\n",
       " '<|endoftext|> file might contain library mylib dll exports cool_function1 cool_function2 alternatively you may be able to use the storage class specifier __declspec dllexport in the c <|EOS|>',\n",
       " '<|endoftext|> __rdiv__ self other strid$ return divide other self <|EOS|>',\n",
       " '<|endoftext|> test_sparse_randomized_pca_inverse strid$strid$strid$ np random seed numid$ n p numid$ numid$ x randn n p # spherical data x numid$ numid$ # make middle component relatively small # no large means because the sparse version of randomized pca does not do # centering to avoid breaking the sparsity x csr_matrix x # same check that we can find the original data from the transformed signal # since the data is almost of rank n_components pca randomizedpca n_components numid$ fit x y pca transform x y_inverse pca inverse_transform y assert_almost_equal x todense y_inverse decimal numid$ # same as above with whitening approximate reconstruction pca randomizedpca n_components numid$ whiten true fit x y pca transform x y_inverse pca inverse_transform y relative_max_delta np abs x todense y_inverse np abs x mean max # xxx this does not seam to work as expected assert_almost_equal relative_max_delta numid$ numid$ decimal numid$ <|EOS|>',\n",
       " '<|endoftext|> iter_coords i ret while not i finished ret append i coords i iternext return ret <|EOS|>',\n",
       " '<|endoftext|> ault numid$ else val new_data get self name self get_ <|EOS|>',\n",
       " '<|endoftext|> int n_samples batch shape numid$ c <|EOS|>',\n",
       " '<|endoftext|> test_floordiv self tgt ch chebyshev numid$ assert_ self p4 self p1 tgt assert_ self p4 numid$ numid$ numid$ tgt assert_ numid$ numid$ numid$ self p1 tgt <|EOS|>',\n",
       " '<|endoftext|> get_choices for i in range numid$ yield i i self assertequal w render strid$ numid$ choices get_choices strid$strid$radiostrid$numstrid$numid$strid$radiostrid$numstrid$numid$strid$checkedstrid$radiostrid$numstrid$numid$strid$radiostrid$numstrid$numid$strid$radiostrid$numstrid$numid$strid$strid$ # you can also pass strid$ to the constructor w radioselect choices numid$ numid$ numid$ numid$ numid$ numid$ self assertequal w render strid$ numid$ strid$strid$radiostrid$numstrid$numid$strid$checkedstrid$radiostrid$numstrid$numid$strid$radiostrid$numstrid$numid$strid$strid$ # if strid$ is passed to both the constructor and render then theystrid$numstrid$beatlestrid$jstrid$jstrid$johnstrid$pstrid$paulstrid$gstrid$georgestrid$rstrid$ringostrid$ s br strid$ p s s p strid$ s s s s sstrid$ nstrid$ nstrid$ nstrid$ n join inp_set4 strid$strid$strid$ # you can create your own custom renderers for radioselect to use class myrenderer radiofieldrenderer <|EOS|>',\n",
       " '<|endoftext|> test_post_view_flatpage self strid$ response self client post strid$ self assertequal response status_code numid$ <|EOS|>',\n",
       " '<|endoftext|> __repr__ self return strid$ self __class__ __name__ strid$ join map repr self name self rctype c for c l in self components class cheader cline strid$strid$noddy hstrid$strid$ template strid$ class cstdheader cheader template strid$ class csource filesource strid$ s csource strid$ print s generate #doctest ellipsis c this file strid$ is generated using extgen tool from numpy version extgen is developed by pearu peterson pearu peterson@gmail com for more information see http www scipy org extgen #if <|EOS|>',\n",
       " '<|endoftext|> inition in the inheritance hierarchy technically it would generate a valid form but the fact that the resulting save method wonstrid$headlinestrid$slugstrid$pub_datestrid$writerstrid$articlestrid$categoriesstrid$status <|EOS|>',\n",
       " '<|endoftext|> __str__ self return self url class clearablefileinputtest widgettest widget clearablefileinput <|EOS|>',\n",
       " '<|endoftext|> _attr op iteritems node attr k copyfrom v func node extend node # pylint disable line too long <|EOS|>',\n",
       " '<|endoftext|> size_t end self end c <|EOS|>',\n",
       " '<|endoftext|> test_pt_br_redirect self response self client get strid$ http_accept_language strid$ self assertredirects response strid$ response self client get response strid$ self assertequal response status_code numid$ <|EOS|>',\n",
       " '<|endoftext|> ault_verbose self settings copy copy galg <|EOS|>',\n",
       " '<|endoftext|> np int_t j c <|EOS|>',\n",
       " '<|endoftext|> attr key attr_ <|EOS|>',\n",
       " '<|endoftext|> eightbitize_bias_add_node self original_node strid$strid$strid$ quantized_bias_add_name original_node name strid$ all_input_names self add_eightbit_prologue_nodes original_node quantized_bias_add_node create_node strid$ quantized_bias_add_name all_input_names set_attr_dtype quantized_bias_add_node strid$ tf quint8 set_attr_dtype quantized_bias_add_node strid$ tf quint8 set_attr_dtype quantized_bias_add_node strid$ tf qint32 self add_output_graph_node quantized_bias_add_node quantize_down_name self add_quantize_down_node original_node quantized_bias_add_name self add_dequantize_result_node quantize_down_name original_node name <|EOS|>',\n",
       " '<|endoftext|> testview self strid$ for i in range self nrows for j in range self ncols self array i j i j a self array view self failunless isinstance a np ndarray self failunless a flags f_contiguous for i in range self nrows for j in range self ncols self failunless a i j i j ###################################################################### if __name__ strid$ # build the test suite suite unittest testsuite suite addtest unittest makesuite farraytestcase # execute the test suite print strid$ print strid$ np __version__ print result unittest texttestrunner verbosity numid$ run suite sys exit bool result errors result failures # usr bin env python from __future__ import division absolute_import print_function # system imports from distutils util import get_platform import os import sys import unittest # import numpy import numpy as np major minor int d for d in np __version__ split strid$ numid$ if major numid$ badlisterror typeerror else badlisterror valueerror import fortran ###################################################################### class fortrantestcase unittest testcase <|EOS|>',\n",
       " '<|endoftext|> test_make_list03 self output render strid$ strid$ mark_safe strid$ self assertequal output str_prefix strid$ @setup strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> inition source_lines list itertools islice source_file_obj first_line numid$ none return strid$ join inspect getblock source_lines source_file first_line except # if the source code fails we use the hash this is fragile and # might change from one session to another if hasattr func strid$ return str func func_code __hash__ source_file numid$ else # weird objects like numpy ufunc don t have func_code # this is fragile as quite often the id of the object is # in the repr so it might not persist accross sessions # however it will work for ufuncs return repr func source_file numid$ <|EOS|>',\n",
       " '<|endoftext|> test_custom_command_with_settings self strid$ args strid$ strid$ out err self run_manage args self assertnooutput out self assertoutput err strid$ <|EOS|>',\n",
       " '<|endoftext|> check_x_y3 self x y numid$ numid$ numid$ numid$ desired self desired_type numid$ numid$ self generic_test x y desired <|EOS|>',\n",
       " '<|endoftext|> testinsertmany self with self test_session b data_flow_ops barrier tf float32 tf float32 shapes name strid$ size_t b ready_size self assertequal size_t get_shape keys bstrid$ bstrid$ bstrid$ insert_0_op b insert_many numid$ keys numid$ numid$ numid$ numid$ numid$ numid$ insert_1_op b insert_many numid$ keys numid$ numid$ numid$ numid$ numid$ numid$ self assertequals size_t eval numid$ insert_0_op run self assertequals size_t eval numid$ insert_1_op run self assertequals size_t eval numid$ <|EOS|>',\n",
       " '<|endoftext|> test_process_request_bad_middleware_not_found self pre_middleware testmiddleware bad_middleware badrequestmiddleware post_middleware testmiddleware self _add_middleware post_middleware self _add_middleware bad_middleware self _add_middleware pre_middleware self assert_exceptions_handled strid$ strid$ # check that the right middleware methods have been invoked self assert_middleware_usage pre_middleware true false false true false self assert_middleware_usage bad_middleware true false false true false self assert_middleware_usage post_middleware false false false true false <|EOS|>',\n",
       " '<|endoftext|> __init__ self n_clusters svd_method mini_batch kmeans_kwargs random_state self n_clusters n_clusters self svd_method svd_method self mini_batch mini_batch self kmeans_kwargs kmeans_kwargs self random_state random_state <|EOS|>',\n",
       " '<|endoftext|> output_exception try type value tb sys exc_info info traceback extract_tb tb #this is more verbose #traceback print_exc filename lineno function text info numid$ # last line only print strid$ filename lineno type __name__ str value function finally type value tb none # clean up return class _dummy_stream <|EOS|>',\n",
       " '<|endoftext|> test_regexfield_4 self f regexfield strid$ error_message strid$ self assertequal strid$ f clean strid$ self assertraisesmessage validationerror strid$ f clean strid$ self assertraisesmessage validationerror strid$ f clean strid$ <|EOS|>',\n",
       " '<|endoftext|> inition in json format strid$strid$run is requiredstrid$text plain <|EOS|>',\n",
       " '<|endoftext|> type_match self value return type value in dicttype <|EOS|>',\n",
       " '<|endoftext|> test_exclude self b8 book objects create title strid$ pubdate datetime numid$ numid$ numid$ b9 book objects create title strid$ pubdate datetime numid$ numid$ numid$ b10 book objects create title strid$ pubdate datetime numid$ numid$ numid$ # exclude is the opposite of filter when doing lookups self assertquerysetequal book objects filter title__contains strid$ exclude title__contains strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ self assertquerysetequal book objects exclude title__startswith strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ self assertquerysetequal book objects exclude title strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> delete_file filename with errors raise_exception_on_not_ok_status as status pywrap_tensorflow deletefile compat as_bytes filename status <|EOS|>',\n",
       " '<|endoftext|> _set_union self a b # validate that we get the same results with or without `validate_indices` ops tf contrib metrics set_union a b validate_indices true tf contrib metrics set_union a b validate_indices false with self test_session as sess results sess run ops self assertallequal results numid$ indices results numid$ indices self assertallequal results numid$ values results numid$ values self assertallequal results numid$ shape results numid$ shape return results numid$ <|EOS|>',\n",
       " '<|endoftext|> test_url_params_from_lookup_dict_any_iterable self lookup1 widgets url_params_from_lookup_dict strid$ strid$ strid$ lookup2 widgets url_params_from_lookup_dict strid$ strid$ strid$ self assertequal lookup1 strid$ strid$ self assertequal lookup1 lookup2 class filteredselectmultiplewidgettest djangotestcase <|EOS|>',\n",
       " '<|endoftext|> test_no_delimiter self strid$ strg strid$ test linesplitter strg assert_equal test strid$ strid$ strid$ strid$ strid$ test linesplitter strid$ strg assert_equal test strid$ strid$ strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> test_ticket7095 self # updates that are filtered on the model being updated are somewhat # tricky in mysql this exercises that case managedmodel objects create data strid$ tag self t1 public true self assertequal managedmodel objects update data strid$ numid$ # a values or values_list query across joined models must use outer # joins appropriately # note in oracle we expect a null charfield to return strid$ instead of # none if connection features interprets_empty_strings_as_nulls expected_null_charfield_repr strid$ else expected_null_charfield_repr none self assertvaluequerysetequal report objects values_list strid$ flat true order_by strid$ strid$ strid$ expected_null_charfield_repr # similarly for select_related joins beyond an initial nullable join # must use outer joins so that all results are included self assertquerysetequal report objects select_related strid$ strid$ order_by strid$ strid$ strid$ strid$ # when there are multiple paths to a table from another table we have # to be careful not to accidentally reuse an inappropriate join when # using select_related we used to return the parentstrid$d2 <|EOS|>',\n",
       " '<|endoftext|> ault value of n_estimators <|EOS|>',\n",
       " '<|endoftext|> lasso_path x y eps 1e numid$ n_alphas numid$ alphas none precompute strid$ xy none fit_intercept true normalize false overwrite_x false verbose false params strid$ compute lasso path with coordinate descent parameters x numpy array of shape n_samples n_features training data pass directly as fortran contiguous data to avoid unnecessary memory duplication y numpy array of shape n_samples target values eps float optional length of the path eps 1e numid$ means that alpha_min alpha_max 1e numid$ n_alphas int optional number of alphas along the regularization path alphas numpy array optional list of alphas where to compute the models if none alphas are set automatically precompute true false strid$ array like whether to use a precomputed gram matrix to speed up calculations if set to strid$ let us decide the gram matrix can also be passed as argument xy array like optional xy np dot x t y that can be precomputed it is useful only when the gram matrix is precomuted fit_intercept bool fit or not an intercept normalize boolean optional if true the regressors x are normalized overwrite_x boolean optionnal if true x will not be copied <|EOS|>',\n",
       " '<|endoftext|> testsomeerrors self with tf graph as_ <|EOS|>',\n",
       " '<|endoftext|> predict_proba self x strid$strid$strid$ self probas_ self _get_probas x avg np average self probas_ axis numid$ weights self weights return avg <|EOS|>',\n",
       " '<|endoftext|> int i int left int right int middle for i in prange data shape numid$ schedule strid$ nogil true left right numid$ binning_thresholds shape numid$ while left right middle right left numid$ numid$ if data i binning_thresholds middle right middle else left middle numid$ binned i left # cython cdivision true # cython boundscheck false # cython wraparound false # cython language_level numid$ # author nicolas hug cimport cython from cython parallel import prange import numpy as np cimport numpy as np from types import y_dtype from types cimport y_dtype_c <|EOS|>',\n",
       " '<|endoftext|> cs_int func strid$ func argtypes cs_ptr pointer c_uint func restype c_int func errcheck check_cs_get return func <|EOS|>',\n",
       " '<|endoftext|> l2 xs return np array np sqrt numid$ numid$ x numid$ numid$ for x in xs <|EOS|>',\n",
       " '<|endoftext|> test_smacof # test metric smacof using the data of strid$ # borg groenen p numid$ sim np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ z np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ x mds smacof sim init z p numid$ max_iter numid$ x_true np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ assert_array_almost_equal x x_true decimal numid$ <|EOS|>',\n",
       " '<|endoftext|> check_float self code strid$strid$strid$ res inline_tools inline code assert sys getrefcount res numid$ assert res numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> ault as g g device test_device_func_pin_variable_to_cpu with g device strid$ const_0 constant_op constant numid$ numid$ with g device strid$ const_1 constant_op constant numid$ numid$ with g device strid$ const_2 constant_op constant numid$ numid$ with g device strid$ const_3 constant_op constant numid$ numid$ with g device strid$ const_4 constant_op constant numid$ numid$ with g device strid$ const_5 constant_op constant numid$ numid$ self assertdeviceequal const_0 device strid$ self assertdeviceequal const_1 device strid$ self assertdeviceequal const_2 device strid$ self assertdeviceequal const_3 device strid$ self assertdeviceequal const_4 device strid$ self assertdeviceequal const_5 device strid$ <|EOS|>',\n",
       " '<|endoftext|> g return abc <|EOS|>',\n",
       " '<|endoftext|> _nearest_cluster_distance y d i strid$strid$strid$ label y i b np min np mean d j for j in range len d if y j cur_label for cur_label in set y if not cur_label label return b import numpy as np from numpy import linalg from numpy testing import assert_true from import datasets from unsupervised import silhouette_coefficient from pairwise import pairwise_distance <|EOS|>',\n",
       " '<|endoftext|> summary_str session run supervisor summary_op if summary_str # todo wicke we should assert that the global step hasnstrid$got exception during tf learn training loop possibly strid$due to exhausted input queue s e if should_stop and tuner is not none try tuner report_done except exception as e # todo mdan vizier should allow softer application error reporting tuner report_done infeasible true infeasible_reason e raise return eval_results should_stop <|EOS|>',\n",
       " '<|endoftext|> __init__ self charset strid$ preprocessor <|EOS|>',\n",
       " '<|endoftext|> _isdst self dt tt dt year dt month dt day dt hour dt minute dt second dt weekday numid$ numid$ stamp _time mktime tt tt _time localtime stamp return tt tm_isdst numid$ utc pytz utc if pytz else utc strid$strid$strid$ # in order to avoid accessing the settings at compile time # wrap the expression in a function and cache the result # if you change settings time_zone in tests reset _localtime to none _localtime none <|EOS|>',\n",
       " '<|endoftext|> build_with_make self kw pass <|EOS|>',\n",
       " '<|endoftext|> render_to_response_view request return render_to_response strid$ strid$ strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> weight_column_name self return self _weight_column_name @property <|EOS|>',\n",
       " '<|endoftext|> np ndarray double ndim numid$ norm_cols_x x numid$ sum axis numid$ # initial value of the residuals c <|EOS|>',\n",
       " '<|endoftext|> __call__ self parser token tokens token contents split if len tokens numid$ raise template templatesyntaxerror strid$ self tag_name if tokens numid$ strid$ raise template templatesyntaxerror strid$ self tag_name try package module tokens numid$ split strid$ except valueerror # unpack list of wrong size raise template templatesyntaxerror strid$ self tag_name try content_type contenttypes get_object package__label__exact package python_module_name__exact module except contenttypes contenttypedoesnotexist raise template templatesyntaxerror strid$ self tag_name package module obj_id_lookup_var obj_id none none if tokens numid$ isdigit obj_id tokens numid$ try # ensure the object id is valid content_type get_object_for_this_type id__exact obj_id except objectdoesnotexist raise template templatesyntaxerror strid$ self tag_name content_type name obj_id else obj_id_lookup_var tokens numid$ kwargs if len tokens numid$ if tokens numid$ strid$ raise template templatesyntaxerror strid$ self tag_name for option args in zip tokens numid$ numid$ tokens numid$ numid$ if option in strid$ strid$ and not self free # validation ############################################## option_list args split strid$ if len option_list numid$ numid$ raise template templatesyntaxerror strid$ self tag_name for opt in option_list numid$ if not opt isalnum raise template templatesyntaxerror strid$ self tag_name opt for opt in option_list numid$ numid$ option_list numid$ numid$ if not opt isdigit or not comments min_photo_dimension int opt comments max_photo_dimension raise template templatesyntaxerror strid$ self tag_name opt comments min_photo_dimension comments max_photo_dimension # validation ends ######################################### kwargs option true kwargs strid$ args elif option in strid$ strid$ and not self free # validation ############################################## if numid$ len args split strid$ numid$ raise template templatesyntaxerror strid$ option self tag_name if re match strid$ args split strid$ numid$ raise template templatesyntaxerror strid$ self tag_name option # validation ends ######################################### kwargs option true kwargs strid$ args elif option in strid$ kwargs option args strid$ else raise template templatesyntaxerror strid$ self tag_name option return commentformnode content_type obj_id_lookup_var obj_id self free kwargs class docommentcount strid$ gets comment count for the given params and populates the template context with a variable containing that value whose name is <|EOS|>',\n",
       " '<|endoftext|> exp_decay global_step return tf train exponential_decay learning_rate numid$ numid$ global_step decay_steps numid$ decay_rate numid$ numid$ tf_random_seed random seed for tensorflow initializers setting this value allows consistency between reruns continue_training when continue_training is true once initialized model will be continuely trained on every call of fit early_stopping_rounds activates early stopping if this is not none loss needs to decrease at least every every early_stopping_rounds round s to continue training <|EOS|>',\n",
       " '<|endoftext|> file parse_cmd #if <|EOS|>',\n",
       " '<|endoftext|> test_zipf self random seed self seed actual random zipf a numid$ numid$ size numid$ numid$ desired np array numid$ numid$ numid$ numid$ numid$ numid$ assert_array_equal actual desired class testbroadcast object # tests that functions that broadcast behave # correctly when presented with non scalar arguments <|EOS|>',\n",
       " '<|endoftext|> is_deletion self return self action_flag deletion <|EOS|>',\n",
       " '<|endoftext|> streaming_mean_squared_error predictions labels weights none metrics_collections none updates_collections none name none strid$strid$strid$ predictions labels _remove_squeezable_dimensions predictions labels predictions get_shape assert_is_compatible_with labels get_shape squared_error math_ops square labels predictions return streaming_mean squared_error weights metrics_collections updates_collections name or strid$ <|EOS|>',\n",
       " '<|endoftext|> build_import_library strid$strid$strid$ if os name strid$ return lib_name strid$ tuple sys version_info numid$ lib_file os path join sys prefix strid$ lib_name out_name strid$ tuple sys version_info numid$ out_file os path join sys prefix strid$ out_name if not os path isfile lib_file log warn strid$ lib_file return if os path isfile out_file log debug strid$ out_file return log info strid$ out_file from scipy distutils import lib2 <|EOS|>',\n",
       " '<|endoftext|> testrejectiondatalistinput self initial_p numid$ numid$ numid$ numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> benchmark_dense_predict print strid$ issparse clf coef_ for _ in range numid$ clf predict x_test @profile <|EOS|>',\n",
       " '<|endoftext|> test_foreignkey self with self assertnumqueries numid$ qs authorwithage objects prefetch_related strid$ addresses unicode address for address in obj addresses all for obj in qs self assertequals addresses unicode self authoraddress <|EOS|>',\n",
       " '<|endoftext|> test_override_with_multiple_roles self self assertequals parse_color_setting strid$ dict palettes light_palette error strid$ strid$ sql_field strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> test_gaussian_suffstat_sk_spherical # computing spherical covariance equals to the variance of one dimension # data after flattening n_components numid$ rng np random randomstate numid$ n_samples n_features numid$ numid$ x rng rand n_samples n_features x x x mean resp np ones n_samples numid$ nk np array n_samples xk x mean covars_pred_spherical _estimate_gaussian_covariance_spherical resp x nk xk numid$ covars_pred_spherical2 np dot x flatten t x flatten n_features n_samples assert_almost_equal covars_pred_spherical covars_pred_spherical2 <|EOS|>',\n",
       " '<|endoftext|> test_sort self sorted_dicts dictsortreversed strid$ numid$ strid$ strid$ strid$ numid$ strid$ strid$ strid$ strid$ strid$ numid$ strid$ self assertequal sorted dict items for dict in sorted_dicts strid$ numid$ strid$ strid$ strid$ numid$ strid$ strid$ strid$ numid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> _maketags tagstr xml strid$strid$strid$ if isinstance tagstr __base_string__ resname tagstr tagstr keyword tagstr caseless not xml else resname tagstr name tagattrname word alphas alphanums strid$ if xml tagattrvalue dblquotedstring copy setparseaction removequotes opentag suppress strid$ tagstr dict zeroormore group tagattrname suppress strid$ tagattrvalue optional strid$ <|EOS|>',\n",
       " '<|endoftext|> test_get_flatpages_tag_for_user self strid$ me user objects create_user strid$ strid$ strid$ out template strid$ strid$ strid$ strid$ strid$ render context strid$ me self assertequal out strid$ <|EOS|>',\n",
       " '<|endoftext|> ault if `seed` is ``none`` then the `mt19937` basicrng is initialized by reading data from `` dev urandom`` or the windows analogue if available or seed from the clock otherwise notes the python stdlib module strid$ also contains a mersenne twister pseudo random number generator with a number of methods that are similar to the ones available in `randomstate` `randomstate` besides being numpy aware has the advantage that it provides a much larger number of probability distributions to choose from strid$ c <|EOS|>',\n",
       " '<|endoftext|> int64_t randoms_data c <|EOS|>',\n",
       " '<|endoftext|> create_superuser self email password date_of_birth u self create_user email password password date_of_birth date_of_birth u is_admin true u save using self _db return u class customuser abstractbaseuser email models emailfield verbose_name strid$ max_length numid$ unique true is_active models booleanfield <|EOS|>',\n",
       " '<|endoftext|> get_doctest self string globs name filename lineno strid$strid$strid$ return doctest self get_examples string name globs name filename lineno string <|EOS|>',\n",
       " '<|endoftext|> fit self x y return self @pytest mark parametrize strid$ kmeans strid$ numid$ strid$ linearregression strid$ numid$ strid$ strid$ strid$ gradientboostingclassifier random_state numid$ strid$ numid$ strid$ strid$ strid$ strid$ strid$ gradientboostingclassifier random_state numid$ strid$ numid$ strid$ strid$ strid$ strid$ strid$ gradientboostingclassifier random_state numid$ strid$ numid$ strid$ strid$ strid$ nopredictprobanodecisionfunction strid$ numid$ strid$ strid$ strid$ nopredictprobanodecisionfunction strid$ numid$ strid$ strid$ strid$ nopredictprobanodecisionfunction strid$ numid$ strid$ strid$ strid$ linearregression strid$ numid$ strid$ strid$ strid$ linearregression strid$ numid$ strid$ strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> test_fftn self x random numid$ numid$ numid$ 1j random numid$ numid$ numid$ assert_array_almost_equal np fft fft np fft fft np fft fft x axis numid$ axis numid$ axis numid$ np fft fftn x assert_array_almost_equal np fft fftn x np sqrt numid$ numid$ numid$ np fft fftn x norm strid$ <|EOS|>',\n",
       " '<|endoftext|> ault func <|EOS|>',\n",
       " '<|endoftext|> test_ticket7076 self # excluding shouldnstrid$namestrid$ item four strid$ item three strid$ item two strid$ tag t1 strid$ tag t4 strid$ tag t5 <|EOS|>',\n",
       " '<|endoftext|> is_available self self version none # works i think only for unix #print strid$ self ver_cmd exit_status out_text run_command self ver_cmd #print exit_status out_text if not exit_status m re match self ver_match out_text if m self version m group strid$ return self version <|EOS|>',\n",
       " '<|endoftext|> strid$numid$ nastrid$bcstrid$dstrid$strid$ <|EOS|>',\n",
       " '<|endoftext|> test_ignore_comments self self asserthtmlequal strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> get_slug_field self strid$strid$strid$ return self slug_field <|EOS|>',\n",
       " '<|endoftext|> fast_cache self code function strid$strid$strid$ try if self cache code numid$ function return except # keyerror indexerror pass try self cache code remove function except valueerror pass # put new function at the beginning of the list to search self cache code insert numid$ function <|EOS|>',\n",
       " '<|endoftext|> ault_directory_index_template strid$strid$ w3c dtd xhtml numid$ numid$ transitional enstrid$http www w3 org tr xhtml1 dtd xhtml1 transitional dtdstrid$http www w3 org numid$ xhtmlstrid$enstrid$enstrid$content typestrid$text html charset utf numid$strid$content languagestrid$en usstrid$ f strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> __str__ self tab self get_indent_tab s strid$ if self expr is not none s strid$ self expr if self name s strid$ self name return tab s <|EOS|>',\n",
       " '<|endoftext|> process_item self line self item get_line m self match line assert m `line` items split_comma line m end strip self item for n in items if not is_name n self isvalid false return self items items return <|EOS|>',\n",
       " '<|endoftext|> strid$ for tag in tags meta_graph_ <|EOS|>',\n",
       " '<|endoftext|> testconstructor self with tf graph as_ <|EOS|>',\n",
       " '<|endoftext|> method_get_order ordered_obj self cursor connection cursor # example strid$ sql strid$ backend quote_name ordered_obj _meta pk column backend quote_name ordered_obj _meta db_table backend quote_name ordered_obj _meta order_with_respect_to column backend quote_name strid$ rel_val getattr self ordered_obj _meta order_with_respect_to rel field_name cursor execute sql rel_val return r numid$ for r in cursor fetchall ############################################## # helper functions curried model functions # ############################################## <|EOS|>',\n",
       " '<|endoftext|> ault strid$ prefix strid$ skip_prefix_when_empty true ignore_empty_content true scalarinitializer dict <|EOS|>',\n",
       " '<|endoftext|> test_func self lexer jslexer result strid$ name tok for name tok in lexer lex input if name strid$ self assertlistequal result toks return test_func for i input toks in enumerate jstokenstest lex_cases setattr jstokenstest strid$ i make_function input toks gettext_cases rstrid$strid$strid$ rstrid$strid$strid$ rstrid$strid$strid$ rstrid$strid$strid$ rstrid$strid$hellostrid$strid$ rstrid$strid$hellostrid$strid$ rstrid$strid$hello strid$ s strid$ s strid$ strid$strid$strid$ s strid$ s strid$ s strid$ strid$strid$strid$ s strid$ hello strid$strid$strid$ s strid$ strid$ strid$strid$strid$ var regex pattern var regex2 matter gm var regex3 gm foo strid$ strid$strid$strid$ var regex strid$ var regex2 strid$ var regex3 strid$ foo strid$ strid$strid$strid$ for var x a in foo strid$ mot z x numid$ x numid$ y g i xyz x for var x a in foo strid$ mot z x numid$ x numid$ y g i xyz x strid$strid$strid$ for var x a in foo strid$ mot z strid$ i xyz x for var x a in foo strid$ mot z x numid$ x numid$ y strid$ xyz x strid$strid$strid$ u1234xyz gettext strid$ strid$strid$strid$ uu1234xyz gettext strid$ strid$ class jstocforgettexttest testcase pass <|EOS|>',\n",
       " '<|endoftext|> test_one_bin self # ticket numid$ hist edges histogram numid$ numid$ numid$ numid$ numid$ numid$ assert_array_equal hist numid$ assert_array_equal edges numid$ numid$ assert_raises valueerror histogram numid$ numid$ bins numid$ h e histogram numid$ numid$ bins numid$ assert_equal h np array numid$ assert_allclose e np array numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> int j numid$ c <|EOS|>',\n",
       " '<|endoftext|> test_form_stepback self response self client get reverse self wizard_urlname kwargs strid$ strid$ self assertequal response status_code numid$ self assertequal response context strid$ strid$ current strid$ response self client post reverse self wizard_urlname kwargs strid$ strid$ self wizard_step_data numid$ response self client get response strid$ self assertequal response status_code numid$ self assertequal response context strid$ strid$ current strid$ response self client post reverse self wizard_urlname kwargs strid$ response context strid$ strid$ current strid$ response context strid$ strid$ prev response self client get response strid$ self assertequal response status_code numid$ self assertequal response context strid$ strid$ current strid$ <|EOS|>',\n",
       " '<|endoftext|> ault_fill_value self return self _fill_value <|EOS|>',\n",
       " '<|endoftext|> test_standard_login_url self self assertloginurlequals strid$ @override_settings login_url strid$ <|EOS|>',\n",
       " '<|endoftext|> test_simple self duration datetime timedelta hours numid$ minutes numid$ seconds numid$ self assertequal parse_duration duration_string duration duration <|EOS|>',\n",
       " '<|endoftext|> _module_get_security_hash options photo_options rating_options target strid$strid$strid$ from django conf settings import secret_key import md5 return md5 new options photo_options rating_options target secret_key hexdigest <|EOS|>',\n",
       " '<|endoftext|> test_password_change_fails_with_invalid_old_password self self login response self client post strid$ strid$ strid$ strid$ strid$ strid$ strid$ self assertformerror response passwordchangeform error_messages strid$ <|EOS|>',\n",
       " '<|endoftext|> parse_paths config if not config has_section <|EOS|>',\n",
       " '<|endoftext|> ine f_modfuncname m f __ ## m ## _mod_ ## f #else # <|EOS|>',\n",
       " '<|endoftext|> test_custom_form_meta_exclude self strid$ ensure that the custom modelform s `meta exclude` is respected by `genericinlinemodeladmin get_formset` and overridden if `modeladmin exclude` or `genericinlinemodeladmin exclude` are <|EOS|>',\n",
       " '<|endoftext|> testbucketizedcolumn self bucket tf contrib layers bucketized_column tf contrib layers real_valued_column strid$ boundaries numid$ numid$ numid$ # buckets numid$ numid$ numid$ features strid$ tf constant numid$ numid$ numid$ output tf contrib layers input_from_feature_columns features bucket expected numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ with self test_session self assertallclose output eval expected <|EOS|>',\n",
       " '<|endoftext|> _trim_1d data trim left strid$ nsize data size ncounts data count ntrim int trim ncounts idxsort data argsort if left data idxsort ntrim masked else data idxsort ncounts nsize ntrim masked return data # data masked_array data copy false subok true data unshare_mask # if not isinstance tail str raise typeerror strid$ tail tail lower numid$ if tail strid$ left true elif tail strid$ left false else raise valueerror strid$ # if axis is none return _trim_1d data ravel proportiontocut left else assert data ndim numid$ strid$ return apply_along_axis _trim_1d axis data proportiontocut left # <|EOS|>',\n",
       " '<|endoftext|> __getitem__ self n return self _str n <|EOS|>',\n",
       " '<|endoftext|> testbasic3tensor self x np asarray true false true false false true false true false false false true # ensure rowmajor mode truth np asarray numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ dtype np int64 self _testwhere x truth if __name__ strid$ tf test main strid$strid$strid$ import tensorflow python platform import numpy as np import tensorflow as tf from tensorflow python kernel_tests import gradient_checker as gc class xenttest tf test testcase <|EOS|>',\n",
       " '<|endoftext|> get_app_paths self strid$strid$strid$ warnings warn strid$ pendingdeprecationwarning stacklevel numid$ self populate_models app_paths for app in self get_apps app_paths append self _get_app_path app return app_paths <|EOS|>',\n",
       " '<|endoftext|> aultstrid$ <|EOS|>',\n",
       " '<|endoftext|> ault if `seed` is ``none`` then ``xoroshiro128`` will try to read data from `` dev urandom`` or the windows analog if available if unavailable a numid$ bit hash of the time and process id is used notes xoroshiro128 is the successor to xorshift128 written by david blackman and sebastiano vigna it is a numid$ bit prng that uses a carefully handcrafted shift rotate based linear transformation this change both improves speed and statistical quality of the prng numid$ _ xoroshiro128 has a period of math `numid$ numid$ numid$` and supports jumping the sequence in increments of math `numid$ numid$ ` which allows multiple non overlapping sequences to be generated ``xoroshiro128`` exposes no user facing api except ``generator`` ``state`` ``cffi`` and ``ctypes`` designed for use in a ``randomgenerator`` object compatibility guarantee ``xoroshiro128`` guarantees that a fixed seed will always produce the same results see ``xorshift1024`` for an related prng implementation with a larger period math `numid$ numid$ numid$` and jump size math `numid$ numid$ numid$` parallel features ``xoroshiro128`` can be used in parallel applications by calling the method ``jump`` which advances the state as if math `numid$ numid$ ` random numbers have been generated this allow the original sequence to be split so that distinct segments can be used in each worker process all generators should be initialized with the same seed to ensure that the segments come from the same sequence from numpy random import randomgenerator xoroshiro128 rg randomgenerator xoroshiro128 numid$ for _ in range numid$ # advance each xoroshiro128 instance by i jumps for i in range numid$ rg i brng jump i state and seeding the ``xoroshiro128`` state vector consists of a numid$ element array of numid$ bit unsigned integers ``xoroshiro128`` is seeded using either a single numid$ bit unsigned integer or a vector of numid$ bit unsigned integers in either case the input seed is used as an input or inputs for another simple random number generator splitmix64 and the output of this prng function is used as the initial state using a single numid$ bit value for the seed can only initialize a small range of the possible initial state values when using an array the splitmix64 state for producing the ith component of the initial state is xord with the ith value of the seed array until the seed array is exhausted when using an array the initial state for the splitmix64 state is numid$ so that using a single element array and using the same value as a scalar will produce the same initial state examples from numpy random import randomgenerator xoroshiro128 rg randomgenerator xoroshiro128 numid$ rg standard_normal numid$ numid$ # random identical method using only xoroshiro128 rg xoroshiro128 numid$ generator rg standard_normal numid$ numid$ # random references numid$ strid$ http xorshift di unimi it strid$ c <|EOS|>',\n",
       " '<|endoftext|> test_unsupported_type self assert_raises typeerror self rfunc numid$ dtype float <|EOS|>',\n",
       " '<|endoftext|> test_full_range self # test for ticket #numid$ for dt in self itype lbnd numid$ if dt is np bool_ else np iinfo dt min ubnd numid$ if dt is np bool_ else np iinfo dt max numid$ try self rfunc lbnd ubnd dtype dt except exception as e raise assertionerror strid$ strid$ strid$ str e <|EOS|>',\n",
       " '<|endoftext|> ault_signature exporter regression_signature input_tensor examples output_tensor score # todo zakaria add validation return <|EOS|>',\n",
       " '<|endoftext|> testthrees self strid$ print self typestr strid$ end strid$ file sys stderr threes vector __dict__ self typestr strid$ vector threes numid$ self assertequals vector numid$ numid$ numid$ numid$ numid$ numid$ all true # test the type argout_array1 int dim1 typemap <|EOS|>',\n",
       " '<|endoftext|> parseimpl self instring loc doactions true if loc numid$ # see if entire string up to here is just whitespace and ignoreables if loc self preparse instring numid$ # raise parseexception instring loc strid$ exc self myexception exc loc loc exc pstr instring raise exc return loc class stringend _positiontoken strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> predict self dataset strid$strid$strid$ z self predictor predict x for x in dataset return n asarray z squeeze <|EOS|>',\n",
       " '<|endoftext|> double result_memview result c <|EOS|>',\n",
       " '<|endoftext|> _quantiles1d data m p x numpy sort data compressed n len x if n numid$ return masked_array numpy empty len p dtype float_ mask true elif n numid$ return masked_array numpy resize x p shape mask nomask aleph n p m k numpy floor aleph clip numid$ n numid$ astype int_ gamma aleph k clip numid$ numid$ return numid$ gamma x k numid$ tolist gamma x k tolist # initialization checks data masked_array data copy false p narray prob copy false ndmin numid$ m alphap p numid$ alphap betap # computes quantiles along axis or globally if axis is none return _quantiles1d data m p else assert data ndim numid$ strid$ return apply_along_axis _quantiles1d axis data m p <|EOS|>',\n",
       " '<|endoftext|> setup self self save_warnings_state warnings filterwarnings strid$ category deprecationwarning module strid$ <|EOS|>',\n",
       " '<|endoftext|> _zseries_int zs strid$ integrate a z series the integral is with respect to x not z this is achieved by a change of variable using dx dz given in the module notes parameters zs z series the z series to integrate returns integral z series the in <|EOS|>',\n",
       " '<|endoftext|> test_2d_diag self data np random randn 1e1 numid$ mu np array numid$ numid$ numid$ numid$ va np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ y mnormalik data mu va log true a1 logsumexp y a2 self naive_logsumexp y assert_array_almost_equal a1 a2 x x numid$ np linspace numid$ numid$ numid$ np newaxis x numid$ np concatenate np linspace numid$ numid$ numid$ np newaxis np linspace numid$ numid$ numid$ np newaxis axis numid$ x numid$ np concatenate np linspace numid$ numid$ numid$ np newaxis np linspace numid$ numid$ numid$ np newaxis axis numid$ mu va mu numid$ np array numid$ va numid$ np array numid$ mu numid$ np array numid$ numid$ va numid$ np array numid$ numid$ mu numid$ np array numid$ numid$ numid$ numid$ va numid$ np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ y y numid$ np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ y numid$ np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ y numid$ np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ class testnormallikelihood testcase <|EOS|>',\n",
       " '<|endoftext|> ault false when set to true reuse the solution of the previous call to fit as initialization otherwise just erase the previous solution attributes `classes_` array or list of array of shape n_classes class labels for each output `cost_` float the current cost value computed by the loss function `label_binarizer_` labelbinarizer a labelbinarizer object trained on the training set `layers_coef_` list length n_layers numid$ the ith element in the list represents the weight matrix corresponding to layer i `layers_intercept_` list length n_layers numid$ the ith element in the list represents the bias vector corresponding to layer i numid$ `learning_rate_` float the current learning rate n_iter_ int the current number of iterations the algorithm has ran n_layers_ int number of layers `n_outputs_` int number of outputs `out_activation_` string name of the output activation function notes multilayerperceptronclassifier trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters it can also use regularizer as a penalty term added to the loss function that shrinks model parameters towards zero this implementation works with data represented as dense and sparse numpy arrays of floating point values for the features references hinton geoffrey e strid$ artificial intelligence numid$ numid$ numid$ numid$ numid$ glorot xavier and yoshua bengio strid$ international conference on artificial intelligence and statistics numid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> test_dependency_sorting_dangling self sorted_deps sort_dependencies strid$ person circle1 store book self assertequal sorted_deps circle1 store person book <|EOS|>',\n",
       " '<|endoftext|> ault models created to satisfy <|EOS|>',\n",
       " '<|endoftext|> start self strid$strid$strid$ self _server start <|EOS|>',\n",
       " '<|endoftext|> exp_decay global_step return tf train exponential_decay learning_rate numid$ numid$ global_step decay_steps numid$ decay_rate numid$ numid$ continue_training when continue_training is true once initialized model will be continuely trained on every call of fit config runconfig object that controls the configurations of the session e g num_cores gpu_memory_fraction etc verbose controls the verbosity possible values numid$ the algorithm and debug information is muted numid$ trainer prints the progress numid$ log device placement is printed dropout when not none the probability we will drop out a given coordinate strid$ <|EOS|>',\n",
       " '<|endoftext|> test_initialization_class_attributes self strid$strid$initializationstrid$strid$ conn connections <|EOS|>',\n",
       " '<|endoftext|> test_fetch_openml_miceprotein monkeypatch # jvr very important check as this dataset <|EOS|>',\n",
       " '<|endoftext|> compare all_dict others names module_name strid$strid$strid$ only_all set for name in all_dict if name not in names for pat in refguide_autosummary_skiplist if re match pat module_name strid$ name break else only_all add name only_ref set missing set for name in names if name not in all_dict for pat in refguide_all_skiplist if re match pat module_name strid$ name if name not in others missing add name break else only_ref add name return only_all only_ref missing <|EOS|>',\n",
       " '<|endoftext|> test_ignore self strid$strid$strid$ self assertfilenotfound strid$ <|EOS|>',\n",
       " '<|endoftext|> ined in the model s inner meta class strid$ <|EOS|>',\n",
       " '<|endoftext|> ined estimators in the __init__ file estimator getattr estimators class_name model_ <|EOS|>',\n",
       " '<|endoftext|> global_step none graph_bytes graph_ <|EOS|>',\n",
       " '<|endoftext|> ine_function f self _input_types return lambda args kwargs call_function func_ <|EOS|>',\n",
       " '<|endoftext|> struct svm_model c <|EOS|>',\n",
       " '<|endoftext|> _accumulate_sufficient_statistics self stats obs framelogprob posteriors fwdlattice bwdlattice params super multinomialhmm self _accumulate_sufficient_statistics stats obs framelogprob posteriors fwdlattice bwdlattice params if strid$ in params for t symbol in enumerate obs stats strid$ symbol posteriors t <|EOS|>',\n",
       " '<|endoftext|> test_kneighbors_regressor_sparse n_samples numid$ n_features numid$ n_test_pts numid$ n_neighbors numid$ random_state numid$ strid$strid$strid$ # like the above but with various types of sparse matrices rng np random randomstate random_state x numid$ rng rand n_samples n_features numid$ y x numid$ sum axis numid$ numid$ astype np int sparse_types bsr_matrix coo_matrix csc_matrix csr_matrix dok_matrix lil_matrix for sparsemat in sparse_types knn neighbors kneighborsregressor n_neighbors n_neighbors algorithm strid$ knn fit sparsemat x y epsilon 1e numid$ numid$ rng rand numid$ n_features numid$ for sparsev in sparse_or_dense x2 sparsev x assert np mean knn predict x2 round y numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> node child int i j int n_dimensions node tree n_dimensions long idx idx1 float dist_check # there are no points below this node if cumulative_size numid$ # so do not bother to calculate any force contributions # also do not compute self interactions if node cumulative_size numid$ and not node is_leaf and node point_index point_index # compute distance between node center of mass and the reference point # istrid$s about # numid$ 5x worse when we do so probbaly because the vectors are small idx1 l numid$ n_dimensions deltas idx1 pos numid$ node barycenter numid$ idx idx1 for i in range numid$ n_dimensions idx numid$ deltas idx pos i node barycenter i # do np sqrt np sum deltas numid$ numid$ dist2s l numid$ snrm2 n_dimensions deltas idx1 numid$ # check whether we can use this node as a summary # it s a summary node if the angular size as measured from the point # is relatively small w r t to theta or if it is a leaf node # if it can be summarized we use the cell center of mass # otherwise we go a higher level of resolution and into the leaves if node is_leaf or node max_width dist2s l numid$ theta # compute the t sne force between the reference point and the # current node sizes l numid$ node cumulative_size dist2s l numid$ dist2s l numid$ dist2s l numid$ l numid$ numid$ else # recursively apply barnes hut to child nodes for idx in range node tree n_cell_per_node child node children idx if child cumulative_size numid$ continue compute_non_edge_forces child theta point_index pos force dist2s sizes deltas l c <|EOS|>',\n",
       " '<|endoftext|> __init__ self methodname strid$ fortrantestcase __init__ self methodname self typestr strid$ self typecode strid$ ###################################################################### class uchartestcase fortrantestcase <|EOS|>',\n",
       " '<|endoftext|> test_partial_fit_classes_error strid$strid$strid$ x numid$ numid$ y numid$ clf multilayerperceptronclassifier algorithm strid$ clf partial_fit x y classes numid$ numid$ assert_raises valueerror clf partial_fit x y classes numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> swig_sources self sources # do nothing swig sources have beed handled in build_src command return sources <|EOS|>',\n",
       " '<|endoftext|> test_mark_for_escaping_lazy self s lazystr strid$ b lazybytes bstrid$ self assertisinstance mark_for_escaping s promise self assertisinstance mark_for_escaping b promise self assertrenderequal strid$ strid$ s mark_for_escaping s <|EOS|>',\n",
       " '<|endoftext|> cost self return self _cost @property <|EOS|>',\n",
       " '<|endoftext|> test_init self request get_request testform sessionwizardview as_view strid$ step1 self asserttrue isinstance testform request templateresponse class cookieformtests testcase <|EOS|>',\n",
       " '<|endoftext|> ault may disappear in # future unless it is proved to be useful verbosity numid$ saved_results notfounderror notfounderror <|EOS|>',\n",
       " '<|endoftext|> ine_integer strid$ numid$ strid$ flags <|EOS|>',\n",
       " '<|endoftext|> get_flag_url c return urlresolvers reverse strid$ args c id <|EOS|>',\n",
       " '<|endoftext|> dtype_t denom d numid$ for j in range size denom abs x1 j abs x2 j if denom numid$ d abs x1 j x2 j denom return d # # bray curtis distance # d x y sum abs x_i y_i sum abs x_i abs y_i c <|EOS|>',\n",
       " '<|endoftext|> ault value is strid$ method str optional either strid$ or strid$ strid$ uses the <|EOS|>',\n",
       " '<|endoftext|> relatedobjectdoesnotexist self # the exception canstrid$relatedobjectdoesnotexist self field remote_field model doesnotexist attributeerror <|EOS|>',\n",
       " '<|endoftext|> ault manager tests class qualification models model name models charfield max_length numid$ class meta ordering strid$ class teachermanager models manager <|EOS|>',\n",
       " '<|endoftext|> cache_info strid$strid$strid$ with lock return _cacheinfo stats hits stats misses maxsize len cache <|EOS|>',\n",
       " '<|endoftext|> double current_squared_sum numid$ numid$ with nogil for i in range n_samples dataset next x_data_ptr x_ind_ptr xnnz y sample_weight for j in range xnnz val x_data_ptr j current_squared_sum val val if current_squared_sum max_squared_sum max_squared_sum current_squared_sum current_squared_sum numid$ numid$ if isinstance loss classification # lipschitz for log loss return numid$ numid$ max_squared_sum fit_intercept numid$ numid$ alpha else # lipschitz for squared loss return numid$ numid$ max_squared_sum fit_intercept alpha c <|EOS|>',\n",
       " '<|endoftext|> __str__ self return self name class editor models model name models charfield max_length numid$ <|EOS|>',\n",
       " '<|endoftext|> ault is strid$ order str or list of str optional when `a` is an array with fields <|EOS|>',\n",
       " '<|endoftext|> train_fn self unused_sess self num_calls numid$ if self num_calls numid$ numid$ self retries_left numid$ if self retries_left numid$ raise tf errors abortederror none none strid$ else raise runtimeerror strid$ with tf graph as_ <|EOS|>',\n",
       " '<|endoftext|> maximum_fill_value obj calculates the <|EOS|>',\n",
       " '<|endoftext|> setup self holder holder dummy numid$ holder save inner dummy numid$ holder holder save self change_url strid$ holder id result self client login username strid$ password strid$ self assertequal result true <|EOS|>',\n",
       " '<|endoftext|> squared_exponential theta d strid$strid$strid$ theta np asanyarray theta dtype np float d np asanyarray d dtype np float if d ndim numid$ n_features d shape numid$ else n_features numid$ if theta size numid$ theta np repeat theta n_features elif theta size n_features raise exception strid$ str n_features td theta reshape numid$ n_features d numid$ r np exp np sum td numid$ return r <|EOS|>',\n",
       " '<|endoftext|> ined media using a property class mywidget1 textinput class media css strid$ strid$ strid$ js strid$ strid$ strid$ class mywidget4 textinput <|EOS|>',\n",
       " '<|endoftext|> __init__ self s self s s <|EOS|>',\n",
       " '<|endoftext|> test_multiple_m2m self # multiple m2m references to model must be distinguished when # accessing the relations through an instance attribute s1 selfrefer objects create name strid$ s2 selfrefer objects create name strid$ s3 selfrefer objects create name strid$ s1 references add s2 s1 related add s3 e1 entry objects create name strid$ t1 tag objects create name strid$ t2 tag objects create name strid$ e1 topics add t1 e1 related add t2 self assertquerysetequal s1 references all strid$ self assertquerysetequal s1 related all strid$ self assertquerysetequal e1 topics all strid$ self assertquerysetequal e1 related all strid$ <|EOS|>',\n",
       " '<|endoftext|> test_decimal_field self field models decimalfield max_digits numid$ decimal_places numid$ name path args kwargs field deconstruct self assertequal path strid$ self assertequal args self assertequal kwargs strid$ numid$ strid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> device self strid$strid$strid$ dev self _node_ <|EOS|>',\n",
       " '<|endoftext|> test_version self state self rg state assert_ strid$ in state assert_ state strid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> test_seed_out_of_range_array self # gh #numid$ rs randomgenerator self brng self data1 strid$ assert_raises valueerror rs brng seed numid$ numid$ self bits numid$ assert_raises valueerror rs brng seed numid$ <|EOS|>',\n",
       " '<|endoftext|> _l2_loss self strid$strid$computes the l1 loss of the model strid$ with tf name_scope strid$ sparse_weights self _convert_n_to_tensor self _variables strid$ dense_weights self _convert_n_to_tensor self _variables strid$ l2 self _options strid$ loss numid$ for w in sparse_weights loss l2 tf reduce_sum tf square w for w in dense_weights loss l2 tf reduce_sum tf square w return loss <|EOS|>',\n",
       " '<|endoftext|> testprobabilitiescanbechanged self # set up graph tf set_random_seed numid$ lbl1 numid$ lbl2 numid$ # this cond allows the necessary class queues to be populated label tf cond tf greater numid$ tf random_uniform lambda tf constant lbl1 lambda tf constant lbl2 val np array numid$ numid$ label probs tf placeholder tf float32 shape numid$ batch_size numid$ data_batch labels tf contrib training stratified_sample_unknown_dist val label probs batch_size with self test_session as sess coord tf train coordinator threads tf train start_queue_runners coord coord for _ in range numid$ data lbls sess run data_batch labels feed_dict probs numid$ numid$ numid$ numid$ numid$ for data_example in data self assertlistequal numid$ numid$ list data_example self assertlistequal numid$ numid$ list lbls # now change distribution and expect different output for _ in range numid$ data lbls sess run data_batch labels feed_dict probs numid$ numid$ numid$ numid$ numid$ for data_example in data self assertlistequal numid$ numid$ list data_example self assertlistequal numid$ numid$ list lbls coord request_stop coord join threads <|EOS|>',\n",
       " '<|endoftext|> render self context context push for var val in self extra_context items context var resolve_variable_with_filters val context singular self render_token_list self singular context if self plural and self countervar and self counter count resolve_variable_with_filters self counter context context self countervar count plural self render_token_list self plural context result translation ngettext singular plural count context else result translation gettext singular context context pop return result <|EOS|>',\n",
       " '<|endoftext|> test_log self with patch_logger strid$ strid$ as calls self client get strid$ self assertequal len calls numid$ self assertequal calls numid$ strid$ @override_settings middleware strid$ <|EOS|>',\n",
       " '<|endoftext|> inition for strid$ invalid_models clash3 reverse query name for m2m field strid$ clashes with field strid$ add a related_name argument to the <|EOS|>',\n",
       " '<|endoftext|> is_glob_pattern s return is_string s and strid$ in s or strid$ is s <|EOS|>',\n",
       " '<|endoftext|> kml self strid$ gtype self geom_type return strid$ gtype self coord_seq kml gtype #### gdal specific output routines #### @property <|EOS|>',\n",
       " '<|endoftext|> test_assert_less # check that the nose implementation of assert_less gives the # same thing as the scikit s assert_less numid$ numid$ _assert_less numid$ numid$ assert_raises assertionerror assert_less numid$ numid$ assert_raises assertionerror _assert_less numid$ numid$ except importerror pass try from nose tools import assert_greater <|EOS|>',\n",
       " '<|endoftext|> is_reparameterized self return true # copyright numid$ google inc all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # strid$strid$strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function from tensorflow contrib distributions python ops normal import normal # pylint disable line too long from tensorflow python ops import math_ops <|EOS|>',\n",
       " '<|endoftext|> test_username_validity self user user objects get username strid$ data strid$ strid$ form userchangeform data instance user self assertfalse form is_valid validator next v for v in user _meta get_field strid$ validators if v code strid$ self assertequal form strid$ errors force_text validator message <|EOS|>',\n",
       " '<|endoftext|> extern from strid$ c <|EOS|>',\n",
       " '<|endoftext|> test_polysub self for i in range numid$ for j in range numid$ msg strid$ i j tgt np zeros max i j numid$ tgt i numid$ tgt j numid$ res poly polysub numid$ i numid$ numid$ j numid$ assert_equal trim res trim tgt err_msg msg <|EOS|>',\n",
       " '<|endoftext|> test_predict_3_classes clf logistic logisticregression c numid$ fit x y2 assert_array_equal clf predict x y2 assert_array_equal clf predict_proba x argmax axis numid$ y2 <|EOS|>',\n",
       " '<|endoftext|> test_should_stop_on_close self with self test_session as sess wrapped_sess tf contrib learn wrappedsession sess self assertfalse wrapped_sess should_stop wrapped_sess close self asserttrue wrapped_sess should_stop <|EOS|>',\n",
       " '<|endoftext|> ault float count int optional number of items to read `` numid$`` means all data in the buffer offset int optional start reading the buffer from this offset in bytes <|EOS|>',\n",
       " '<|endoftext|> ault outputs build_graph device input_shape axes num_layers py scale train with tf session graph graph as session tf initialize_all_variables run _ session run out op for out in outputs # warm up start_time time time for _ in range num_iters _ session run out op for out in outputs duration time time start_time print strid$ len input_shape len axes num_layers py scale train duration <|EOS|>',\n",
       " '<|endoftext|> ault true if true a copy of x will be created if false imputation will be done in place whenever possible note that in the following cases a new copy will always be made even if `copy false` if x is not an array of floating values if x is sparse and `missing_values numid$` if `axis numid$` and x is encoded as a csr matrix if `axis numid$` and x is encoded as a csc matrix attributes statistics_ array of shape n_features the imputation fill value for each feature if axis numid$ notes when ``axis numid$`` columns which only contained missing values at `fit` are discarded upon `transform` when ``axis numid$`` an exception is raised if there are rows for which it is not possible to fill in the missing values e g because they only contain missing values strid$ <|EOS|>',\n",
       " '<|endoftext|> testmyoperator self with self test_session use_gpu true valid_input numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ result myoperator valid_input eval self assertequal result numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ invalid_input numid$ numid$ numid$ numid$ numid$ numid$ with self assertraisesoperror strid$ myoperator invalid_input eval args graph optional graph to use during the returned session config an optional config_pb2 configproto to use to configure the session use_gpu if true attempt to run as many ops as possible on gpu force_gpu if true pin all ops to ` gpu numid$` returns a session object that should be used as a context manager to surround the graph building and execution code in a test case strid$ <|EOS|>',\n",
       " '<|endoftext|> raise typeerror meta_info_ <|EOS|>',\n",
       " '<|endoftext|> test_read_version_1_0_bad_magic for magic in bad_version_magic malformed_magic f stringio magic yield raises valueerror format read_array f # usr bin env python # system imports from distutils util import get_platform import os import sys import unittest # import numpy import numpy as np major minor int d for d in np __version__ split strid$ numid$ if major numid$ badlisterror typeerror else badlisterror valueerror # add the distutils generated build directory to the python search path and then # import the extension module libdir strid$ get_platform sys version numid$ sys path insert numid$ os path join strid$ libdir import matrix ###################################################################### class matrixtestcase unittest testcase <|EOS|>',\n",
       " '<|endoftext|> admin_ordered_callable obj return obj order admin_ordered_callable admin_order_field strid$ class adminorderedcallableadmin admin modeladmin ordering strid$ list_display strid$ admin_ordered_callable class reportadmin admin modeladmin <|EOS|>',\n",
       " '<|endoftext|> ault is numid$ size int or tuple of ints optional output shape if the given shape is e g `` m n k `` then ``m n k`` samples are drawn if size is ``none`` <|EOS|>',\n",
       " '<|endoftext|> __init__ self args self transforms args <|EOS|>',\n",
       " '<|endoftext|> aults dictionary optional dictionary mapping field names to the corresponding <|EOS|>',\n",
       " '<|endoftext|> hstack tup strid$strid$strid$ return _nx concatenate map atleast_1d tup numid$ from numpy testing import from numpy core import array atleast_1d atleast_2d atleast_3d vstack hstack newaxis class testatleast1d testcase <|EOS|>',\n",
       " '<|endoftext|> check_basic_ufuncs self strid$ x y a10 m1 m2 xm ym z zm xf self d assert_equal numpy cos x cos xm assert_equal numpy cosh x cosh xm assert_equal numpy sin x sin xm assert_equal numpy sinh x sinh xm assert_equal numpy tan x tan xm assert_equal numpy tanh x tanh xm assert_equal numpy sqrt abs x sqrt xm assert_equal numpy log abs x log xm assert_equal numpy log10 abs x log10 xm assert_equal numpy exp x exp xm assert_equal numpy arcsin z arcsin zm assert_equal numpy arccos z arccos zm assert_equal numpy arctan z arctan zm assert_equal numpy arctan2 x y arctan2 xm ym assert_equal numpy absolute x absolute xm assert_equal numpy equal x y equal xm ym assert_equal numpy not_equal x y not_equal xm ym assert_equal numpy less x y less xm ym assert_equal numpy greater x y greater xm ym assert_equal numpy less_equal x y less_equal xm ym assert_equal numpy greater_equal x y greater_equal xm ym assert_equal numpy conjugate x conjugate xm # <|EOS|>',\n",
       " '<|endoftext|> test_runner_ambiguous self # only numid$ characters all of which could be in an ipv6 address self cmd handle addrport strid$ self assertserversettings strid$ strid$ # uses only characters that could be in an ipv6 address self cmd handle addrport strid$ self assertserversettings strid$ strid$ ########################################################################## # command processing tests # check that user space commands are correctly handled in particular # that arguments to the commands are correctly parsed and processed ########################################################################## class commandtypes adminscripttestcase tests for the various types of base command types that can be <|EOS|>',\n",
       " '<|endoftext|> flatten_data self new_data obj self change and self original_object or none for f in self opts get_data_holders self follow fol self follow get f name new_data update f flatten_data fol obj return new_data class automaticaddmanipulator automaticmanipulator change false class automaticchangemanipulator automaticmanipulator change true <|EOS|>',\n",
       " '<|endoftext|> get_model self app_label model_name seed_cache true only_installed true strid$strid$strid$ if not self master only_installed false if seed_cache self populate if only_installed app_config self app_configs get app_label if app_config is not none and not app_config installed return none if self available_apps is not none and app_config name not in self available_apps raise unavailableapp strid$ app_label try return self app_configs app_label models model_name lower except keyerror return none <|EOS|>',\n",
       " '<|endoftext|> removequotes s l t strid$strid$strid$ return t numid$ numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> ield self __init__ rstrid$ max_length none min_length none args kwargs class bephonenumberfield regexfield strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> ine_boolean strid$ true strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> aults to false verbose integer optional the verbosity level n_jobs integer optional the number of cpus to use to do the ova one versus all for multi class problems computation numid$ means strid$ <|EOS|>',\n",
       " '<|endoftext|> get_func str return str # functions used by the geomanager geoqueryset area get_func strid$ centroid get_func strid$ contained get_func strid$ difference get_func strid$ distance get_func strid$ envelope get_func strid$ geom_from_text get_func strid$ geom_from_wkb get_func strid$ intersection get_func strid$ length get_func strid$ # opengis <|EOS|>',\n",
       " '<|endoftext|> testparams self strid$strid$strid$ num_classes numid$ with self test_session as sess # experiment numid$ update weights only data tf constant self data dtype tf float32 gmm_tool gmm_ops gmmalgorithm data num_classes numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ strid$ training_ops gmm_tool training_ops tf initialize_all_variables run for _ in xrange self iterations sess run training_ops # only the probability to each class is updated alphas sess run gmm_tool alphas self assertgreater alphas numid$ numid$ numid$ means sess run gmm_tool clusters np testing assert_almost_equal np expand_dims numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ means covs sess run gmm_tool covariances np testing assert_almost_equal covs numid$ covs numid$ # experiment numid$ update means and covariances gmm_tool gmm_ops gmmalgorithm data num_classes numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ strid$ training_ops gmm_tool training_ops tf initialize_all_variables run for _ in xrange self iterations sess run training_ops alphas sess run gmm_tool alphas self assertalmostequal alphas numid$ alphas numid$ means sess run gmm_tool clusters np testing assert_almost_equal np expand_dims numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ means decimal numid$ covs sess run gmm_tool covariances np testing assert_almost_equal numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ covs numid$ decimal numid$ np testing assert_almost_equal numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ covs numid$ decimal numid$ # experiment numid$ update covariances only gmm_tool gmm_ops gmmalgorithm data num_classes numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ strid$ training_ops gmm_tool training_ops tf initialize_all_variables run for _ in xrange self iterations sess run training_ops alphas sess run gmm_tool alphas self assertalmostequal alphas numid$ alphas numid$ means sess run gmm_tool clusters np testing assert_almost_equal np expand_dims numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ means covs sess run gmm_tool covariances np testing assert_almost_equal numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ covs numid$ decimal numid$ np testing assert_almost_equal numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ covs numid$ decimal numid$ if __name__ strid$ tf test main # copyright numid$ the tensorflow authors all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # strid$strid$strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function import numpy as np from six moves import xrange # pylint disable re <|EOS|>',\n",
       " '<|endoftext|> testformattensor2dnoellipsiswithrowbreak self a np linspace numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ reshape numid$ numid$ out tensor_format format_tensor a strid$ np_printoptions strid$ numid$ self assertequal strid$ a dtype strid$ a shape out annotations strid$ self assertequal strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ out lines self _checktensormetadata a out annotations # check annotations for the beginning indices of the lines self _checkbeginindices numid$ numid$ out annotations numid$ self _checkbeginindices numid$ numid$ out annotations numid$ self _checkbeginindices numid$ numid$ out annotations numid$ self _checkbeginindices numid$ numid$ out annotations numid$ self _checkbeginindices numid$ numid$ out annotations numid$ self _checkbeginindices numid$ numid$ out annotations numid$ self _checkbeginindices numid$ numid$ out annotations numid$ self _checkbeginindices numid$ numid$ out annotations numid$ <|EOS|>',\n",
       " '<|endoftext|> test_dotted_test_class_vanilla_unittest self count discoverrunner build_suite strid$ counttestcases self assertequal count numid$ <|EOS|>',\n",
       " '<|endoftext|> setup self base data <|EOS|>',\n",
       " '<|endoftext|> test_weibull_0 self assert_equal mt19937 weibull a numid$ numid$ assert_raises valueerror mt19937 weibull a numid$ <|EOS|>',\n",
       " '<|endoftext|> test_lte self qs self queryset filter qty_needed__lte numid$ self assertcountequal qs self p1 self p2 import warnings from django conf urls import url from django test import simpletestcase override_settings from django urls import reverse from views import empty_view urlpatterns url rstrid$ empty_view name strid$ url rstrid$ empty_view name strid$ @override_settings root_urlconf strid$ class urlpatternreverse simpletestcase <|EOS|>',\n",
       " '<|endoftext|> parse_params self args kwargs strid$strid$strid$ pass <|EOS|>',\n",
       " '<|endoftext|> setup self self _cwd os getcwd self test_dir os path abspath os path dirname __file__ <|EOS|>',\n",
       " '<|endoftext|> test16bit self img_bytes numid$ numid$ numid$ numid$ numid$ # encoded png bytes resulting from encoding the above img_bytes # using go s image png encoder encoded_bytes numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ byte_string strid$ join map chr encoded_bytes img_in tf constant byte_string dtype tf string decode tf squeeze tf image decode_png img_in dtype tf uint16 with self test_session decoded decode eval self assertallequal decoded img_bytes if __name__ strid$ tf test main # copyright numid$ the tensorflow authors all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # strid$strid$strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function import collections import six <|EOS|>',\n",
       " '<|endoftext|> ault strid$ weight function used in prediction possible values strid$ uniform weights all points in each neighborhood are weighted equally strid$ weight points by the inverse of their distance in this case closer neighbors of a query point will have a greater influence than neighbors which are further away callable a user <|EOS|>',\n",
       " '<|endoftext|> double wnorm numid$ numid$ c <|EOS|>',\n",
       " '<|endoftext|> predict_proba self x x sp csr_matrix x return sagclassifier predict_proba self x class sparsesagregressor sagregressor <|EOS|>',\n",
       " '<|endoftext|> test_rank_passing_untyped_args self searched line objects filter character self minstrel annotate rank searchrank strid$ strid$ order_by strid$ self assertsequenceequal searched self verse2 self verse1 self verse0 <|EOS|>',\n",
       " '<|endoftext|> test_basic_context self self assertequal loader render_to_string strid$ strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> ault_image_mimetype class _outputformat object strid$strid$strid$ json strid$ csv strid$ class tensorboardhandler basehttpserver basehttprequesthandler strid$strid$strid$ # how many samples to include in sampling api calls by <|EOS|>',\n",
       " '<|endoftext|> _get_closed self return self _closed closed property _get_closed <|EOS|>',\n",
       " '<|endoftext|> file to load strid$ tf flags <|EOS|>',\n",
       " '<|endoftext|> testnormalcdf self with tf session batch_size numid$ mu tf constant numid$ numid$ batch_size sigma tf constant math sqrt numid$ numid$ batch_size mu_v numid$ numid$ sigma_v np sqrt numid$ numid$ x np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ dtype np float32 normal tf contrib distributions normal mu mu sigma sigma erf_fn np vectorize math erf # from wikipedia expected_cdf numid$ numid$ numid$ numid$ erf_fn x mu_v sigma_v np sqrt numid$ cdf normal cdf x self assertallclose expected_cdf cdf eval <|EOS|>',\n",
       " '<|endoftext|> ault none a figure object onto which the plots will be drawn after the figure has been cleared by <|EOS|>',\n",
       " '<|endoftext|> testadddebugtensorwatches_multipledebugops self debug_utils add_debug_tensor_watch self _run_options strid$ numid$ debug_ops strid$ strid$ debug_urls strid$ self assertequal numid$ len self _run_options debug_tensor_watch_opts watch_0 self _run_options debug_tensor_watch_opts numid$ self assertequal strid$ watch_0 node_name self assertequal numid$ watch_0 output_slot # verify <|EOS|>',\n",
       " '<|endoftext|> testyesshuffle self id_source rs readersource reader_cls tf identityreader work_units self work_units batch_size numid$ shuffle true num_threads numid$ seed numid$ index_column value_column id_source cache index_tensor index_column build cache value_tensor value_column build cache self assertequal numid$ index_tensor get_shape as_list self assertequal numid$ value_tensor get_shape as_list seen set with self test_session as sess tf initialize_all_variables run coord tf train coordinator threads tf train start_queue_runners sess sess coord coord for _ in range numid$ index value sess run index_tensor value_tensor self assertequal index value self assertnotin int value numid$ seen seen add int value numid$ coord request_stop coord join threads if __name__ strid$ tf test main # copyright numid$ the tensorflow authors all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # strid$strid$strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function from contextlib import contextmanager import threading from tensorflow python framework import ops from tensorflow python training import coordinator __all__ strid$ strid$ _queue_runner_lock threading lock class nestedqueuerunnererror exception pass @contextmanager <|EOS|>',\n",
       " '<|endoftext|> test_ipaddress self f ipaddressfield self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean none self assertequal f clean strid$ strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ f ipaddressfield required false self assertequal f clean strid$ strid$ self assertequal f clean none strid$ self assertequal f clean strid$ strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ <|EOS|>',\n",
       " '<|endoftext|> test_noncentral_f self self _set_common_state self _is_state_common compare_3_input self nprs noncentral_f self rg noncentral_f self _is_state_common <|EOS|>',\n",
       " '<|endoftext|> ghistrid$strid$ tests append test ################################################################# if numid$ or all and not skip test test strid$ strid$ test strid$ strid$strid$strid$ test strid$ strid$ import f2pytest sys <|EOS|>',\n",
       " '<|endoftext|> graph_search neighbors distances method strid$ strid$strid$strid$ neighbors np asarray neighbors dtype itype distances np asarray distances dtype dtype assert neighbors shape distances shape n k neighbors shape if method strid$ if k n numid$ method strid$ else method strid$ graph np empty n n dtype dtype if method strid$ floydwarshall neighbors distances graph elif method strid$ dijkstra neighbors distances graph else raise valueerror strid$ method return graph c <|EOS|>',\n",
       " '<|endoftext|> ault_db_alias # postgresql creates two indexes self assertin len output numid$ numid$ self asserttrue output numid$ startswith strid$ <|EOS|>',\n",
       " '<|endoftext|> test_get_actions_respects_permissions self class mockrequest pass class bandadmin admin modeladmin actions strid$ <|EOS|>',\n",
       " '<|endoftext|> teardown self self stdout close <|EOS|>',\n",
       " '<|endoftext|> train_wrap np ndarray np float64_t ndim numid$ mode strid$ x np ndarray np int32_t ndim numid$ mode strid$ y int solver_type double eps double bias double c np ndarray np int32_t ndim numid$ weight_label np ndarray np float64_t ndim numid$ weight strid$strid$strid$ c <|EOS|>',\n",
       " '<|endoftext|> wrapped_view args kwargs resp view_func args kwargs if resp get strid$ none is none resp strid$ strid$ return resp return wraps view_func assigned available_attrs view_func wrapped_view <|EOS|>',\n",
       " '<|endoftext|> test_solo self strid$ _ x _ z self data # test merge_arrays x control np array numid$ numid$ dtype strid$ int assert_equal test control test merge_arrays x assert_equal test control # test merge_arrays z flatten false assert_equal test z test merge_arrays z flatten true assert_equal test z # <|EOS|>',\n",
       " '<|endoftext|> normals_zig n prng out np empty n for i in range n out i random_gauss_zig prng return out normalsj nb jit normals nopython true normals_zigj nb jit normals_zig nopython true # numba requires a memory address for void # can also get address from x ctypes prng value prng_address int ffi cast strid$ prng norm normalsj numid$ prng_address norm_zig normals_zigj numid$ prng_address import os import struct import timeit import numpy as np import pandas as pd from numpy random import randomstate rs randomstate setup strid$strid$ prng strid$numpystrid$strid$ scale_32 scale_64 numid$ if struct calcsize strid$ numid$ and os name strid$ # numid$ bit scale_32 numid$ numid$ else scale_64 numid$ prngs strid$ strid$ strid$ strid$ strid$ strid$ strid$ # strid$ #strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> process_item self self close_specs self item get_line numid$ lstrip numid$ numid$ strip return <|EOS|>',\n",
       " '<|endoftext|> ined `tf float32` numid$ bit single precision floating point `tf float64` numid$ bit double precision floating point `tf bfloat16` numid$ bit truncated floating point `tf complex64` numid$ bit single precision complex `tf int8` numid$ bit signed integer `tf uint8` numid$ bit unsigned integer `tf int32` numid$ bit signed integer `tf int64` numid$ bit signed integer `tf bool` boolean `tf string` string `tf qint8` quantized numid$ bit signed integer `tf quint8` quantized numid$ bit unsigned integer `tf qint32` quantized numid$ bit signed integer in addition variants of these types with the `_ref` suffix are <|EOS|>',\n",
       " '<|endoftext|> ault <|EOS|>',\n",
       " '<|endoftext|> extern from strid$ object pylong_fromvoidptr void void pylong_asvoidptr object ctype <|EOS|>',\n",
       " '<|endoftext|> test_ifequal08 self output render strid$ strid$ strid$ self assertequal output strid$ @setup strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> test_basic self random multinomial numid$ numid$ numid$ numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> double dloss self double p double y c <|EOS|>',\n",
       " '<|endoftext|> __str__ self return self msg class metainfo object <|EOS|>',\n",
       " '<|endoftext|> long i j dn c <|EOS|>',\n",
       " '<|endoftext|> check_empty_3_slice self strid$strid$strid$ test strid$ desired strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ self generic_test test desired <|EOS|>',\n",
       " '<|endoftext|> teardown self settings authentication_backends self curr_auth <|EOS|>',\n",
       " '<|endoftext|> test_y_as_list # pass y as list in gridsearchcv x np arange numid$ reshape numid$ numid$ y np array numid$ numid$ numid$ numid$ clf checkingclassifier check_y lambda x isinstance x list cv kfold n_folds numid$ grid_search gridsearchcv clf strid$ numid$ numid$ numid$ cv cv grid_search fit x y tolist score x y assert_true hasattr grid_search strid$ @ignore_warnings <|EOS|>',\n",
       " '<|endoftext|> naturalkeyserializertest format self # create all the objects <|EOS|>',\n",
       " '<|endoftext|> inite otherwise the behavior of this method is un <|EOS|>',\n",
       " '<|endoftext|> _str_examples self examples_str strid$ join self strid$ if self use_plots and strid$ in examples_str and strid$ not in examples_str out out self _str_header strid$ out strid$ strid$ out self _str_indent self strid$ out strid$ return out else return self _str_section strid$ <|EOS|>',\n",
       " '<|endoftext|> values self strid$strid$strid$ return v for k v in self _headers <|EOS|>',\n",
       " '<|endoftext|> test_append_slash_quoted_custom_urlconf self strid$strid$strid$ request self _get_request strid$ request urlconf strid$ r commonmiddleware process_request request self assertfalse r is none strid$ self assertequal r status_code numid$ self assertequal r url strid$ @override_settings append_slash false prepend_www true <|EOS|>',\n",
       " '<|endoftext|> testmixtureofdequeueanddequeuemany self with self test_session as sess q tf paddingfifoqueue numid$ tf int32 shapes enqueue_op q enqueue_many np arange numid$ dtype np int32 dequeued_t q dequeue count_placeholder tf placeholder tf int32 shape dequeuemany_t q dequeue_many count_placeholder <|EOS|>',\n",
       " '<|endoftext|> ault_site self app_config self assertequal site objects count numid$ self assertin strid$ stdout getvalue with captured_stdout as stdout create_ <|EOS|>',\n",
       " '<|endoftext|> node extend bias_add_node test_graph float_graph_ <|EOS|>',\n",
       " '<|endoftext|> blocking_enqueue enq_done append false # this will fill the queue and then block until enough dequeues happen sess run enq enq_done append true thread self checkedthread target blocking_enqueue thread start # the enqueue should start and then block results results append deq eval # will only complete after the enqueue starts self assertequal len enq_done numid$ self assertequal sess run size_op numid$ for _ in range numid$ results append deq eval time sleep numid$ numid$ self assertequal len enq_done numid$ self assertequal sess run size_op numid$ # this dequeue will unblock the thread results append deq eval time sleep numid$ numid$ self assertequal len enq_done numid$ thread join for i in range numid$ self assertequal size_op eval numid$ i results append deq eval self assertequal size_op eval numid$ i numid$ self assertitemsequal elem results <|EOS|>',\n",
       " '<|endoftext|> ining batch matrix of same `dtype` and `batch_shape` as `operator` and last two dimensions of shape ` k r ` diag optional `tensor` <|EOS|>',\n",
       " '<|endoftext|> test_nonstandard_keys self strid$strid$strid$ self asserttrue strid$ in parse_cookie strid$ keys <|EOS|>',\n",
       " '<|endoftext|> ault values this is useful for comparing protocol buffers where the semantics of unset fields and <|EOS|>',\n",
       " '<|endoftext|> ault_protocol instead if you need to ensure compatibility with older versions of python strid$ cloudpickler file protocol protocol dump obj <|EOS|>',\n",
       " '<|endoftext|> ault append wx_spec wx_converter except pass # # blitz conversion classes # # same as <|EOS|>',\n",
       " '<|endoftext|> ault_local_init_op with tf graph as_ <|EOS|>',\n",
       " '<|endoftext|> drop_foreignkey_sql self return strid$ <|EOS|>',\n",
       " '<|endoftext|> aults args_list append strid$ arg <|EOS|>',\n",
       " '<|endoftext|> self page_text page_template format self type self name self overview briefs fulls <|EOS|>',\n",
       " '<|endoftext|> render_to_response_view_with_dirs request return render_to_response strid$ dirs dirs <|EOS|>',\n",
       " '<|endoftext|> test_normalizer x np random randn numid$ numid$ normalizer normalizer x_norm normalizer transform x copy false assert_array_almost_equal x_norm sum axis numid$ np ones x shape numid$ assert x_norm is x normalizer normalizer x_norm normalizer transform x copy true assert_array_almost_equal x_norm sum axis numid$ np ones x shape numid$ assert x_norm is not x <|EOS|>',\n",
       " '<|endoftext|> main tagname sys argv numid$ order_file sys argv numid$ functions get_api_functions tagname order_file m md5 new tagname for func in functions print func ah func api_hash m update ah print hex int ah numid$ print hex int m hexdigest numid$ numid$ if __name__ strid$ main import unittest import sys from scipy test testing import set_package_path import scipy base reload scipy base from scipy base import from scipy base import records as rec class test_fromrecords scipytestcase <|EOS|>',\n",
       " '<|endoftext|> test_multi_target_score strid$strid$strid$ # create the data set using the helper function x y _create_data_set forest multi_target_forest _set_up_multi_target_random_forest # train the multi_target_forest multi_target_forest fit x y #score the multi_target_forest expect an array of floats multi_score multi_target_forest score x y # train the forest with each column #and then assert that scores are similar for i in range numid$ score forest fit x y i score x y i assert_almost_equal score multi_score i if __name__ strid$ test_multi_target_init_with_random_forest test_multi_target_fit_and_predict_with_random_forest test_multi_target_fit_and_predict_probs_with_random_forest test_multi_target_score # cython cdivision true # cython boundscheck false # cython wraparound false # cython profile true # # author andreas mueller # # licence bsd numid$ clause import numpy as np cimport numpy as np cimport cython from libc math cimport sqrt from metrics import euclidean_distances from _k_means import _centers_dense from utils fixes import partition c <|EOS|>',\n",
       " '<|endoftext|> ault_shape_function_registry registry registry <|EOS|>',\n",
       " '<|endoftext|> __init__ self host port strid$strid$strid$ streamhandler __init__ self self host host self port port self sock none self closeonerror numid$ <|EOS|>',\n",
       " '<|endoftext|> test_custom_backend self strid$ test custom backend <|EOS|>',\n",
       " '<|endoftext|> quantize_node self input_node strid$strid$strid$ input_name input_node name if input_name in self already_quantized return self already_quantized input_name true original_input_name input_name strid$ reshape_name input_name strid$ reshape_dims_name input_name strid$ max_name input_name strid$ min_name input_name strid$ dims_name input_name strid$ quantize_name input_name strid$ dequantize_name input_name original_input_node tf node <|EOS|>',\n",
       " '<|endoftext|> testclosestack self self _testclosestack use_gpu false self _testclosestack use_gpu true <|EOS|>',\n",
       " '<|endoftext|> test_override_one2one_relation_auto_field_clashes self class concreteparent models model name models charfield max_length numid$ class abstractparent models model name models integerfield class meta abstract true msg strid$ strid$ strid$ with self assertraisesmessage fielderror msg class descendant concreteparent abstractparent concreteparent_ptr models charfield max_length numid$ <|EOS|>',\n",
       " '<|endoftext|> ined used by sstrid$program_unitstrid$main_programstrid$external_subprogramstrid$modulestrid$block_datastrid$function_subprogramstrid$subroutine_subprogramstrid$function_stmtstrid$specification_partstrid$execution_partstrid$internal_subprogram_partstrid$end_function_stmtstrid$subroutine_stmtstrid$specification_partstrid$execution_partstrid$internal_subprogram_partstrid$end_subroutine_stmtstrid$prefixstrid$subroutine_namestrid$dummy_arg_liststrid$proc_language_binding_specstrid$subroutine_namestrid$use_stmtstrid$import_stmtstrid$implicit_partstrid$declaration_constructstrid$implicit_part_stmtstrid$implicit_stmtstrid$implicit_stmtstrid$parameter_stmtstrid$format_stmtstrid$entry_stmt class declaration_construct base strid$ declaration construct derived type <|EOS|>',\n",
       " '<|endoftext|> aults self # use of callable <|EOS|>',\n",
       " '<|endoftext|> test_rs_bands self self assertequal len self rs bands numid$ self assertisinstance self rs bands numid$ gdalband <|EOS|>',\n",
       " '<|endoftext|> random_upload_to self filename # this returns a different result each time # to make sure it only gets called once import random return strid$ random randint numid$ numid$ filename normal models filefield storage temp_storage upload_to strid$ custom models filefield storage temp_storage upload_to custom_upload_to random models filefield storage temp_storage upload_to random_upload_to <|EOS|>',\n",
       " '<|endoftext|> __iter__ self for d in self dicts yield d <|EOS|>',\n",
       " '<|endoftext|> testcompilehelpwithouthelpintro self ui mockcursesui numid$ numid$ command_sequence string_to_codes strid$ self _exit ui register_command_handler strid$ self _babble strid$ prefix_aliases strid$ ui run_ui self assertequal strid$ strid$ strid$ strid$ ui unwrapped_outputs numid$ lines numid$ <|EOS|>',\n",
       " '<|endoftext|> inite strid$covariance is not positive semi <|EOS|>',\n",
       " '<|endoftext|> test_httponly_cookie self response httpresponse response set_cookie strid$ httponly true example_cookie response cookies strid$ self assertin strid$ cookies morsel _reserved strid$ str example_cookie self assertis example_cookie strid$ true <|EOS|>',\n",
       " '<|endoftext|> input_map output_name strid$ for output_name in output_names for expected result in zip float_results weights_rounded_results assert are_tensors_near expected result numid$ numid$ class quantizegraphtest tf test testcase <|EOS|>',\n",
       " '<|endoftext|> i18n_javascript self request strid$strid$strid$ from django conf import settings if settings use_i18n from django views i18n import javascript_catalog else from django views i18n import null_javascript_catalog as javascript_catalog return javascript_catalog request packages strid$ <|EOS|>',\n",
       " '<|endoftext|> np ndarray x_ndarray x # pre sort x if self x_old self x self x_old self x self x_argsorted np asfortranarray np argsort x_ndarray axis numid$ dtype np int32 self x_argsorted_ptr int32_t self x_argsorted data self x_argsorted_stride size_t self x_argsorted strides numid$ size_t self x_argsorted itemsize self n_total_samples x shape numid$ sample_mask safe_realloc self sample_mask self n_total_samples memset sample_mask numid$ self n_total_samples c <|EOS|>',\n",
       " '<|endoftext|> test_matching_named_fields self strid$ _ x _ z self data zz np array strid$ numid$ numid$ strid$ numid$ numid$ strid$ numid$ numid$ dtype strid$ strid$ strid$ float strid$ float test stack_arrays z zz control ma array strid$ numid$ numid$ strid$ numid$ numid$ strid$ numid$ numid$ strid$ numid$ numid$ strid$ numid$ numid$ dtype strid$ strid$ strid$ float strid$ float mask numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ assert_equal test control assert_equal test mask control mask # test stack_arrays z zz x ndtype strid$ strid$ strid$ float strid$ float strid$ int control ma array strid$ numid$ numid$ numid$ strid$ numid$ numid$ numid$ strid$ numid$ numid$ numid$ strid$ numid$ numid$ numid$ strid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ dtype ndtype mask numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ assert_equal test control assert_equal test mask control mask # <|EOS|>',\n",
       " '<|endoftext|> ined in strid$ strid$strid$ if given must be set to a list or tuple strid$strid$ refers to r which isn strid$ fn # date_hierarchy if opts admin date_hierarchy try f opts get_field opts admin date_hierarchy except models fielddoesnotexist e add opts strid$ opts admin date_hierarchy # check ordering attribute if opts ordering for field_name in opts ordering if field_name strid$ continue if field_name startswith strid$ field_name field_name numid$ if opts order_with_respect_to and field_name strid$ continue if strid$ in field_name continue # skip ordering in the format strid$ try opts get_field field_name many_to_many false except models fielddoesnotexist e add opts strid$ field_name # check core true if needed for related in opts get_followed_related_objects if not related edit_inline continue try for f in related opts fields if f core raise stopiteration e add related opts strid$ related opts object_name opts module_name opts object_name except stopiteration pass # check unique_together for ut in opts unique_together for field_name in ut try f opts get_field field_name many_to_many true except models fielddoesnotexist e add opts strid$ field_name else if isinstance f rel models manytomanyrel e add opts strid$ f name return len e errors from django core management base import basecommand class command basecommand help strid$ args strid$ requires_model_validation false <|EOS|>',\n",
       " '<|endoftext|> test_symmetrical_self_referential_field self class person models model # implicit symmetrical false friends models manytomanyfield strid$ through strid$ class relationship models model first models foreignkey person related_name strid$ second models foreignkey person related_name strid$ field person _meta get_field strid$ errors field check from_model person expected error strid$ hint none obj field id strid$ self assertequal errors expected <|EOS|>',\n",
       " '<|endoftext|> salt self bcrypt self _load_library return bcrypt gensalt self rounds <|EOS|>',\n",
       " '<|endoftext|> __init__ self methodname strid$ fortrantestcase __init__ self methodname self typestr strid$ self typecode strid$ ###################################################################### class ulonglongtestcase fortrantestcase <|EOS|>',\n",
       " '<|endoftext|> get_manipulator opts klass extra_methods add false change false strid$ assert add false or change false and add change strid$ man types classtype strid$ opts object_name add and strid$ or strid$ formfields manipulator man __module__ model_prefix strid$ opts module_name # set this explicitly as above man __init__ curry manipulator_init opts add change man save curry manipulator_save opts klass add change for field_name_list in opts unique_together setattr man strid$ strid$ join field_name_list curry manipulator_validator_unique_together field_name_list opts for f in opts fields if f unique_for_date setattr man strid$ f name f unique_for_date curry manipulator_validator_unique_for_date f opts get_field f unique_for_date opts strid$ if f unique_for_month setattr man strid$ f name f unique_for_month curry manipulator_validator_unique_for_date f opts get_field f unique_for_month opts strid$ if f unique_for_year setattr man strid$ f name f unique_for_year curry manipulator_validator_unique_for_date f opts get_field f unique_for_year opts strid$ for k v in extra_methods items setattr man k v return man <|EOS|>',\n",
       " '<|endoftext|> __repr__ self return strid$ self get_user <|EOS|>',\n",
       " '<|endoftext|> test_numpy_state self nprs np random randomstate nprs standard_normal numid$ state nprs get_state self rg brng state state state2 self rg brng state assert state numid$ state2 strid$ strid$ all assert state numid$ state2 strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> fit self x y strid$strid$strid$ self _scores self score_func x y #self _scores _scores numid$ #self _pvalues _scores numid$ #self _rank np argsort self _pvalues return self <|EOS|>',\n",
       " '<|endoftext|> __init__ self dr_input strid$ if isinstance dr_input basestring # if a string name of the driver was passed in self _ptr none # initially null self _register # checking the alias dictionary case insensitive to see if an alias # exists for the given driver if dr_input lower in self _alias name self _alias dr_input lower else name dr_input # attempting to get the ogr driver by the string name dr get_driver_by_name name elif isinstance dr_input int self _register dr get_driver dr_input elif isinstance dr_input c_void_p dr dr_input else raise ogrexception strid$ str type dr_input # making sure we get a valid pointer to the ogr driver if not dr raise ogrexception strid$ str dr_input self _ptr dr <|EOS|>',\n",
       " '<|endoftext|> fit self x y none strid$strid$strid$ self x smacof x metric self metric p self p init self init max_iter self max_iter verbose self verbose eps self eps return self <|EOS|>',\n",
       " '<|endoftext|> testscalewrongtype self strid$ print sys stderr self typestr strid$ scale tensor __dict__ self typestr strid$ tensor np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ strid$ self assertraises typeerror scale tensor # test type inplace_array3 any any any typemap <|EOS|>',\n",
       " '<|endoftext|> test_run_sql self self _test_run_sql strid$ should_run false @unittest skipif sqlparse is none and connection features requires_sqlparse_for_splitting strid$ @override_settings database_routers migratewhenfoorouter <|EOS|>',\n",
       " '<|endoftext|> test_simple_sitemap_section self strid$ response self client get strid$ expected_content strid$strid$numid$ numid$strid$utf numid$strid$http www sitemaps org schemas sitemap numid$ numid$strid$strid$ self base_url date today self assertxmlequal response content decode strid$ expected_content <|EOS|>',\n",
       " '<|endoftext|> ine_commentstrid$ <|EOS|>',\n",
       " '<|endoftext|> test_get_many self strid$ self cache set strid$ strid$ self cache set strid$ strid$ self cache set strid$ strid$ self cache set strid$ strid$ self assertequal self cache get_many strid$ strid$ strid$ self assertequal self cache get_many strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> ault cv clf stackingclassifier estimators strid$ logisticregression max_iter 1e4 strid$ linearsvc max_iter 1e4 # since iris is not shuffled a simple k fold would not contain the # numid$ classes during training clf fit x_iris y_iris @pytest mark parametrize strid$ stackingclassifier estimators strid$ logisticregression strid$ linearsvc random_state numid$ final_estimator logisticregression cv kfold shuffle true random_state numid$ load_breast_cancer return_x_y true stackingregressor estimators strid$ linearregression strid$ linearsvr random_state numid$ final_estimator linearregression cv kfold shuffle true random_state numid$ x_diabetes y_diabetes ids strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> test_f_oneway_vs_scipy_stats strid$strid$strid$ x1 np random randn numid$ numid$ x2 numid$ np random randn numid$ numid$ f pv stats f_oneway x1 x2 f2 pv2 f_oneway x1 x2 assert np allclose f f2 assert np allclose pv pv2 <|EOS|>',\n",
       " '<|endoftext|> testdegenerate self with self test_session rnd tf variable tf random_uniform numid$ numid$ vs tf create_partitioned_variables rnd get_shape numid$ numid$ rnd initialized_value tf initialize_all_variables run val tf concat numid$ vs eval rnd rnd eval self assertallclose rnd val self _testsavespec vs strid$ <|EOS|>',\n",
       " '<|endoftext|> void _gemv blas_order order blas_trans ta int m int n floating alpha floating a int lda floating x int incx floating beta floating y int incy nogil strid$strid$strid$ c <|EOS|>',\n",
       " '<|endoftext|> double loss self double p double y raise notimplementederror cp <|EOS|>',\n",
       " '<|endoftext|> __init__ self placeholders dataframe if len placeholders len dataframe columns numid$ raise valueerror strid$ format len dataframe columns len placeholders self _index_placeholder placeholders numid$ self _row_placeholders placeholders numid$ self _dataframe dataframe self _reset <|EOS|>',\n",
       " '<|endoftext|> ault array_like array_like opt_out array_like opt_out with assert_raises typeerror array_like opt_out with assert_raises typeerror opt_out array_like <|EOS|>',\n",
       " '<|endoftext|> test_float32 self self _test_grads_are_positive np float32 self _grid <|EOS|>',\n",
       " '<|endoftext|> test_intermeiary self r1 reporter objects create first_name strid$ last_name strid$ r2 reporter objects create first_name strid$ last_name strid$ a article objects create headline strid$ pub_date datetime numid$ numid$ numid$ w1 writer objects create reporter r1 article a position strid$ w2 writer objects create reporter r2 article a position strid$ self assertquerysetequal a writer_set select_related order_by strid$ strid$ strid$ strid$ strid$ lambda w unicode w reporter w position self assertequal w1 reporter r1 self assertequal w2 reporter r2 self assertequal w1 article a self assertequal w2 article a self assertquerysetequal r1 writer_set all strid$ strid$ lambda w unicode w reporter w position from datetime import datetime from django test import testcase from models import article category class m2mmultipletests testcase <|EOS|>',\n",
       " '<|endoftext|> test_group_ignored self pattern rstrid$ expected strid$ result regex_helper normalize pattern self assertequal result expected <|EOS|>',\n",
       " '<|endoftext|> double rk_cont3 rk_state state double a double b double c ctype <|EOS|>',\n",
       " '<|endoftext|> __conform__ self protocol if protocol is database prepareprotocol return str self from ctypes util import find_library from django conf import settings from django core exceptions import improperlyconfigured from django db backends sqlite3 base import from django db backends sqlite3 base import databasewrapper as sqlitedatabasewrapper _sqlite_extract _sqlite_date_trunc _sqlite_regexp from django contrib gis db backends spatialite client import spatialiteclient from django contrib gis db backends spatialite creation import spatialitecreation from django contrib gis db backends spatialite operations import spatialiteoperations class databasewrapper sqlitedatabasewrapper <|EOS|>',\n",
       " '<|endoftext|> check_arg_errcode result func cargs strid$strid$strid$ check_err arg_byref cargs return result <|EOS|>',\n",
       " '<|endoftext|> transformstring self instring strid$ extension to scanstring to modify matching text with modified tokens that may be returned from a parse action to use transformstring <|EOS|>',\n",
       " '<|endoftext|> ault return <|EOS|>',\n",
       " '<|endoftext|> aultstrid$sphinxdocstrid$ <|EOS|>',\n",
       " '<|endoftext|> test_logistic self random brng seed self seed actual random logistic loc numid$ scale numid$ numid$ size numid$ numid$ desired np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ assert_array_almost_equal actual desired decimal numid$ <|EOS|>',\n",
       " '<|endoftext|> learned_unigram_candidate_sampler true_classes num_true num_sampled unique range_max seed none name none strid$ samples a set of classes from a distribution learned during training this operation randomly samples a tensor of sampled classes `sampled_candidates` from the range of integers ` numid$ range_max ` the elements of `sampled_candidates` are drawn without replacement if `unique true` or with replacement if `unique false` from the base distribution the base distribution for this operation is constructed on the fly during training it is a unigram distribution over the target classes seen so far during training every integer in ` numid$ range_max ` begins with a weight of numid$ and is incremented by numid$ each time it is seen as a target class the base distribution is not saved to checkpoints so it is reset when the model is reloaded in addition this operation returns tensors `true_expected_count` and `sampled_expected_count` representing the number of times each of the target classes `true_classes` and the sampled classes `sampled_candidates` is expected to occur in an average tensor of sampled classes these values correspond to `q y x ` <|EOS|>',\n",
       " '<|endoftext|> ine_retstrid$successstrid$successstrid$success numid$ <|EOS|>',\n",
       " '<|endoftext|> get_flags_arch self vast_version self get_version gnu gnufcompiler gnu customize self version gnu get_version opt gnufcompiler get_flags_arch self self version vast_version return opt if __name__ strid$ from distutils import log log set_verbosity numid$ from scipy distutils fcompiler import new_fcompiler compiler new_fcompiler compiler strid$ compiler customize print compiler get_version # usr bin python strid$ process_file filename takes templated file xxx src and produces xxx file where xxx is pyf f90 or f using the following template rules strid$ denotes a template all function and subroutine blocks in a source file with names that contain strid$ will be replicated according to the rules in strid$ the number of comma separeted words in strid$ will determine the number of replicates strid$ may have two different forms named and short for example named p d s z c where anywhere inside a block strid$ will be replaced with strid$ strid$ strid$ and strid$ for each replicate of the block _c is already <|EOS|>',\n",
       " '<|endoftext|> testdoublescale self strid$ matrix n array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ strid$ series doublescale matrix numid$ self assertequals matrix numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ all true <|EOS|>',\n",
       " '<|endoftext|> ault_graph_stack get_ <|EOS|>',\n",
       " '<|endoftext|> chararray import chararray from numpy core records import find_duplicate from numpy core records import format_parser record recarray from numpy core records import fromarrays as recfromarrays ndarray numeric ndarray _byteorderconv numpy core records _byteorderconv _typestr ntypes _typestr import numpy ma from numpy ma import maskedarray masked nomask masked_array make_mask mask_or getmask getmaskarray filled from numpy ma core import <|EOS|>',\n",
       " '<|endoftext|> test_url_fail09 self with self assertraises templatesyntaxerror get_template strid$ @setup strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> _assert_no_warnings_context name none __tracebackhide__ true # hide traceback for py test with warnings catch_warnings record true as l warnings simplefilter strid$ yield if len l numid$ name_str strid$ name if name is not none else strid$ raise assertionerror strid$ name_str l <|EOS|>',\n",
       " '<|endoftext|> inclusion_only_unlimited_args_from_template args strid$strid$strid$ return strid$ strid$ strid$ join six text_type arg for arg in args inclusion_only_unlimited_args_from_template anything strid$ @register inclusion_tag strid$ takes_context true <|EOS|>',\n",
       " '<|endoftext|> test_inheritance35 self strid$strid$strid$ output render strid$ strid$ numid$ self assertequal output strid$ @setup inheritance_templates <|EOS|>',\n",
       " '<|endoftext|> __init__ self start end self start start self end end <|EOS|>',\n",
       " '<|endoftext|> ine_comments key return none @waflib configure conf <|EOS|>',\n",
       " '<|endoftext|> _media self if strid$ in self classes return forms media js strid$ settings admin_media_prefix return forms media media property _media <|EOS|>',\n",
       " '<|endoftext|> predict self x prediction np zeros x shape numid$ dtype np float64 norm numid$ for alpha estimator in self prediction alpha estimator predict x norm alpha if norm numid$ prediction norm return prediction strid$strid$strid$ strid$strid$strid$ from scikits learn decisiontree import decisiontree from scikits learn ensemble boosting import adaboost from scikits learn ensemble bagging import bagged import numpy as np import matplotlib pyplot as plt #a adaboost decisiontree minleafsize numid$ maxdepth numid$ nbins numid$ a bagged decisiontree minleafsize numid$ maxdepth numid$ nbins numid$ #a decisiontree minleafsize numid$ maxdepth numid$ nbins numid$ nsample numid$ #cov numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ cov numid$ numid$ numid$ numid$ x_bkg np concatenate np reshape np random multivariate_normal numid$ numid$ cov nsample numid$ nsample numid$ numid$ np reshape np random multivariate_normal numid$ numid$ cov nsample numid$ nsample numid$ numid$ x_sig np reshape np random multivariate_normal numid$ numid$ numid$ cov nsample nsample numid$ x np concatenate x_sig x_bkg y np append np ones nsample np ones nsample a fit x y baggs numid$ sample_fraction numid$ plt figure plt hist a predict x_bkg bins numid$ range numid$ numid$ label strid$ plt hist a predict x_sig bins numid$ range numid$ numid$ label strid$ alpha numid$ l plt legend l legendpatch set_alpha numid$ numid$ plt figure xs ys x_sig t xb yb x_bkg t plt plot xb yb strid$ label strid$ plt plot xs ys strid$ label strid$ alpha numid$ l plt legend l legendpatch set_alpha numid$ numid$ plt axis strid$ plt show strid$strid$strid$ # author pierre lafaye de micheaux stefan van der walt gael varoquaux # bertrand thirion alexandre gramfort # license bsd numid$ clause import types import numpy as np from scipy import linalg from base import baseestimator __all__ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> testfloatceil self strid$ tensor n array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ strid$ tensor floatceil tensor numid$ n testing assert_array_equal tensor n array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> _alloc_pid self strid$strid$strid$ pid self _next_pid self _next_pid numid$ return pid <|EOS|>',\n",
       " '<|endoftext|> inition for this gene strid$ the mutation rate for the gene is chosen randomly from the range mr_bounds strid$ if mrate strid$ try del self mutation_rate #remove local mrates and use gene classes mrate except attributeerror pass elif mrate strid$ self mutation_rate scipy rv uniform self mr_bounds numid$ self mr_bounds numid$ else self __class__ mutation_rate mrate <|EOS|>',\n",
       " '<|endoftext|> eval self func args kwargs strid$strid$strid$ if self cachedir is none return func args kwargs return self cache func args kwargs # # private `object` interface # <|EOS|>',\n",
       " '<|endoftext|> make_docs_from_model_tests output_dir from django conf import settings # manually set installed_apps to point to the test app settings installed_apps runtests app_name for model_name in runtests get_test_models mod meta get_app model_name # clean up the title and blurb title blurb mod __doc__ strip split strid$ numid$ blurb strid$ blurb strip replace strid$ strid$ api_usage mod api_tests # get the source code of the model without the docstring or the # api_tests variable model_source inspect getsource mod model_source model_source replace mod __doc__ strid$ model_source model_source replace mod api_tests strid$ model_source model_source replace strid$ strid$ model_source model_source replace strid$ strid$ model_source model_source strip # run this through the template system t template template model_doc_template c template context locals html t render c file_name os path join output_dir strid$ model_name strid$ try fp open file_name strid$ except ioerror sys stderr write strid$ file_name continue else fp write html fp close if __name__ strid$ import sys make_docs_from_model_tests sys argv numid$ strid$ numid$ one to one relationships to <|EOS|>',\n",
       " '<|endoftext|> testallvaluespresent self with self test_session as sess values_queue tf fifoqueue numid$ dtypes tf float32 shapes numid$ numid$ _enqueue_vector sess values_queue numid$ numid$ _enqueue_vector sess values_queue numid$ numid$ numid$ numid$ _enqueue_vector sess values_queue numid$ numid$ numid$ _enqueue_vector sess values_queue numid$ numid$ numid$ numid$ values values_queue dequeue mean update_op tf contrib metrics streaming_mean values sess run tf initialize_local_variables for _ in range numid$ sess run update_op self assertalmostequal numid$ numid$ sess run mean numid$ <|EOS|>',\n",
       " '<|endoftext|> __unicode__ self return self name class city models model name models charfield max_length numid$ point models pointfield objects models geomanager <|EOS|>',\n",
       " '<|endoftext|> ault hook basic_session_run_hooks checkpointsaverhook self model_dir save_secs numid$ scaffold self scaffold hook begin self scaffold finalize with tf session as sess sess run self scaffold init_op mon_sess monitored_session monitoredsession sess hook mon_sess run self train_op mon_sess run self train_op hook end sess self assertequal numid$ tf contrib framework load_variable self model_dir self global_step name class summarysaverhooktest tf test testcase <|EOS|>',\n",
       " '<|endoftext|> reduce self target axis numid$ strid$strid$strid$ m getmask target if m is none t filled target return masked_array umath maximum reduce t axis else t umath maximum reduce filled target maximum_fill_value target axis m umath logical_and reduce m axis return masked_array t m get_fill_value target <|EOS|>',\n",
       " '<|endoftext|> ault of numid$ means the module of the immediate caller higher values are useful for utility routines that want to initialize `nosetester` objects on behalf of other code strid$ <|EOS|>',\n",
       " '<|endoftext|> test_no_directory_traversal self with self assertraises templatedoesnotexist self engine get_template strid$ <|EOS|>',\n",
       " '<|endoftext|> double_t diff_w numid$ numid$ # update statistics up to new_pos # # given that # sum_left x sum_right x sum_total x # and that sum_total is known we are going to update # label_count_left from the direction that require the least amount # of computations i e from pos to new_pos or from end to new_po if new_pos pos end new_pos for p in range pos new_pos i samples p if sample_weight null w sample_weight i for k in range n_outputs sum_left k w y i y_stride k diff_w w else self reverse_reset for p in range end numid$ new_pos numid$ numid$ i samples p if sample_weight null w sample_weight i for k in range n_outputs sum_left k w y i y_stride k diff_w w for k in range n_outputs sum_right k sum_total k sum_left k self weighted_n_left diff_w self weighted_n_right diff_w self pos new_pos c <|EOS|>',\n",
       " '<|endoftext|> set_x self value strid$ self _cs setordinate numid$ numid$ value <|EOS|>',\n",
       " '<|endoftext|> ault false help strid$ action strid$ if self failfast false parser add_option strid$ strid$ dest strid$ <|EOS|>',\n",
       " '<|endoftext|> test_has_listeners self self assertfalse a_signal has_listeners self assertfalse a_signal has_listeners sender object receiver_1 callable a_signal connect receiver_1 self asserttrue a_signal has_listeners self asserttrue a_signal has_listeners sender object a_signal disconnect receiver_1 self assertfalse a_signal has_listeners self assertfalse a_signal has_listeners sender object class receivertestcase unittest testcase strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> test_timefield self timefields can parse dates in the <|EOS|>',\n",
       " '<|endoftext|> ault_graph is none # todo mrry perhaps log that the <|EOS|>',\n",
       " '<|endoftext|> __init__ self mult numid$ numid$ self mult mult <|EOS|>',\n",
       " '<|endoftext|> aults to numid$ strid$ # if a geos geometry isnstrid$gpolyline may only initialize on geos linestring linearring and or polygon geometries # getting the envelope for automatic zoom determination self envelope geom envelope self color self weight self opacity color weight opacity super gpolyline self __init__ @property <|EOS|>',\n",
       " '<|endoftext|> islong_complex var if not iscomplex var return numid$ return get_kind var strid$ <|EOS|>',\n",
       " '<|endoftext|> filter_py_files self sources return self filter_files sources strid$ <|EOS|>',\n",
       " '<|endoftext|> _model_fn self x y return models get_rnn_model self rnn_size self cell_type self input_op_fn models linear_regression x y strid$strid$strid$ # copyright numid$ present scikit flow authors all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license from __future__ import division print_function absolute_import from sklearn base import classifiermixin regressormixin from skflow estimators base import tensorflowestimator from skflow import models class tensorflowrnnclassifier tensorflowestimator classifiermixin strid$ tensorflow rnn classifier model parameters n_classes number of classes in the target tf_master tensorflow master empty string is <|EOS|>',\n",
       " '<|endoftext|> library_dir_option self dir return strid$ dir <|EOS|>',\n",
       " '<|endoftext|> get_flags_opt self if self get_version strid$ # with this compiler version building fortran blas lapack # with o3 caused failures in lib lapack heevr syevr tests opt strid$ else opt strid$ opt append strid$ return opt <|EOS|>',\n",
       " '<|endoftext|> get_dependencies sources #xxx scan sources for include statements return _get_headers _get_directories sources <|EOS|>',\n",
       " '<|endoftext|> ault tf session as sess global_step_tensor tf contrib framework create_global_step mock_mon fakemonitor mock_mon2 fakemonitor mon_sess monitored_session monitoredsession sess sess monitors mock_mon mock_mon2 global_step_tensor global_step_tensor a_tensor tf constant numid$ name strid$ tf constant numid$ name strid$ mock_mon requested_tensors strid$ mock_mon2 requested_tensors strid$ sess run tf initialize_all_variables output mon_sess run fetches a_tensor self assertequal output numid$ self assertequal mock_mon output strid$ numid$ self assertequal mock_mon2 output strid$ numid$ if __name__ strid$ tf test main # copyright numid$ the tensorflow authors all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # strid$strid$strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function from tensorflow python framework import constant_op from tensorflow python framework import dtypes from tensorflow python framework import ops from tensorflow python ops import array_ops from tensorflow python ops import logging_ops from tensorflow python ops import math_ops from tensorflow python ops import tensor_array_ops __all__ strid$ <|EOS|>',\n",
       " '<|endoftext|> confusion_matrix y_true y_pred labels none strid$ compute confusion matrix to evaluate the accuracy of a classification by <|EOS|>',\n",
       " '<|endoftext|> fft a n none axis numid$ norm none strid$strid$ortho optional versionadded numid$ numid$ numid$ normalization mode see `numpy fft` <|EOS|>',\n",
       " '<|endoftext|> test_error_dict_copy self e errordict e strid$ errorlist validationerror message strid$ params strid$ numid$ validationerror message strid$ params strid$ numid$ e_copy copy copy e self assertequal e e_copy self assertequal e as_data e_copy as_data e_deepcopy copy deepcopy e self assertequal e e_deepcopy self assertequal e as_data e_copy as_data # coding utf numid$ from __future__ import unicode_literals from django core management base import basecommand commanderror from django db import connections <|EOS|>',\n",
       " '<|endoftext|> setup self self col_init # shard numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ # shard numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ # shard numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ self row_wts numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ self col_wts numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ self _wals_inputs sparse_input # values of factor shards after running one iteration of row and column # updates self _row_factors_0 numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ self _row_factors_1 numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ self _col_factors_0 numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ self _col_factors_1 numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ self _col_factors_2 numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> _add_integer_aliases seen_bits set for i_ctype u_ctype in zip _int_ctypes _uint_ctypes i_info _concrete_typeinfo i_ctype u_info _concrete_typeinfo u_ctype bits i_info bits # same for both for info charname intname intname in i_info strid$ bits numid$ strid$ bits strid$ bits u_info strid$ bits numid$ strid$ bits strid$ bits if bits not in seen_bits # sometimes two different types have the same number of bits # if so the one iterated over first takes precedence alltypes intname info type sctypedict intname info type sctypedict intname info type sctypedict charname info type sctypena intname info type sctypena charname info type sctypena info type intname sctypena info char intname seen_bits add bits _add_integer_aliases # we use these later void alltypes strid$ # # rework the python names so that float and complex and int are consistent # with python usage # <|EOS|>',\n",
       " '<|endoftext|> infer restore_checkpoint_path output_dict feed_dict none return run_feeds output_dict output_dict feed_dicts feed_dict if feed_dict is not none else none restore_checkpoint_path restore_checkpoint_path numid$ # copyright numid$ google inc all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # strid$strid$strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function import math import tensorflow as tf class conv3dtest tf test testcase <|EOS|>',\n",
       " '<|endoftext|> dtype_t p self p c <|EOS|>',\n",
       " '<|endoftext|> double array_data c <|EOS|>',\n",
       " '<|endoftext|> test_vonmises self vals self rg vonmises numid$ numid$ numid$ numid$ assert_ len vals numid$ <|EOS|>',\n",
       " '<|endoftext|> __mod__ self other return self binary_op other <|EOS|>',\n",
       " '<|endoftext|> test03c_layer_references self strid$ source ds_list numid$ # see ticket #numid$ <|EOS|>',\n",
       " '<|endoftext|> p self strid$strid$strid$ if self date minute numid$ and self date hour numid$ return strid$ if self date minute numid$ and self date hour numid$ return strid$ return strid$ self f self a <|EOS|>',\n",
       " '<|endoftext|> ault filling value for the first argument numid$ filly <|EOS|>',\n",
       " '<|endoftext|> initialize self pass <|EOS|>',\n",
       " '<|endoftext|> plot_batch_times all_times n_features all_batch_sizes data plt figure plot_results all_batch_sizes all_times strid$ label strid$ plot_results all_batch_sizes all_times strid$ label strid$ plot_results all_batch_sizes all_times strid$ label strid$ plt legend loc strid$ plt suptitle strid$ n_features data shape numid$ data shape numid$ plt xlabel strid$ plt ylabel strid$ <|EOS|>',\n",
       " '<|endoftext|> ault strid$ strid$ traceback most recent call last attributeerror this querydict instance is immutable q urlencode strid$ strid$strid$__main__strid$strid$ numid$ or lookups to perform an or lookup or a lookup that combines ands and ors use the ``complex`` keyword argument and pass it an expression of clauses using the variable ``django core meta q`` strid$ from django core import meta class article meta model headline meta charfield maxlength numid$ pub_date meta datetimefield class meta ordering strid$ <|EOS|>',\n",
       " '<|endoftext|> string_concat strings strid$strid$ lazy variant of string concatenation needed for translations that are constructed from multiple parts handles lazy strings and non strings by first turning all arguments to strings before joining them strid$strid$strid$unit tests for reverse url lookup from django core urlresolvers import reverse_helper noreversematch import re test_data strid$ strid$ numid$ strid$ strid$ strid$ strid$ noreversematch strid$ strid$ noreversematch strid$ strid$ strid$ numid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ noreversematch strid$ strid$ noreversematch strid$ strid$ strid$ noreversematch strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ noreversematch strid$ strid$ strid$ strid$ strid$ noreversematch strid$ strid$ strid$ noreversematch strid$ strid$ strid$ noreversematch strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> int error_check numid$ c <|EOS|>',\n",
       " '<|endoftext|> have_f90c self strid$strid$strid$ simple_fortran_subroutine strid$strid$strid$ config_cmd self get_config_cmd flag config_cmd try_compile simple_fortran_subroutine lang strid$ return flag <|EOS|>',\n",
       " '<|endoftext|> test_get_for_models_empty_cache self # empty cache with self assertnumqueries numid$ cts contenttype objects get_for_models contenttype foowithurl self assertequal cts contenttype contenttype objects get_for_model contenttype foowithurl contenttype objects get_for_model foowithurl <|EOS|>',\n",
       " '<|endoftext|> check_set_item_operator_equal self level numid$ code strid$strid$strid$ a inline_tools inline code assert a numid$ numid$ numid$ # returned value should only have a single refcount assert sys getrefcount a numid$ <|EOS|>',\n",
       " '<|endoftext|> push_item name rest if not name return name role parse_item_name name items append name list rest role del rest current_func none rest for line in content if not line strip continue m self _name_rgx match line if m and line m end strip startswith strid$ push_item current_func rest current_func line line m end line m end rest line split strid$ numid$ numid$ strip if not rest numid$ rest elif not line startswith strid$ push_item current_func rest current_func none if strid$ in line for func in line split strid$ push_item func elif line strip current_func line elif current_func is not none rest append line strip push_item current_func rest return items <|EOS|>',\n",
       " '<|endoftext|> testinferenceconstruction self input_data numid$ numid$ numid$ numid$ # node numid$ numid$ numid$ numid$ numid$ # node numid$ params tensor_forest foresthparams num_classes numid$ num_features numid$ num_trees numid$ max_nodes numid$ fill graph_builder tensor_forest randomforestgraphs params graph graph_builder inference_graph input_data self asserttrue isinstance graph tf tensor if __name__ strid$ googletest main # copyright numid$ google inc all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # strid$strid$strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function import sys import tensorflow as tf flags tf app flags flags tf app flags <|EOS|>',\n",
       " '<|endoftext|> check_session_cookie_httponly app_configs kwargs errors if not settings session_cookie_httponly if _session_app errors append w013 if _session_middleware errors append w014 if len errors numid$ errors w015 return errors <|EOS|>',\n",
       " '<|endoftext|> test_i18n_language_english_ <|EOS|>',\n",
       " '<|endoftext|> testdequeuemanywithtensorparameter self with self test_session # <|EOS|>',\n",
       " '<|endoftext|> ine_string strid$ strid$ strid$ flags <|EOS|>',\n",
       " '<|endoftext|> ault_parts models manytomanyfield part optional_parts models manytomanyfield part related_name strid$ class meta ordering strid$ <|EOS|>',\n",
       " '<|endoftext|> test_process_request_middleware_exception self pre_middleware testmiddleware middleware requestmiddleware post_middleware testmiddleware self _add_middleware post_middleware self _add_middleware middleware self _add_middleware pre_middleware self assert_exceptions_handled strid$ # check that the right middleware methods have been invoked self assert_middleware_usage pre_middleware true false false true false self assert_middleware_usage middleware true false false true false self assert_middleware_usage post_middleware false false false true false <|EOS|>',\n",
       " '<|endoftext|> test_simple_sitemap_section self strid$ response self client get strid$ expected_content strid$strid$numid$ numid$strid$utf numid$strid$http www sitemaps org schemas sitemap numid$ numid$strid$strid$ self base_url date today self assertxmlequal response content decode strid$ expected_content <|EOS|>',\n",
       " '<|endoftext|> _get_loss_function self strid$strid$strid$ raise notimplementederror strid$ <|EOS|>',\n",
       " '<|endoftext|> select_k_best p_values k strid$strid$strid$ assert k len p_values valueerror strid$ strid$ k len p_values #alpha stats scoreatpercentile p_values numid$ k len p_values alpha np sort p_values k return p_values alpha <|EOS|>',\n",
       " '<|endoftext|> ault none the number of jobs to run in parallel for ``fit`` ``none`` means numid$ unless in a obj `joblib parallel_backend` context `` numid$`` means using all processors see term `glossary n_jobs ` for more details attributes estimators_ list of regressors the collection of fitted sub estimators as <|EOS|>',\n",
       " '<|endoftext|> aultout self self _add_op name polymorphic <|EOS|>',\n",
       " '<|endoftext|> ault numid$ the total number of features these comprise `n_informative` informative features `n_redundant` redundant features `n_repeated` dupplicated features and `n_features n_informative n_redundant n_repeated` useless features drawn at random n_informative int optional <|EOS|>',\n",
       " '<|endoftext|> test_datetimefield_1 self f datetimefield self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ f clean datetime date numid$ numid$ numid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ f clean datetime datetime numid$ numid$ numid$ numid$ numid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ numid$ f clean datetime datetime numid$ numid$ numid$ numid$ numid$ numid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ numid$ numid$ f clean datetime datetime numid$ numid$ numid$ numid$ numid$ numid$ numid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertequal datetime datetime numid$ numid$ numid$ numid$ numid$ f clean strid$ self assertraiseserrorwithmessage validationerror strid$ f clean strid$ self assertraiseserrorwithmessage validationerror strid$ f clean strid$ <|EOS|>',\n",
       " '<|endoftext|> double y numid$ numid$ c <|EOS|>',\n",
       " '<|endoftext|> find_lib_dir self library_dirs lib_match rstrid$ strid$ cmd self f90_compiler strid$ exit_status output run_command cmd if not exit_status libs re findall lib_match output if libs library_dirs string split libs numid$ strid$ self is_available # force version calculation compiler_home os path dirname library_dirs numid$ library_dirs append os path join compiler_home self version strid$ return library_dirs <|EOS|>',\n",
       " '<|endoftext|> ine_macros strid$ numid$ depends depends return config if __name__ strid$ from numpy distutils core import setup setup configuration top_path strid$ todict strid$strid$strid$ print __doc__ import pylab as pl from sklearn datasets import make_classification pl figure figsize numid$ numid$ pl subplot numid$ pl title strid$ x1 y1 make_classification n_features numid$ n_redundant numid$ n_informative numid$ n_clusters_per_class numid$ pl scatter x1 numid$ x1 numid$ marker strid$ c y1 pl subplot numid$ pl title strid$ x1 y1 make_classification n_features numid$ n_redundant numid$ n_informative numid$ n_clusters_per_class numid$ pl scatter x1 numid$ x1 numid$ marker strid$ c y1 pl subplot numid$ pl title strid$ x2 y2 make_classification n_features numid$ n_redundant numid$ n_informative numid$ pl scatter x2 numid$ x2 numid$ marker strid$ c y2 pl subplot numid$ pl title strid$ x1 y1 make_classification n_features numid$ n_redundant numid$ n_informative numid$ n_clusters_per_class numid$ n_classes numid$ pl scatter x1 numid$ x1 numid$ marker strid$ c y1 pl show strid$strid$strid$ print __doc__ import numpy as np import pylab as pl from sklearn svm import svc from sklearn preprocessing import scaler from sklearn datasets import load_iris from sklearn cross_validation import stratifiedkfold from sklearn grid_search import gridsearchcv iris_dataset load_iris x y iris_dataset data iris_dataset target # it is usually a good idea to scale the data for svm training # we are cheating a bit in this example in scaling all of the data # instead of fitting the transformation on the trainingset and # just applying it on the test set scaler scaler x scaler fit_transform x # for an initial search a logarithmic grid with basis # numid$ is often helpful using a basis of numid$ a finer # tuning can be achieved but at a much higher cost c_range numid$ np arange numid$ numid$ gamma_range numid$ np arange numid$ numid$ param_grid dict gamma gamma_range c c_range grid gridsearchcv svc param_grid param_grid cv stratifiedkfold y y k numid$ grid fit x y print strid$ grid best_estimator # plot the scores of the grid # grid_scores_ contains parameter settings and scores score_dict grid grid_scores_ # we extract just the scores scores x numid$ for x in score_dict scores np array scores reshape len c_range len gamma_range # make a nice figure pl figure figsize numid$ numid$ pl imshow scores interpolation strid$ pl xlabel strid$ pl ylabel strid$ pl colorbar pl xticks np arange len gamma_range gamma_range rotation numid$ pl yticks np arange len c_range c_range pl show strid$ rbf svm parameters this example illustrates the effect of the parameters `gamma` and `c` of the rbf kernel svm intuitively the `gamma` parameter <|EOS|>',\n",
       " '<|endoftext|> ined by ``` x_1 x_n in r n numid$ sum_j x_j numid$ and x_j numid$ for all j ``` the distribution has hyperparameters `alpha alpha_1 alpha_k ` and probability mass function prob ```prob x numid$ beta alpha prod_j x_j alpha_j numid$ ``` where `beta x prod_j gamma x_j gamma sum_j x_j ` is the multivariate beta function this class provides methods to create indexed batches of dirichlet distributions if the provided `alpha` is rank numid$ or higher for every fixed set of leading dimensions the last dimension represents one single dirichlet distribution when calling distribution functions e g `dist prob x ` `alpha` and `x` are broadcast to the same shape if possible in all cases the last dimension of alpha x represents single dirichlet distributions #### examples ```python alpha numid$ numid$ numid$ dist dirichlet alpha ``` creates a numid$ class distribution with the 3rd class is most likely to be drawn the distribution functions can be evaluated on x ```python # x same shape as alpha x numid$ numid$ numid$ dist prob x # shape # alpha will be broadcast to numid$ numid$ numid$ numid$ numid$ numid$ to match x x numid$ numid$ numid$ numid$ numid$ numid$ dist prob x # shape numid$ # alpha will be broadcast to shape numid$ numid$ numid$ to match x x # shape numid$ numid$ numid$ dist prob x # shape numid$ numid$ ``` creates a numid$ batch of numid$ class distributions ```python alpha numid$ numid$ numid$ numid$ numid$ numid$ # shape numid$ numid$ dist dirichlet alpha # x will be broadcast to numid$ numid$ numid$ numid$ numid$ numid$ to match alpha x numid$ numid$ numid$ dist prob x # shape numid$ ``` strid$ <|EOS|>',\n",
       " '<|endoftext|> ield instatefield instateselect inphonenumberfield from django test import simpletestcase class inlocalflavortests simpletestcase <|EOS|>',\n",
       " '<|endoftext|> loadtestsfromtestcase self testcaseclass strid$strid$strid$ if issubclass testcaseclass suite testsuite raise typeerror strid$ strid$ testcasenames self gettestcasenames testcaseclass if not testcasenames and hasattr testcaseclass strid$ testcasenames strid$ loaded_suite self suiteclass map testcaseclass testcasenames return loaded_suite <|EOS|>',\n",
       " '<|endoftext|> __setattr__ self key val raise valueerror strid$ <|EOS|>',\n",
       " '<|endoftext|> ine the numeric type objects this module is designed so strid$ is safe exported symbols include dictionary with all registered number types including aliases typedict numeric type objects bool int8 int16 int32 int64 uint8 uint16 uint32 uint64 float32 double64 complex32 complex64 numeric type classes numerictype booleantype signedtype unsignedtype integraltype signedintegraltype unsignedintegraltype floatingtype complextype $id numerictypes py v numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ jaytmiller exp $ strid$ max_align numid$ max_int_size numid$ import numpy lp64 numpy intp numid$ itemsize numid$ hasuint64 numid$ try numpy int64 numid$ except hasuint64 numid$ #from typeconv import typeconverters as _typeconverters #import numinclude #from _numerictype import _numerictype typedict import types as _types import copy as _copy import sys as _sys # enumeration of numarray type codes typedict _tany numid$ _tbool numid$ _tint8 numid$ _tuint8 numid$ _tint16 numid$ _tuint16 numid$ _tint32 numid$ _tuint32 numid$ _tint64 numid$ _tuint64 numid$ _tfloat32 numid$ _tfloat64 numid$ _tcomplex32 numid$ _tcomplex64 numid$ _tobject numid$ <|EOS|>',\n",
       " '<|endoftext|> isblank line return line strip strid$ <|EOS|>',\n",
       " '<|endoftext|> check_include_trailing_dollar pattern strid$strid$strid$ regex_pattern pattern regex pattern if regex_pattern endswith strid$ and not regex_pattern endswith strid$ warning warning strid$ strid$ strid$ format describe_pattern pattern id strid$ return warning else return <|EOS|>',\n",
       " '<|endoftext|> int i ## for i from numid$ i nnz ## pair x i ## if pair idx wdim ## sum w pair idx pair val ## return sum ## c <|EOS|>',\n",
       " '<|endoftext|> _compute_kernel self x strid$strid$strid$ if hasattr self strid$ # in the case of precomputed kernel given as a function we # have to compute explicitly the kernel matrix x np asanyarray self kernel_function x self __xfit dtype np float64 order strid$ return x <|EOS|>',\n",
       " '<|endoftext|> test_list_display_first_item_same_as_list_editable_first_item self strid$strid$strid$ class productadmin modeladmin list_display strid$ strid$ strid$ list_editable strid$ strid$ list_display_links strid$ self assertisvalid productadmin validationtestmodel <|EOS|>',\n",
       " '<|endoftext|> test_emailfield_min_max_length self f emailfield min_length numid$ max_length numid$ self assertwidgetrendersto f strid$ with self assertraisesmessage validationerror strid$ f clean strid$ self assertequal strid$ f clean strid$ with self assertraisesmessage validationerror strid$ f clean strid$ # coding utf numid$ from __future__ import unicode_literals import pickle from django core files uploadedfile import simpleuploadedfile from django forms import filefield validationerror from django test import simpletestcase class filefieldtest simpletestcase <|EOS|>',\n",
       " '<|endoftext|> ined_types <|EOS|>',\n",
       " '<|endoftext|> uniforms py_ssize_t n c <|EOS|>',\n",
       " '<|endoftext|> db_type self connection return strid$ class daterangefield rangefield base_field models datefield range_type daterange form_field forms daterangefield <|EOS|>',\n",
       " '<|endoftext|> ev_graph parsefromstring ev graph_ <|EOS|>',\n",
       " '<|endoftext|> ault numid$ suffix2 models integerfield blank true <|EOS|>',\n",
       " '<|endoftext|> check_1d_array self a array numid$ numid$ numid$ numid$ try vsplit a numid$ assert numid$ except valueerror pass <|EOS|>',\n",
       " '<|endoftext|> expr_to_filename expr strid$strid$strid$ import md5 base strid$ return base md5 new expr hexdigest <|EOS|>',\n",
       " '<|endoftext|> inline code arg_names local_dict none global_dict none force numid$ compiler strid$ verbose numid$ support_code none customize none type_factories none auto_downcast numid$ kw strid$ inline c c code within python scripts inline compiles and executes c c code on the fly variables in the local and global python scope are also available in the c c code values are passed to the c c code by assignment much like variables passed are passed into a standard python function values are returned from the c c code through a special argument called return_val also the contents of mutable objects can be changed within the c c code and the changes remain after the c code exits and returns to python inline has quite a few options as listed below also the keyword arguments for distutils extension modules are accepted to specify extra information needed for compiling code string a string of valid c code it should not specify a return statement instead it should assign results that need to be returned to python in the return_val arg_names list of strings a list of python variable names that should be transferred from python into the c c code local_dict optional dictionary if specified it is a dictionary of values that should be used as the local scope for the c c code if local_dict is not specified the local dictionary of the calling function is used global_dict optional dictionary if specified it is a dictionary of values that should be used as the global scope for the c c code if global_dict is not specified the global dictionary of the calling function is used force optional numid$ or numid$ <|EOS|>',\n",
       " '<|endoftext|> test_check_median_02 self a np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ a pad a t numid$ strid$ t b np array numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ assert_array_equal a b <|EOS|>',\n",
       " '<|endoftext|> ault datetime now <|EOS|>',\n",
       " '<|endoftext|> testreferenceinput self g ops graph ref_t nonref_t _apply_op g strid$ types float32_ref types float32 name strid$ self assertprotoequals strid$ ref_t op node_ <|EOS|>',\n",
       " '<|endoftext|> ault a single value is returned if ``dfnum`` ``dfden`` and ``nonc`` are all scalars otherwise ``np broadcast dfnum dfden nonc size`` samples are drawn returns out ndarray or scalar drawn samples from the parameterized noncentral fisher distribution notes when calculating the power of an experiment power probability of rejecting the null hypothesis when a specific alternative is true the non central f statistic becomes important when the null hypothesis is true the f statistic follows a central f distribution when the null hypothesis is not true then it follows a non central f statistic references numid$ weisstein eric w strid$ from mathworld a wolfram web resource http mathworld wolfram com noncentralf distribution html numid$ wikipedia strid$ https en wikipedia org wiki noncentral_f distribution examples in a study testing for a specific alternative to the null hypothesis requires use of the noncentral f distribution we need to calculate the area in the tail of the distribution that exceeds the value of the f distribution for the null hypothesis we ll plot the two probability distributions for comparison dfnum numid$ # between group deg of freedom dfden numid$ # within groups degrees of freedom nonc numid$ numid$ nc_vals np random noncentral_f dfnum dfden nonc numid$ nf np histogram nc_vals bins numid$ density true c_vals np random f dfnum dfden numid$ f np histogram c_vals bins numid$ density true import matplotlib pyplot as plt plt plot f numid$ numid$ f numid$ plt plot nf numid$ numid$ nf numid$ plt show strid$ c <|EOS|>',\n",
       " '<|endoftext|> result_list cl res list results cl return strid$ cl strid$ list result_headers cl strid$ list results cl result_list inclusion_tag strid$ result_list #@inclusion_tag strid$ <|EOS|>',\n",
       " '<|endoftext|> __init__ self func kwargs kwargs set <|EOS|>',\n",
       " '<|endoftext|> get_manipulator_field_objs self return curry formfields xmllargetextfield schema_path self schema_path class foreignkey field empty_strings_allowed false <|EOS|>',\n",
       " '<|endoftext|> test_clear self strid$ self cache clear <|EOS|>',\n",
       " '<|endoftext|> double sample_weight c <|EOS|>',\n",
       " '<|endoftext|> test_localized_datetimefield_with_inputformat self strid$ f forms datetimefield input_formats strid$ strid$ localize true # parse a date in an unaccepted format get an error self assertraises forms validationerror f clean strid$ self assertraises forms validationerror f clean strid$ # parse a date in a valid format get a parsed result result f clean strid$ self assertequal result datetime numid$ numid$ numid$ numid$ numid$ numid$ # # check that the parsed result does a round trip to the same format text f widget _format_value result self assertequal text strid$ # parse a date in a valid format get a parsed result result f clean strid$ self assertequal result datetime numid$ numid$ numid$ numid$ numid$ # check that the parsed result does a round trip to <|EOS|>',\n",
       " '<|endoftext|> test_session_key_is_read_only self <|EOS|>',\n",
       " '<|endoftext|> is_private prefix base strid$strid$ strid$privatestrid$a bstrid$my_funcstrid$____strid$_my_funcstrid$someclassstrid$__init__strid$sometypostrid$__init_strid$x y zstrid$_strid$_x y zstrid$__strid$strid$strid$strid$ warnings warn strid$ strid$ deprecationwarning stacklevel numid$ return base numid$ strid$ and not base numid$ strid$ base numid$ <|EOS|>',\n",
       " '<|endoftext|> test_typedchoicefield_1 self f typedchoicefield choices numid$ strid$ numid$ strid$ coerce int self assertequal numid$ f clean strid$ self assertraisesmessage validationerror strid$ f clean strid$ <|EOS|>',\n",
       " '<|endoftext|> object cont0_array rk_state state rk_cont0 func object size c <|EOS|>',\n",
       " '<|endoftext|> cross_correlation self x1 x2 return np zeros x1 shape numid$ x2 shape numid$ strid$strid$strid$ # authors jan hendrik metzen jhm@informatik uni bremen de # # license bsd numid$ clause import numpy as np from scipy linalg import cholesky cho_solve solve from scipy optimize import fmin_l_bfgs_b from sklearn base import baseestimator class gaussianprocessregression baseestimator strid$ gaussian process regression gpr the implementation is based on algorithm numid$ numid$ of ``gaussian processes for machine learningstrid$ gpml by rasmussen and williams in addition to standard sklearn estimators gaussianprocessregression allows prediction without prior fitting based on the gp prior provides an additional method sample x which evaluates samples drawn from the gpr prior or posterior at given inputs exposes a method log_marginal_likelihood theta which can be used externally for other ways of selecting hyperparamters e g via markov chain monte carlo parameters kernel kernel object the kernel specifying the covariance function of the gp y_err float optional <|EOS|>',\n",
       " '<|endoftext|> _maybe_launch_in_process_server self master strid$ launches the in process tensorflow server if needed if strid$ is strid$ an in memory tensorflow master is launched todo sherrym add support for taking a cluster <|EOS|>',\n",
       " '<|endoftext|> options self parser env os environ plugin options self parser env # test doctests in strid$ files directories standard plugin <|EOS|>',\n",
       " '<|endoftext|> test_remote_login_url self quoted_next urlquote strid$ expected strid$ quoted_next self assertloginurlequals expected @override_settings login_url strid$ <|EOS|>',\n",
       " '<|endoftext|> ault_db_alias settings_dict strid$ strid$ msg strid$ strid$ with self assertraisesmessage improperlyconfigured msg conns <|EOS|>',\n",
       " '<|endoftext|> test_5d self level numid$ d numid$ k numid$ mode strid$ nframes int 1e2 #seed numid$ self _create_model_and_run_em d k mode nframes class test_datasets emtest strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> test_basic self authors author objects annotate sha256_alias sha256 strid$ values_list strid$ flat true order_by strid$ self assertsequenceequal authors strid$ strid$ strid$ strid$ strid$ if connection features interprets_empty_strings_as_nulls else none <|EOS|>',\n",
       " '<|endoftext|> _validate_n_bins self n_features ignored strid$strid$strid$ orig_bins self n_bins if isinstance orig_bins numbers number if not isinstance orig_bins np int raise valueerror strid$ strid$ format kbinsdiscretizer __name__ type orig_bins __name__ if orig_bins numid$ raise valueerror strid$ strid$ format kbinsdiscretizer __name__ orig_bins return np ones n_features orig_bins n_bins check_array orig_bins dtype np int copy true ensure_2d false if n_bins ndim numid$ or n_bins shape numid$ n_features raise valueerror strid$ strid$ bad_nbins_value n_bins numid$ n_bins orig_bins bad_nbins_value ignored false violating_indices np where bad_nbins_value numid$ if violating_indices shape numid$ numid$ indices strid$ join str i for i in violating_indices raise valueerror strid$ strid$ strid$ format kbinsdiscretizer __name__ indices n_bins ignored numid$ return n_bins <|EOS|>',\n",
       " '<|endoftext|> test_iter_object_arrays_basic # check that object arrays work obj strid$ numid$ strid$ strid$ a np array numid$ numid$ numid$ none obj none dtype strid$ rc sys getrefcount obj # need to allow references for object arrays assert_raises typeerror nditer a assert_equal sys getrefcount obj rc i nditer a strid$ strid$ vals x for x in i assert_equal np array vals dtype strid$ a vals i x none numid$ assert_equal sys getrefcount obj rc i nditer a reshape numid$ numid$ t strid$ strid$ strid$ order strid$ assert_ i iterationneedsapi vals x for x in i assert_equal np array vals dtype strid$ a reshape numid$ numid$ ravel order strid$ vals i x none numid$ assert_equal sys getrefcount obj rc i nditer a reshape numid$ numid$ t strid$ strid$ strid$ order strid$ for x in i x none vals i x none numid$ assert_equal sys getrefcount obj rc numid$ assert_equal a np array none numid$ dtype strid$ <|EOS|>',\n",
       " '<|endoftext|> cumprod a axis numid$ dtype none strid$strid$strid$ try cumprod a cumprod except attributeerror return _wrapit a strid$ axis dtype return cumprod axis dtype <|EOS|>',\n",
       " '<|endoftext|> name self return self _name @property <|EOS|>',\n",
       " '<|endoftext|> assert_approx_equal actual desired significant numid$ err_msg strid$ verbose numid$ strid$ raise an assertion if two items are not equal i think this should be part of unittest py approximately equal is <|EOS|>',\n",
       " '<|endoftext|> handle_inspection self from django db import connection get_introspection_module import keyword introspection_module get_introspection_module table2model lambda table_name table_name title replace strid$ strid$ cursor connection cursor yield strid$ yield strid$ yield strid$ yield strid$ yield strid$ yield strid$ yield strid$ yield strid$ yield strid$ yield strid$ yield strid$ for table_name in introspection_module get_table_list cursor yield strid$ table2model table_name try relations introspection_module get_relations cursor table_name except notimplementederror relations try indexes introspection_module get_indexes cursor table_name except notimplementederror indexes for i row in enumerate introspection_module get_table_description cursor table_name att_name row numid$ lower comment_notes # holds field notes to be displayed in a python comment extra_params # holds field parameters such as strid$ if strid$ in att_name extra_params strid$ att_name att_name att_name replace strid$ strid$ comment_notes append strid$ if keyword iskeyword att_name extra_params strid$ att_name att_name strid$ comment_notes append strid$ if i in relations rel_to relations i numid$ table_name and strid$ or table2model relations i numid$ field_type strid$ rel_to if att_name endswith strid$ att_name att_name numid$ else extra_params strid$ att_name else try field_type introspection_module data_types_reverse row numid$ except keyerror field_type strid$ comment_notes append strid$ # this is a hook for data_types_reverse to return a tuple of # field_type extra_params_dict if type field_type is tuple field_type new_params field_type extra_params update new_params # add max_length for all charfields if field_type strid$ and row numid$ extra_params strid$ row numid$ if field_type strid$ extra_params strid$ row numid$ extra_params strid$ row numid$ # add primary_key and unique if necessary column_name extra_params get strid$ att_name if column_name in indexes if indexes column_name strid$ extra_params strid$ true elif indexes column_name strid$ extra_params strid$ true field_type strid$ # donstrid$id meta autofield primary_key true strid$s assumed if it doesnstrid$idstrid$autofield strid$primary_keystrid$nullstrid$blankstrid$null_okstrid$s null extra_params strid$ true if not field_type in strid$ strid$ extra_params strid$ true field_desc strid$ att_name field_type if extra_params if not field_desc endswith strid$ field_desc strid$ field_desc strid$ join strid$ k v for k v in extra_params items field_desc strid$ if comment_notes field_desc strid$ strid$ join comment_notes yield strid$ field_desc yield strid$ yield strid$ table_name yield strid$ from django core management base import basecommand from django core management color import no_style import sys import os try set except nameerror from sets import set as set # python numid$ numid$ fallback class command basecommand help strid$ args strid$ <|EOS|>',\n",
       " '<|endoftext|> check_compact self traindata testdata self _make_basic_datasets model oneclassmodel linear results model fit traindata pythonpredictor refv results predict_values testdata results compact v results predict_values testdata assert_array_equal refv v if __name__ strid$ numpytest run from numpy testing import import numpy as n set_local_path strid$ from svm dataset import regressiondataset testdataset from svm kernel import from svm predict import from svm regression import restore_path class test_regression numpytestcase <|EOS|>',\n",
       " '<|endoftext|> trimmed_mean data proportiontocut numid$ numid$ axis none strid$strid$strid$ return trim_both data proportiontocut proportiontocut axis axis mean axis axis # <|EOS|>',\n",
       " '<|endoftext|> _is_pentiumiii self return re match rstrid$ self info numid$ strid$ is not none <|EOS|>',\n",
       " '<|endoftext|> run_tests self test_labels extra_tests none kwargs strid$strid$strid$ self setup_test_environment suite self build_suite test_labels extra_tests old_config self setup_databases result self run_suite suite self teardown_databases old_config self teardown_test_environment return self suite_result suite result <|EOS|>',\n",
       " '<|endoftext|> unsigned int jj c <|EOS|>',\n",
       " '<|endoftext|> test_fit_transform x np random random numid$ numid$ for obj in scaler normalizer binarizer x_transformed obj fit x transform x x_transformed2 obj fit_transform x assert_array_equal x_transformed x_transformed2 # author alexandre gramfort alexandre gramfort@inria fr # fabian pedregosa fabian pedregosa@inria fr # olivier grisel olivier grisel@ensta org # # license bsd style cimport numpy as np import numpy as np import numpy linalg as linalg cimport cython import warnings c <|EOS|>',\n",
       " '<|endoftext|> main unused_args freeze_graph flags input_graph flags input_saver flags input_binary flags input_checkpoint flags output_node_names flags restore_op_name flags filename_tensor_name flags output_graph flags clear_devices if __name__ strid$ tf app run # copyright numid$ google inc all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # # pylint disable g bad import order unused import strid$strid$strid$ from __future__ import absolute_import from __future__ import division from __future__ import print_function import tensorflow python platform import os import tensorflow as tf from tensorflow python framework import test_util from tensorflow python platform import googletest from tensorflow python tools import freeze_graph class freezegraphtest test_util tensorflowtestcase <|EOS|>',\n",
       " '<|endoftext|> test_reverse_one_to_one_prefetch_related self with self assertnumqueries numid$ pool pool objects prefetch_related strid$ get pk numid$ style pool poolstyle self assertis pool style pool <|EOS|>',\n",
       " '<|endoftext|> ined data types from some source sstable tfrecord cns directory etc the most basic function of a data provider is the `get` operation where one requests one or more types of data or strid$ provider get items strid$ strid$ strid$ more concretely a data provider a subclass of basedataprovider returns a single tensor for each requested item data type provider mydataprovider image sentence clazz provider get strid$ strid$ strid$ in this example the provider `mydataprovider` must know how to load each item a data provider may be written in a way that the logic necessary to map from each item to tensor is completely encapsulated within the data_provider itself strid$strid$strid$maps a list of requested data items to tensors from a data source all data providers must inherit from dataprovider and implement the get method which returns arbitrary types of data no assumption is made about the source of the data nor the mechanism for providing it strid$ __metaclass__ abc abcmeta <|EOS|>',\n",
       " '<|endoftext|> ault new_data update _get_flattened_data f f get_ <|EOS|>',\n",
       " '<|endoftext|> get_step_index self step none strid$strid$strid$ if step is none step self steps current return self get_form_list keyorder index step <|EOS|>',\n",
       " '<|endoftext|> ine `_iter_test_masks` or `_iter_test_indices` strid$ <|EOS|>',\n",
       " '<|endoftext|> testchi2mean self with tf session df_v np array numid$ numid$ numid$ dtype np float64 expected_mean stats chi2 mean df_v chi2 tf contrib distributions chi2 df df_v self assertequal chi2 mean get_shape numid$ self assertallclose chi2 mean eval expected_mean <|EOS|>',\n",
       " '<|endoftext|> resolve_expression self query none allow_joins true reuse none summarize false for_save false resolved super searchquery self resolve_expression query allow_joins reuse summarize for_save if self config if not hasattr self config strid$ resolved config value self config resolve_expression query allow_joins reuse summarize for_save else resolved config self config resolve_expression query allow_joins reuse summarize for_save return resolved <|EOS|>',\n",
       " '<|endoftext|> noresult pass <|EOS|>',\n",
       " '<|endoftext|> _update_gamma x expelogbeta alpha rng max_iters mean_change_tol cal_delta strid$strid$strid$ n_docs n_vocabs x shape n_topics expelogbeta shape numid$ # gamma is non normailzed topic distribution gamma rng gamma numid$ numid$ numid$ n_docs n_topics expelogtheta np exp _dirichlet_expectation gamma # diff on component only calculate it when keep_comp_change is true delta_component np zeros expelogbeta shape if cal_delta else none x_data x data x_indices x indices x_indptr x indptr for d in xrange n_docs ids x_indices x_indptr d x_indptr d numid$ cnts x_data x_indptr d x_indptr d numid$ gammad gamma d expelogthetad expelogtheta d expelogbetad expelogbeta ids # the optimal phi_ dwk is proportional to # expelogthetad_k expelogbetad_w phinorm is the normalizer phinorm np dot expelogthetad expelogbetad 1e numid$ # iterate between gamma and phi until convergence for it in xrange numid$ max_iters lastgamma gammad # we represent phi implicitly to save memory and time # substituting the value of the optimal phi back into # the update for gamma gives this update cf lee seung numid$ gammad alpha expelogthetad np dot cnts phinorm expelogbetad t expelogthetad np exp _dirichlet_expectation gammad phinorm np dot expelogthetad expelogbetad 1e numid$ meanchange np mean abs gammad lastgamma if meanchange mean_change_tol break gamma d gammad # contribution of document d to the expected sufficient # statistics for the m step if cal_delta delta_component ids np outer expelogthetad cnts phinorm return gamma delta_component class onlinelda baseestimator transformermixin strid$strid$online learning for latent dirichlet allocation matthew d hoffman david m blei francis bach numid$ matthew d hoffman s onlineldavb code link http www cs princeton edu mdhoffma code onlineldavb tar parameters n_topics int optional <|EOS|>',\n",
       " '<|endoftext|> reference self return strid$ self name <|EOS|>',\n",
       " '<|endoftext|> __repr__ self return strid$ self model model _meta object_name self instance _get_pk_val <|EOS|>',\n",
       " '<|endoftext|> __init__ self parent item statement __init__ self parent item line item get_line numid$ strip self expr strid$ if line self expr line <|EOS|>',\n",
       " '<|endoftext|> test_entropy_init self rg randomgenerator self prng rg2 randomgenerator self prng s1 rg state s2 rg2 state assert_ not comp_state rg state rg2 state <|EOS|>',\n",
       " '<|endoftext|> items if isinstance value string_types and not isinstance value str model_ <|EOS|>',\n",
       " '<|endoftext|> binary_op self other try x other shape except attributeerror x empty new_shape binary_op_size self shape x return dummy_array new_shape numid$ <|EOS|>',\n",
       " '<|endoftext|> test_own_alias_dependency self raw strid$ strid$ strid$ strid$ dependencies strid$ strid$ with self assertraises improperlyconfigured simple dependency_ordered raw dependencies dependencies # reordering aliases shouldnstrid$s1strid$s1_dbstrid$bravostrid$alpha with self assertraises improperlyconfigured simple dependency_ordered raw dependencies dependencies class mocktestrunner object invoked false <|EOS|>',\n",
       " '<|endoftext|> test_month_filter self self generate self assertequal thing objects filter where__month numid$ numid$ when strid$ from __future__ import unicode_literals from django core exceptions import fielderror from django test import testcase from models import user poll choice class reverselookuptests testcase <|EOS|>',\n",
       " '<|endoftext|> safe_exec self value string l try exec string l except self fail strid$ value string strip return l <|EOS|>',\n",
       " '<|endoftext|> stmt strid$ subclass_names data_component_ <|EOS|>',\n",
       " '<|endoftext|> density x if x numid$ return numid$ numid$ else lambda_ self _args numid$ return lambda_ exp lambda_ x class lognormaldistribution distribution <|EOS|>',\n",
       " '<|endoftext|> test_sitemap_get_urls_no_site_1 self strid$strid$strid$ site objects all delete self assertraises improperlyconfigured sitemap get_urls @modify_settings installed_apps strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> test_that_changepassword_command_changes_joes_password self strid$ self asserttrue self user check_password strid$ command changepassword command command _get_pass lambda args strid$ command execute username strid$ stdout self stdout command_output self stdout getvalue strip self assertequal command_output strid$ self asserttrue models user objects get username strid$ check_password strid$ <|EOS|>',\n",
       " '<|endoftext|> compare_1_input f1 f2 is_small false a numid$ numid$ if is_small else numid$ inputs a a strid$ numid$ np array a numid$ np array a numid$ strid$ numid$ np array a numid$ strid$ numid$ numid$ for i in inputs v1 f1 i numid$ i numid$ v2 f2 i numid$ i numid$ assert_allclose v1 v2 <|EOS|>',\n",
       " '<|endoftext|> np ndarray np float64_t ndim numid$ mode strid$ support_vectors if kernel_type numid$ support_vectors np empty numid$ numid$ dtype np float64 else support_vectors np empty sv_len x shape numid$ dtype np float64 copy_sv support_vectors data model support_vectors shape # copy model nsv # todo do only in classification c <|EOS|>',\n",
       " '<|endoftext|> clean self value strid$strid$strid$ value super regexfield self clean value if value ustrid$ return value if not self regex search value raise validationerror self error_messages strid$ return value email_re re compile rstrid$ # dot atom rstrid$ # quoted string rstrid$ re ignorecase # domain class emailfield regexfield <|EOS|>',\n",
       " '<|endoftext|> svm_csr_model model c <|EOS|>',\n",
       " '<|endoftext|> ndarray odf c <|EOS|>',\n",
       " '<|endoftext|> ault numid$ the axis along which to impute if `axis numid$` then impute along columns if `axis numid$` then impute along rows verbose integer optional <|EOS|>',\n",
       " '<|endoftext|> __str__ self return self hostname from functools import update_wrapper from django contrib import admin from django core urlresolvers import reverse from django db import models from django http import httpresponseredirect from django utils encoding import python_2_unicode_compatible @python_2_unicode_compatible class action models model name models charfield max_length numid$ primary_key true description models charfield max_length numid$ <|EOS|>',\n",
       " '<|endoftext|> testemptyreservoir self r reservoir reservoir numid$ self assertfalse r keys <|EOS|>',\n",
       " '<|endoftext|> __init__ self seed none inc numid$ self rng_state pcg32_state malloc sizeof pcg32_state self rng_state pcg_state pcg32_random_t malloc sizeof pcg32_random_t self _brng brng_t malloc sizeof brng_t self seed seed inc self lock lock self _brng state void self rng_state self _brng next_uint64 pcg32_uint64 self _brng next_uint32 pcg32_uint32 self _brng next_double pcg32_double self _brng next_raw pcg32_raw self _ctypes none self _cffi none self _generator none c <|EOS|>',\n",
       " '<|endoftext|> _parse self self _doc reset self _parse_summary for section content in self _read_sections if not section startswith strid$ section strid$ join s capitalize for s in section split strid$ if section in strid$ strid$ strid$ strid$ strid$ strid$ self section self _parse_param_list content elif section startswith strid$ self strid$ self _parse_index section content elif section strid$ self strid$ self _parse_see_also content else self section content # string conversion routines <|EOS|>',\n",
       " '<|endoftext|> aultstrid$sstrid$strid$ name strid$ op npolymorphicout <|EOS|>',\n",
       " '<|endoftext|> test_if_tag_not18 self output render strid$ strid$ true strid$ false self assertequal output strid$ @setup strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> _initassignfetch self x y use_gpu false strid$strid$strid$ super assignoptest self setup with self test_session use_gpu use_gpu p tf variable x assign tf assign p y p initializer run new_value assign eval return p eval new_value <|EOS|>',\n",
       " '<|endoftext|> test_custom_command_with_environment self <|EOS|>',\n",
       " '<|endoftext|> test_split_indices # check that split_indices returns the correct splits and that # splitter partition is consistent with what is returned rng np random randomstate numid$ n_bins numid$ n_samples numid$ l2_regularization numid$ min_hessian_to_split 1e numid$ min_samples_leaf numid$ min_gain_to_split numid$ # split will happen on feature numid$ and on bin numid$ x_binned numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ x_binned np asfortranarray x_binned dtype x_binned_dtype sample_indices np arange n_samples dtype np uint32 all_gradients rng randn n_samples astype g_h_dtype all_hessians np ones numid$ dtype g_h_dtype sum_gradients all_gradients sum sum_hessians numid$ n_samples hessians_are_constant true actual_n_bins np array n_bins x_binned shape numid$ dtype np uint32 builder histogrambuilder x_binned n_bins all_gradients all_hessians hessians_are_constant splitter splitter x_binned n_bins actual_n_bins l2_regularization min_hessian_to_split min_samples_leaf min_gain_to_split hessians_are_constant assert np all sample_indices splitter partition histograms builder compute_histograms_brute sample_indices si_root splitter find_node_split sample_indices histograms sum_gradients sum_hessians # sanity checks for best split assert si_root feature_idx numid$ assert si_root bin_idx numid$ samples_left samples_right position_right splitter split_indices si_root splitter partition assert set samples_left set numid$ numid$ numid$ numid$ numid$ numid$ numid$ assert set samples_right set numid$ numid$ numid$ assert list samples_left list splitter partition position_right assert list samples_right list splitter partition position_right # check that the resulting split indices sizes are consistent with the # count statistics anticipated when looking for the best split assert samples_left shape numid$ si_root n_samples_left assert samples_right shape numid$ si_root n_samples_right <|EOS|>',\n",
       " '<|endoftext|> transform self x args kwargs return x @hides <|EOS|>',\n",
       " '<|endoftext|> _media self from django conf import settings if strid$ in self classes return forms media js strid$ settings admin_media_prefix return forms media media property _media <|EOS|>',\n",
       " '<|endoftext|> geometric self p size none strid$ geometric p size none draw samples from the geometric distribution bernoulli trials are experiments with one of two outcomes success or failure an example of such an experiment is flipping a coin the geometric distribution models the number of trials that must be run in order to achieve success it is therefore supported on the positive integers ``k numid$ numid$ `` the probability mass function of the geometric distribution is math f k numid$ p k numid$ p where `p` is the probability of success of an individual trial parameters p float or array_like of floats the probability of success of an individual trial size int or tuple of ints optional output shape if the given shape is e g `` m n k `` then ``m n k`` samples are drawn if size is ``none`` <|EOS|>',\n",
       " '<|endoftext|> inition out_ <|EOS|>',\n",
       " '<|endoftext|> test_gamma_floats self rg randomgenerator self brng warmup rg state rg state r1 rg standard_gamma numid$ numid$ numid$ dtype np float32 rg2 randomgenerator self brng warmup rg2 rg2 state state r2 rg2 standard_gamma numid$ numid$ numid$ dtype np float32 assert_array_equal r1 r2 assert_equal r1 dtype np float32 assert_ comp_state rg state rg2 state <|EOS|>',\n",
       " '<|endoftext|> column_sql self model field include_ <|EOS|>',\n",
       " '<|endoftext|> __init__ self alpha numid$ numid$ fit_intercept true max_iter numid$ tol numid$ numid$ verbose numid$ random_state none eta0 strid$ warm_start false self loss_function squaredloss super sagregressor self __init__ alpha alpha fit_intercept fit_intercept max_iter max_iter verbose verbose random_state random_state tol tol eta0 eta0 warm_start warm_start strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> assert_equal o1 o2 assert o1 o2 <|EOS|>',\n",
       " '<|endoftext|> test_egg4 self strid$strid$strid$ egg_name strid$ self egg_dir sys path append egg_name models load_app strid$ self asserttrue models is none <|EOS|>',\n",
       " '<|endoftext|> testapprovepostunsafenext self strid$strid$strid$ c1 c2 c3 c4 self createsomecomments c1 is_public false c1 save makemoderator strid$ self client login username strid$ password strid$ response self client post strid$ c1 pk strid$ strid$ self assertequal response strid$ strid$ c1 pk <|EOS|>',\n",
       " '<|endoftext|> test_silhouette strid$strid$strid$ dataset datasets load_iris x dataset data y dataset target d pairwise_distances x metric strid$ # given that the actual labels are used we can assume that s would be # positive silhouette silhouette_score d y assert silhouette numid$ # test with sparse x x_sparse csr_matrix x d pairwise_distances x metric strid$ silhouette silhouette_score d y assert silhouette numid$ # author alexandre gramfort alexandre gramfort@inria fr # olivier grisel olivier grisel@ensta org # # license bsd style strid$strid$strid$ import warnings import numpy as np import scipy sparse as sp from base import linearmodel from import cd_fast_sparse class elasticnet linearmodel strid$ linear model trained with l1 and l2 prior as regularizer this implementation works on scipy sparse x and dense coef_ rho numid$ is the lasso penalty currently rho numid$ numid$ is not reliable unless you supply your own sequence of alpha parameters alpha float constant that multiplies the l1 term <|EOS|>',\n",
       " '<|endoftext|> _serve_runs self unused_query_params strid$strid$strid$ self _send_json_response self _multiplexer runs <|EOS|>',\n",
       " '<|endoftext|> vote request comment_id vote strid$strid$strid$ rating strid$ numid$ strid$ numid$ get vote false if not rating raise http404 strid$ if request user is_anonymous raise http404 strid$ try comment comments get_object id__exact comment_id except comments commentdoesnotexist raise http404 strid$ if comment user_id request user id raise http404 strid$ karma vote request user id comment_id rating # reload comment to ensure we have up to date karma count comment comments get_object id__exact comment_id t template_loader get_template strid$ c context request strid$ comment return httpresponse t render c from django core import template_loader from django core extensions import cmscontext as context from django core exceptions import http404 from django models comments import comments moderatordeletions userflags from django views decorators auth import login_required from django utils httpwrappers import httpresponse httpresponseredirect from django conf settings import site_id <|EOS|>',\n",
       " '<|endoftext|> migrate obj caller strid$strid$strid$ if inspect isroutine obj return migratedroutine obj caller raise notimplementederror `type obj ` class attrs <|EOS|>',\n",
       " '<|endoftext|> _multi_class_head n_classes label_name none weight_column_name none enable_centered_bias false head_name none thresholds none strid$ creates a _head for multi class single label classification the head uses softmax cross entropy loss args n_classes integer number of classes must be numid$ label_name string name of the key in label dict can be null if label is a tensor single headed models weight_column_name a string <|EOS|>',\n",
       " '<|endoftext|> test_tomaxint self random seed self seed rs random randomstate self seed actual rs tomaxint size numid$ numid$ if np iinfo np int max numid$ desired np array numid$ numid$ numid$ numid$ numid$ numid$ dtype np int64 else desired np array numid$ numid$ numid$ numid$ numid$ numid$ dtype np int64 assert_equal actual desired rs seed self seed actual rs tomaxint assert_equal actual desired numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> __repr__ self return strid$ self first_name self last_name class article models model headline models charfield maxlength numid$ pub_date models datefield reporter models foreignkey reporter <|EOS|>',\n",
       " '<|endoftext|> inedstrid$un <|EOS|>',\n",
       " '<|endoftext|> input_constant quantize_graph create_constant_node input_constant_name value numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ dtype tf float32 shape numid$ numid$ numid$ numid$ float_graph_ <|EOS|>',\n",
       " '<|endoftext|> initions on second level strid$ output render strid$ self assertequal output strid$ @setup inheritance_templates <|EOS|>',\n",
       " '<|endoftext|> test_assert_raises_exceptions ir isotonicregression rng np random randomstate numid$ assert_raises valueerror ir fit numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ numid$ assert_raises valueerror ir fit numid$ numid$ numid$ numid$ numid$ assert_raises valueerror ir fit rng randn numid$ numid$ numid$ numid$ numid$ assert_raises valueerror ir transform rng randn numid$ numid$ strid$strid$strid$ # author nelle varoquaux nelle varoquaux@gmail com # alexandre gramfort alexandre gramfort@inria fr # licence bsd import numpy as np import pylab as pl from matplotlib collections import linecollection from sklearn linear_model import linearregression from sklearn isotonic import isotonicregression from sklearn utils import check_random_state n numid$ x np arange n rs check_random_state numid$ y rs randint numid$ numid$ size n numid$ np log numid$ np arange n ############################################################################### # fit isotonicregression and linearregression models ir isotonicregression y_ ir fit_transform x y lr linearregression lr fit x np newaxis y # x needs to be 2d for linearregression ############################################################################### # plot result segments i y i i y_ i for i in range n lc linecollection segments zorder numid$ lc set_array np ones len y lc set_linewidths numid$ numid$ np ones n fig pl figure pl plot x y strid$ markersize numid$ pl plot x y_ strid$ markersize numid$ pl plot x lr predict x np newaxis strid$ pl gca add_collection lc pl legend strid$ strid$ strid$ loc strid$ pl title strid$ pl show # author lars buitinck l j buitinck@uva nl # license numid$ clause bsd # todo see if we can leverage the arraybuilder from sklearn utils here that # would probably need a pxd for an extra speed boost from libc stdlib cimport abs cimport numpy as np #from utils import murmurhash3_32 from sklearn utils murmurhash cimport murmurhash3_bytes_s32 <|EOS|>',\n",
       " '<|endoftext|> remove self objs val getattr instance rel_field rel get_related_field attname for obj in objs # is obj actually part of this descriptor set if getattr obj rel_field attname val setattr obj rel_field name none obj save else raise rel_field rel to doesnotexist strid$ obj instance remove alters_data true <|EOS|>',\n",
       " '<|endoftext|> __init__ self expressions extra if len expressions numid$ raise valueerror strid$ paired self _paired expressions super __init__ paired extra <|EOS|>',\n",
       " '<|endoftext|> testradiofieldsforeignkey self ff self assertformfield models event strid$ widgets adminradioselect radio_fields strid$ admin vertical self assertequal ff empty_label none <|EOS|>',\n",
       " '<|endoftext|> get_form_class self strid$strid$strid$ return self form_class <|EOS|>',\n",
       " '<|endoftext|> test_if_tag_not23 self output render strid$ strid$ true strid$ false self assertequal output strid$ @setup strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> _compareboth self x np_func tf_func self _comparecpu x np_func tf_func self _comparegpu x np_func tf_func <|EOS|>',\n",
       " '<|endoftext|> test_get self strid$strid$strid$ self _assert_about abouttemplateview as_view self rf get strid$ <|EOS|>',\n",
       " '<|endoftext|> test_basic_syntax16 self with self assertraises templatesyntaxerror get_template strid$ @setup strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> inline dtype_t dist self dtype_t x1 dtype_t x2 itype_t size c <|EOS|>',\n",
       " '<|endoftext|> name self return self _name @property <|EOS|>',\n",
       " '<|endoftext|> teardown self settings use_l10n self old_use_l10n settings template_dirs self old_template_dirs site _meta installed self old_site_meta_installed from django conf import settings from django utils unittest import skipunless from base import sitemaptestsbase class flatpagessitemaptests sitemaptestsbase @skipunless strid$ in settings installed_apps strid$ <|EOS|>',\n",
       " '<|endoftext|> inverse_transform self x strid$strid$strid$ return np dot x self components_ self mean_ class probabilisticpca pca strid$strid$strid$ __doc__ pca __doc__ <|EOS|>',\n",
       " '<|endoftext|> test_collapsible_fieldset self strid$ test that the strid$ class in fieldsets <|EOS|>',\n",
       " '<|endoftext|> check_pagination self url expected_status_code object_count none response self client get url self assertequal response status_code expected_status_code if object_count self assertequal response context strid$ true self assertequal len response context strid$ object_list object_count return response <|EOS|>',\n",
       " '<|endoftext|> advance self step strid$strid$strid$ c <|EOS|>',\n",
       " '<|endoftext|> ines a relation with the model strid$strid$ but that model does not have a strid$genericforeignkey obj bookmark tags field id strid$ @override_settings test_swapped_model strid$ <|EOS|>',\n",
       " '<|endoftext|> optimize_cost_function distances function nbcoords numid$ kwargs strid$strid$strid$ function function distances nbcoords kwargs std numpy std numpy sqrt distances numid$ x0 numpy random normal numid$ std distances shape numid$ nbcoords err numpy seterr invalid strid$ optimi optimizer standardoptimizermodifying function function step step frprpconjugategradientstep criterion criterion criterion gtol numid$ numid$ ftol numid$ numid$ iterations_max numid$ x0 x0 line_search line_search strongwolfepowellrule post_modifier modifier nbcoords function optimal optimi optimize optimal optimal reshape numid$ nbcoords numpy seterr err return optimal # matthieu brucher # last change numid$ numid$ numid$ numid$ numid$ strid$strid$strid$ import numpy <|EOS|>',\n",
       " '<|endoftext|> add_quantize_down_node self original_node quantized_output_name quantize_down_name original_node name strid$ quantize_down_node create_node strid$ quantize_down_name quantized_output_name quantized_output_name strid$ quantized_output_name strid$ set_attr_dtype quantize_down_node strid$ tf qint32 set_attr_dtype quantize_down_node strid$ tf quint8 self add_output_graph_node quantize_down_node return quantize_down_name <|EOS|>',\n",
       " '<|endoftext|> np npy_intp i n cnt if size is not none if np prod size numid$ return np empty size dtype np uint8 low_arr np ndarray np array low copy false high_arr np ndarray np array high copy false low_ndim np pyarray_ndim low_arr high_ndim np pyarray_ndim high_arr if low_ndim numid$ or low_ndim numid$ and low_arr size numid$ and size is not none and high_ndim numid$ or high_ndim numid$ and high_arr size numid$ and size is not none low int low_arr high int high_arr high numid$ if low 0x0ul raise valueerror strid$ if high 0xfful raise valueerror strid$ if low high # numid$ already subtracted closed interval raise valueerror strid$ rng uint8_t high low off uint8_t uint8_t low if size is none with lock random_bounded_uint8_fill state off rng numid$ out_val return np uint8 uint8_t out_val else out_arr np ndarray np empty size np uint8 cnt np pyarray_size out_arr out_data uint8_t np pyarray_data out_arr with lock nogil random_bounded_uint8_fill state off rng cnt out_data return out_arr return _rand_uint8_broadcast low_arr high_arr size state lock c <|EOS|>',\n",
       " '<|endoftext|> signature obj strid$strid$strid$ if not callable obj raise typeerror strid$ format obj if isinstance obj types methodtype sig signature obj __func__ if obj __self__ is none # unbound method the first parameter becomes positional only if sig parameters first sig parameters values numid$ replace kind _positional_only return sig replace parameters first tuple sig parameters values numid$ else return sig else # in this case we skip the first parameter of the underlying # function usually `self` or `cls` return sig replace parameters tuple sig parameters values numid$ try sig obj __signature__ except attributeerror pass else if sig is not none return sig try # was this function wrapped by a decorator wrapped obj __wrapped__ except attributeerror pass else return signature wrapped if isinstance obj types functiontype return signature from_function obj if isinstance obj functools partial sig signature obj func new_params ordereddict sig parameters items partial_args obj args or partial_keywords obj keywords or try ba sig bind_partial partial_args partial_keywords except typeerror as ex msg strid$ format obj raise valueerror msg for arg_name arg_value in ba arguments items param new_params arg_name if arg_name in partial_keywords # we set a new <|EOS|>',\n",
       " '<|endoftext|> checkrecursion self parseelementlist subrecchecklist parseelementlist self for e in self exprs e checkrecursion subrecchecklist if not e mayreturnempty break <|EOS|>',\n",
       " '<|endoftext|> __setstate__ self state self _reader self _writer self _reducers self _rlock self _wlock state if sys version_info numid$ numid$ numid$ # for python2 numid$ numid$ numid$ overload get to avoid creating deadlocks with # unpickling errors <|EOS|>',\n",
       " '<|endoftext|> test_generic_ipaddress_as_ipv6_only self f genericipaddressfield protocol strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean none self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ self assertequal f clean strid$ strid$ self assertequal f clean strid$ strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ self assertformerrors strid$ f clean strid$ <|EOS|>',\n",
       " '<|endoftext|> exp_decay global_step return tf train exponential_decay learning_rate numid$ numid$ global_step decay_steps numid$ decay_rate numid$ numid$ tf_random_seed random seed for tensorflow initializers setting this value allows consistency between reruns continue_training when continue_training is true once initialized model will be continuely trained on every call of fit early_stopping_rounds activates early stopping if this is not none loss needs to decrease at least every every early_stopping_rounds round s to continue training <|EOS|>',\n",
       " '<|endoftext|> blocking_close sess run close_op thread2 self checkedthread target blocking_close thread2 start # wait for the close op to block before unblocking the enqueue # todo mrry figure out how to do this without sleeping time sleep numid$ numid$ results # dequeue to unblock the first blocking_enqueue_op after which the # close will complete results append dequeued_t eval self asserttrue results numid$ in elems thread2 join thread1 join <|EOS|>',\n",
       " '<|endoftext|> as_text self attrs none kwargs strid$strid$textstrid$strid$ return self as_widget textinput attrs kwargs <|EOS|>',\n",
       " '<|endoftext|> test_inheritance38 self strid$strid$strid$ output render strid$ self assertequal output strid$ # the super block will still be found @setup inheritance_templates <|EOS|>',\n",
       " '<|endoftext|> check_foo_simple self level numid$ foo m foo foo if __name__ strid$ numpytest run # usr bin env python strid$strid$strid$ import os import sys from numpy testing import set_package_path from lib main import build_extension compile restore_path fortran_code strid$strid$strid$ m compile fortran_code modulenames strid$ from numpy import class test_m numpytestcase <|EOS|>',\n",
       " '<|endoftext|> test_transform self strid$ # pre transformed points for houston and pueblo htown fromstr strid$ srid numid$ ptown fromstr strid$ srid numid$ prec numid$ # precision is low due to version variations in proj and gdal # asserting the result of the transform operation with the values in # the pre transformed points oracle does not have the numid$ srid if not oracle h city objects transform htown srid get name strid$ self assertequal numid$ h point srid self assertalmostequal htown x h point x prec self assertalmostequal htown y h point y prec p1 city objects transform ptown srid field_name strid$ get name strid$ p2 city objects transform srid ptown srid get name strid$ for p in p1 p2 self assertequal numid$ p point srid self assertalmostequal ptown x p point x prec self assertalmostequal ptown y p point y prec @skipunlessdbfeature strid$ <|EOS|>',\n",
       " '<|endoftext|> __call__ self estimator x y y_pred estimator predict x return score_func y y_pred return scoreobj <|EOS|>',\n",
       " '<|endoftext|> _set_last_loss_seen self strid$strid$strid$ val_loss self sess run self loss_expression_tensor feed_dict self val_dict self last_loss_seen val_loss self all_val_loss_buffer append val_loss self print_val_loss_buffer append val_loss <|EOS|>',\n",
       " '<|endoftext|> check_doctests_testfile fname verbose ns none dots true doctest_warnings false strid$strid$blocksstrid$strid$ results if ns is none ns dict <|EOS|>',\n",
       " '<|endoftext|> test_filter_syntax11 self strid$strid$strid$ output render strid$ strid$ none strid$ strid$ self assertequal output strid$ @setup strid$ rstrid$ <|EOS|>',\n",
       " '<|endoftext|> _macros un <|EOS|>',\n",
       " '<|endoftext|> double _a numid$ numid$ _b numid$ numid$ _c numid$ numid$ c <|EOS|>',\n",
       " '<|endoftext|> ault format text f widget _format_value result self assertequal text strid$ @override_settings date_input_formats strid$ strid$ use_l10n true class localizeddatetests simpletestcase <|EOS|>',\n",
       " '<|endoftext|> test_imports_strategies # make sure different import strategies work or fail as expected # since python caches the imported modules we need to run a child process # for every test case else the tests would not be independent # manually removing the imports from the cache sys modules is not # recommended and can lead to many complications good_import strid$strid$strid$ assert_run_python_script textwrap dedent good_import good_import_with_ensemble_first strid$strid$strid$ assert_run_python_script textwrap dedent good_import_with_ensemble_first bad_imports strid$strid$strid$ assert_run_python_script textwrap dedent bad_imports strid$ svm tie breaking example tie breaking is costly if ``decision_function_shape strid$`` and therefore it is not enabled by <|EOS|>',\n",
       " '<|endoftext|> ined self strid$ ensure `old` complains when only `old` is <|EOS|>',\n",
       " '<|endoftext|> truncatewords value arg strid$strid$strid$ from django utils text import truncate_words try length int arg except valueerror # invalid literal for int return value # fail silently if not isinstance value basestring value str value return truncate_words value length <|EOS|>',\n",
       " '<|endoftext|> ault models that have been swapped out will not be included in the list of models however if you specify include_swapped they will be strid$ if not self master only_installed false model_list none self populate_models if app_mod app_label app_mod __name__ split strid$ numid$ if only_installed try model_dicts self app_configs app_label models except keyerror model_dicts else model_dicts self all_models app_label else if only_installed model_dicts app_config models for app_config in self app_configs values else model_dicts self all_models values model_list for model_dict in model_dicts model_list extend model for model in model_dict values if not model _ <|EOS|>',\n",
       " '<|endoftext|> test_primary_key self class model models model field models filefield primary_key false upload_to strid$ field model _meta get_field strid$ errors field check expected error strid$ hint none obj field id strid$ self assertequal errors expected class filepathfieldtests isolatedmodelstestcase <|EOS|>',\n",
       " '<|endoftext|> test03_geom_type self strid$ # by <|EOS|>',\n",
       " '<|endoftext|> __enter__ self strid$strid$strid$ pass <|EOS|>',\n",
       " '<|endoftext|> aults import from django contrib import admin urlpatterns patterns strid$ rstrid$ include admin site urls from django test import testcase class nomodeltests testcase strid$strid$strid$ pass from __future__ import with_statement from datetime import timedelta date datetime from django template import template context add_to_builtins <|EOS|>',\n",
       " '<|endoftext|> aultstrid$otherstrid$otherstrid$otherstrid$otherstrid$ <|EOS|>',\n",
       " '<|endoftext|> len t args len t <|EOS|>',\n",
       " '<|endoftext|> __repr__ self return strid$ self delta <|EOS|>',\n",
       " '<|endoftext|> test_select_kbest_classif strid$strid$strid$ x y make_classification n_samples numid$ n_features numid$ n_informative numid$ n_redundant numid$ n_repeated numid$ n_classes numid$ n_clusters_per_class numid$ flip_y numid$ numid$ class_sep numid$ shuffle false random_state numid$ univariate_filter selectkbest f_classif k numid$ x_r univariate_filter fit x y transform x x_r2 genericunivariateselect f_classif mode strid$ param numid$ fit x y transform x assert_array_equal x_r x_r2 support univariate_filter get_support gtruth np zeros numid$ gtruth numid$ numid$ assert_array_equal support gtruth <|EOS|>',\n",
       " '<|endoftext|> render self context resolved_vars var resolve context for var in self vars_to_resolve if takes_context args context resolved_vars else args resolved_vars dict func args if not getattr self strid$ false from django template loader import get_template select_template if not isinstance file_name basestring and is_iterable file_name t select_template file_name else t get_template file_name self nodelist t nodelist new_context context_class dict autoescape context autoescape # copy across the csrf token if present because inclusion # tags are often used for forms and we need instructions # for using csrf protection to be as simple as possible csrf_token context get strid$ none if csrf_token is not none new_context strid$ csrf_token return self nodelist render new_context compile_func curry generic_tag_compiler params <|EOS|>',\n",
       " '<|endoftext|> testnormalizesfloat self pb1 compare_test_pb2 large pb1 double_ numid$ numid$ pb2 compare_test_pb2 large pb2 double_ 4l compare assertproto2equal self pb1 pb2 normalize_numbers true pb1 compare_test_pb2 medium pb1 floats extend numid$ numid$ numid$ numid$ pb2 compare_test_pb2 medium pb2 floats extend 6l 4l compare assertproto2sameelements self pb1 pb2 normalize_numbers true <|EOS|>',\n",
       " '<|endoftext|> member_ <|EOS|>',\n",
       " '<|endoftext|> testunregisterpluginfilter self strid$ template register_filter strid$ self custom_filter true c template context strid$ strid$ t template template strid$ rendered t render c # should run with no exception template unregister_filter strid$ class plugintagcheck unittest testcase class customnode template node strid$ <|EOS|>',\n",
       " '<|endoftext|> inclusion_tag self filename func none takes_context none name none strid$ register a callable as an inclusion tag @register inclusion_tag strid$ <|EOS|>',\n",
       " '<|endoftext|> ptr_byref args offset numid$ strid$ return args offset _obj <|EOS|>',\n",
       " '<|endoftext|> aultvalue else tokens return loc tokens <|EOS|>',\n",
       " '<|endoftext|> ault for f90 compiler fix self __get_cmd strid$ strid$ conf strid$ if fix fixflags self __get_flags self get_flags_fix f90flags oflags aflags dflags if not noopt oflags self __get_flags self get_flags_opt strid$ conf strid$ if f77 and self get_flags_opt is not self get_flags_opt_f77 f77flags self __get_flags self get_flags_opt_f77 if f90 and self get_flags_opt is not self get_flags_opt_f90 f90flags self __get_flags self get_flags_opt_f90 if fix and self get_flags_opt is not self get_flags_opt_f90 fixflags self __get_flags self get_flags_opt_f90 if not noarch aflags self __get_flags self get_flags_arch strid$ conf strid$ if f77 and self get_flags_arch is not self get_flags_arch_f77 f77flags self __get_flags self get_flags_arch_f77 if f90 and self get_flags_arch is not self get_flags_arch_f90 f90flags self __get_flags self get_flags_arch_f90 if fix and self get_flags_arch is not self get_flags_arch_f90 fixflags self __get_flags self get_flags_arch_f90 if debug dflags self __get_flags self get_flags_debug strid$ if f77 and self get_flags_debug is not self get_flags_debug_f77 f77flags self __get_flags self get_flags_debug_f77 if f90 and self get_flags_debug is not self get_flags_debug_f90 f90flags self __get_flags self get_flags_debug_f90 if fix and self get_flags_debug is not self get_flags_debug_f90 fixflags self __get_flags self get_flags_debug_f90 fflags self __get_flags self get_flags strid$ dflags oflags aflags if f77 self set_executables compiler_f77 f77 f77flags fflags if f90 self set_executables compiler_f90 f90 freeflags f90flags fflags if fix self set_executables compiler_fix fix fixflags fflags #xxx do we need ldshared soshared ldflags soflags linker_so self __get_cmd self get_linker_so strid$ if linker_so linker_so_flags self __get_flags self get_flags_linker_so strid$ self set_executables linker_so linker_so linker_so_flags linker_exe self __get_cmd self get_linker_exe strid$ if linker_exe linker_exe_flags self __get_flags self get_flags_linker_exe strid$ self set_executables linker_exe linker_exe linker_exe_flags ar self __get_cmd strid$ strid$ if ar arflags self __get_flags self get_flags_ar strid$ self set_executables archiver ar arflags ranlib self __get_cmd strid$ strid$ if ranlib self set_executables ranlib ranlib self set_library_dirs self get_library_dirs self set_libraries self get_libraries verbose conf get strid$ none numid$ numid$ if verbose self dump_properties return <|EOS|>',\n",
       " '<|endoftext|> l1_regularizer scale strid$strid$strid$ if isinstance scale numbers integral raise valueerror strid$ scale if isinstance scale numbers real if scale numid$ raise valueerror strid$ scale if scale numid$ raise valueerror strid$ scale if scale numid$ logging info strid$ return lambda _ name none none <|EOS|>',\n",
       " '<|endoftext|> testoneepoch self files self _createfiles with self test_session as sess reader tf tfrecordreader name strid$ queue tf fifoqueue numid$ tf string shapes key value reader read queue queue enqueue_many files run queue close run for i in range self _num_files for j in range self _num_records k v sess run key value self asserttrue k startswith strid$ files i self assertallequal self _record i j v with self assertraisesoperror strid$ strid$ k v sess run key value if __name__ strid$ tf test main strid$strid$strid$ import tensorflow python platform import numpy as np import tensorflow as tf from tensorflow python framework import tensor_shape from tensorflow python kernel_tests import gradient_checker class sumreductiontest tf test testcase <|EOS|>',\n",
       " '<|endoftext|> __iter__ self for field in self fields yield field <|EOS|>',\n",
       " '<|endoftext|> __str__ self return strid$ self first_name self last_name class meta db_table strid$ ordering strid$ strid$ # a models py so that tests run from __future__ import unicode_literals from django utils encoding import python_2_unicode_compatible strid$strid$strid$ from django db import models @python_2_unicode_compatible class number models model integer models integerfield db_column strid$ float models floatfield null true db_column strid$ <|EOS|>',\n",
       " '<|endoftext|> __init__ self topics_path self topics_ open topics_path read split strid$ self topics_ dict self topics_ i i for i in range len self topics_ <|EOS|>',\n",
       " '<|endoftext|> test_repeatability self import hashlib # we use a md5 hash of generated sequences of numid$ samples # in the range numid$ numid$ for all but bool where the range # is numid$ numid$ hashes are for little endian numbers tgt strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ for dt in self itype numid$ random seed numid$ # view as little endian for hash if sys byteorder strid$ val self rfunc numid$ numid$ size numid$ dtype dt else val self rfunc numid$ numid$ size numid$ dtype dt byteswap res hashlib md5 val view np int8 hexdigest assert_ tgt np dtype dt name res # bools do not depend on endianness random seed numid$ val self rfunc numid$ numid$ size numid$ dtype bool view np int8 res hashlib md5 val hexdigest assert_ tgt np dtype bool name res <|EOS|>',\n",
       " '<|endoftext|> test_base_hmm_attributes self n_components numid$ startprob self prng rand n_components startprob startprob startprob sum transmat prng rand n_components n_components transmat np tile transmat sum axis numid$ np newaxis numid$ n_components h self stubhmm n_components self assertequals h n_components n_components h startprob startprob assert_array_almost_equal h startprob startprob self assertraises valueerror h __setattr__ strid$ numid$ startprob self assertraises valueerror h __setattr__ strid$ self assertraises valueerror h __setattr__ strid$ np zeros n_components numid$ numid$ h transmat transmat assert_array_almost_equal h transmat transmat self assertraises valueerror h __setattr__ strid$ numid$ transmat self assertraises valueerror h __setattr__ strid$ self assertraises valueerror h __setattr__ strid$ np zeros n_components numid$ n_components <|EOS|>',\n",
       " '<|endoftext|> test_extra_method_select_argument_with_dashes_and_values self # the strid$ argument to extra supports names with dashes in # them as long as you use values a10 article objects create headline strid$ pub_date datetime numid$ numid$ numid$ numid$ numid$ numid$ a11 article objects create headline strid$ pub_date datetime numid$ numid$ numid$ a12 article objects create headline strid$ pub_date datetime numid$ numid$ numid$ numid$ numid$ numid$ numid$ dicts article objects filter pub_date__year numid$ extra select strid$ strid$ values strid$ strid$ self assertequal sorted d items for d in dicts strid$ numid$ strid$ strid$ strid$ numid$ strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> __init__ self n_jobs backend_args self _executor get_memmapping_executor n_jobs backend_args self _temp_folder self _executor _temp_folder <|EOS|>',\n",
       " '<|endoftext|> ewkt self strid$ if self get_srid return strid$ self srid self wkt else return self wkt @property <|EOS|>',\n",
       " '<|endoftext|> safe_repr value strid$strid$strid$ # this is pretty horrible but should always return something try return pydoc text repr value except keyboardinterrupt raise except try return repr value except keyboardinterrupt raise except try # all still in an except block so we catch # getattr raising name getattr value strid$ none if name # ick recursion return safe_repr name klass getattr value strid$ none if klass return strid$ safe_repr klass except keyboardinterrupt raise except return strid$ <|EOS|>',\n",
       " '<|endoftext|> _testgradientssimple self use_gpu inp np random rand numid$ numid$ astype strid$ with self test_session use_gpu use_gpu inp_tensor tf convert_to_tensor inp s tf split numid$ numid$ inp_tensor inp_grads np random rand numid$ numid$ astype strid$ for _ in range numid$ grad_tensors tf constant x for x in inp_grads grad tf gradients s inp_tensor grad_tensors numid$ result grad eval for i in range numid$ self assertallequal result i i numid$ inp_grads i <|EOS|>',\n",
       " '<|endoftext|> test_for_update_sql_generated_nowait self strid$strid$strid$ list person objects all select_for_update nowait true self asserttrue self has_for_update_sql connection nowait true # in python numid$ numid$ beta and some final releases exceptions raised in __len__ # are swallowed python issue numid$ so these cases return an empty # list rather than raising an exception not a lot we can do about that # unfortunately due to the way python handles list calls internally # python numid$ numid$ numid$ is the strid$ version affected by this so we skip # the test for that version @requires_threading @skipunlessdbfeature strid$ @unittest skipif sys version_info numid$ numid$ numid$ numid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> inition for strid$ invalid_models clash2 accessor for m2m field strid$ clashes with field strid$ add a related_name argument to the <|EOS|>',\n",
       " '<|endoftext|> np npy_intp i n cnt if size is not none if np prod size numid$ return np empty size dtype np int16 low_arr np ndarray np array low copy false high_arr np ndarray np array high copy false low_ndim np pyarray_ndim low_arr high_ndim np pyarray_ndim high_arr if low_ndim numid$ or low_ndim numid$ and low_arr size numid$ and size is not none and high_ndim numid$ or high_ndim numid$ and high_arr size numid$ and size is not none low int low_arr high int high_arr high numid$ if low 0x8000l raise valueerror strid$ if high 0x7fffl raise valueerror strid$ if low high # numid$ already subtracted closed interval raise valueerror strid$ rng uint16_t high low off uint16_t int16_t low if size is none with lock random_bounded_uint16_fill state off rng numid$ out_val return np int16 int16_t out_val else out_arr np ndarray np empty size np int16 cnt np pyarray_size out_arr out_data uint16_t np pyarray_data out_arr with lock nogil random_bounded_uint16_fill state off rng cnt out_data return out_arr return _rand_int16_broadcast low_arr high_arr size state lock c <|EOS|>',\n",
       " '<|endoftext|> laplacian_maps2 samples nbcoords method kwargs strid$ computes a laplacian eigenmap for a manifold parameters samples are the samples that will be reduced nbcoords is the number of coordinates in the manifold method is the method to create the similarity matrix neigh is the neighboorer used optional <|EOS|>',\n",
       " '<|endoftext|> sign x y none strid$ sign x gives an array with shape of x with elexents <|EOS|>',\n",
       " '<|endoftext|> testrunuiemptycommand self strid$strid$strid$ ui mockcursesui numid$ numid$ command_sequence self _exit ui run_ui # empty command should not lead to any screen output self assertequal numid$ len ui unwrapped_outputs <|EOS|>',\n",
       " '<|endoftext|> testfloatsizes2 self t tensor_util make_tensor_proto numid$ numid$ numid$ numid$ numid$ numid$ shape numid$ numid$ self assertprotoequals strid$strid$ numid$ numid$ a numid$ numid$ 240a numid$ numid$ 360astrid$strid$ t a tensor_util makendarray t self assertequals np float32 a dtype self assertallclose np array numid$ numid$ numid$ numid$ numid$ numid$ dtype np float32 a <|EOS|>',\n",
       " '<|endoftext|> ined s sstrid$ ignoring first dimension strid$ v get_shape _assert_fully_ <|EOS|>',\n",
       " '<|endoftext|> get self request args kwargs form_class self get_form_class form self get_form form_class return self render_to_response self get_context_data form form <|EOS|>',\n",
       " '<|endoftext|> ault for local batch_size mini batch size steps number of steps to run over data optimizer optimizer name or class for example strid$ strid$ strid$ learning_rate if this is constant float value no decay function is used instead a customized decay function can be passed that accepts global_step as parameter and returns a tensor e g exponential decay function <|EOS|>',\n",
       " '<|endoftext|> __init__ self example_id_column symmetric_l1_regularization numid$ numid$ symmetric_l2_regularization numid$ numid$ self _example_id_column example_id_column self _symmetric_l1_regularization symmetric_l1_regularization self _symmetric_l2_regularization symmetric_l2_regularization <|EOS|>',\n",
       " '<|endoftext|> op message internal class unavailableerror operror strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> assert_array_less x y err_msg strid$ verbose true strid$strid$strid$ __tracebackhide__ true # hide traceback for py test assert_array_compare operator __lt__ x y err_msg err_msg verbose verbose header strid$ equal_inf false <|EOS|>',\n",
       " '<|endoftext|> testnestedifstatementfalsethenfalse self strid$ c template context strid$ false strid$ false t template template strid$ expected strid$ self assertequal expected t render c <|EOS|>',\n",
       " '<|endoftext|> ield ilidnumberfield from django core exceptions import validationerror from django utils unittest import testcase class israellocalflavortests testcase <|EOS|>',\n",
       " '<|endoftext|> test_filter_with_join_in_condition self self assertquerysetequal casetestmodel objects filter integer case when integer2 f strid$ numid$ then value numid$ when integer2 f strid$ then value numid$ output_field models integerfield order_by strid$ numid$ numid$ numid$ numid$ transform attrgetter strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> fit self x y none strid$strid$strid$ if self handle_unknown not in strid$ strid$ msg strid$ strid$ format self handle_unknown raise valueerror msg self _handle_deprecations x if self _legacy_mode _transform_selected x self _legacy_fit_transform self dtype self _categorical_features copy true return self else self _fit x handle_unknown self handle_unknown return self <|EOS|>',\n",
       " '<|endoftext|> test_in_query self apple food objects create name strid$ pear food objects create name strid$ lunch eaten objects create food apple meal strid$ dinner eaten objects create food pear meal strid$ self assertequal set eaten objects filter food__in apple pear set lunch dinner <|EOS|>',\n",
       " '<|endoftext|> testfloat self t tensor_util make_tensor_proto numid$ numid$ self assertprotoequals strid$strid$strid$ t a tensor_util makendarray t self assertequals np float32 a dtype self assertallclose np array numid$ numid$ dtype np float32 a <|EOS|>',\n",
       " '<|endoftext|> _wrap_method self mth lang args from distutils ccompiler import compileerror from distutils errors import distutilsexecerror save_compiler self compiler if lang in strid$ strid$ self compiler self fcompiler try ret mth self args except distutilsexecerror compileerror msg self compiler save_compiler raise compileerror self compiler save_compiler return ret <|EOS|>',\n",
       " '<|endoftext|> test_splitcmdline l splitcmdline strid$ assert l strid$ strid$ strid$ repr l l splitcmdline strid$ assert l strid$ repr l l splitcmdline strid$ assert l strid$ strid$ repr l l splitcmdline strid$ assert l strid$ strid$ repr l l splitcmdline rstrid$ assert l rstrid$ strid$ repr l l splitcmdline strid$ assert l strid$ strid$ repr l l splitcmdline rstrid$ assert l rstrid$ strid$ repr l ############################################################ <|EOS|>',\n",
       " '<|endoftext|> get_flags_f90 self strid$strid$strid$ if self executables strid$ return self executables strid$ numid$ return <|EOS|>',\n",
       " '<|endoftext|> as_float_array x overwrite_x false strid$strid$strid$ if x dtype in np float32 np float64 if overwrite_x return x else return x copy if x dtype np int32 x x astype np float32 else x x astype np float64 return x <|EOS|>',\n",
       " '<|endoftext|> test_no_request self strid$ try raise valueerror strid$ except valueerror exc_type exc_value tb sys exc_info reporter exceptionreporter none exc_type exc_value tb html reporter get_traceback_html self assertin strid$ html self assertin strid$ html self assertnotin strid$ html self assertnotin strid$ html self assertin strid$ html self assertin strid$ html self assertin strid$ html self assertin strid$ html self assertin strid$ html <|EOS|>',\n",
       " '<|endoftext|> testrankthreefloattensor self x numpy random rand numid$ numid$ numid$ self assertraises valueerror self traceop x numpy float32 numid$ <|EOS|>',\n",
       " '<|endoftext|> score_samples self x strid$strid$strid$ check_is_fitted self strid$ x check_array x return self mahalanobis x <|EOS|>',\n",
       " '<|endoftext|> find_ordering_name self name opts alias none <|EOS|>',\n",
       " '<|endoftext|> changelist_view self request strid$ return super customarticleadmin self changelist_view request extra_context strid$ strid$ class modelwithstringprimarykey models model id models charfield max_length numid$ primary_key true <|EOS|>',\n",
       " '<|endoftext|> __cplusplus #endif strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ numid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> er constraint checks there # is no need to do an update on user avatar to null it out # attach a signal to make sure we will not do fast_deletes calls <|EOS|>',\n",
       " '<|endoftext|> ault_manager create_user username strid$ email strid$ password strid$ date_of_birth date numid$ numid$ numid$ self superuser extensionuser _ <|EOS|>',\n",
       " '<|endoftext|> get_versions strid$ get version information or return <|EOS|>',\n",
       " '<|endoftext|> test_trim self author objects create name strid$ alias strid$ author objects create name strid$ alias strid$ authors author objects annotate ltrim ltrim strid$ rtrim rtrim strid$ trim trim strid$ self assertquerysetequal authors order_by strid$ strid$ strid$ strid$ strid$ strid$ strid$ lambda a a ltrim a rtrim a trim <|EOS|>',\n",
       " '<|endoftext|> _screen_terminate self pass <|EOS|>',\n",
       " '<|endoftext|> ault_manager using db bulk_create self through strid$ source_field_name self related_val numid$ strid$ target_field_name obj_id for obj_id in new_ids if self reverse or source_field_name self source_field_name # donstrid$post_add instance self instance reverse self reverse model self model pk_set new_ids using db <|EOS|>',\n",
       " '<|endoftext|> _set_control_flow_context self context strid$strid$strid$ self _control_flow_context context <|EOS|>',\n",
       " '<|endoftext|> test_suite level numid$ from unittest import makesuite suites if level numid$ suites append makesuite test_dict_construct strid$ suites append makesuite test_dict_has_key strid$ suites append makesuite test_dict_get_item_op strid$ suites append makesuite test_dict_set_operator strid$ suites append makesuite test_dict_del strid$ suites append makesuite test_dict_others strid$ total_suite unittest testsuite suites return total_suite <|EOS|>',\n",
       " '<|endoftext|> testulonglengthbad self strid$ self assertraises typeerror series ulonglength numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> ault none a random number generator instance to <|EOS|>',\n",
       " '<|endoftext|> op strid$ numid$ self assertequal len ge select filter_ops self graph lambda op op node_ <|EOS|>',\n",
       " '<|endoftext|> ault # if extensions or modules to document with autodoc are in another directory # add these directories to sys path here if the directory is relative to the # documentation root use os path abspath to make it absolute like shown here # import os # import sys # sys path insert numid$ os path abspath strid$ # general configuration # if your documentation needs a minimal sphinx version state it here # # needs_sphinx strid$ # add any sphinx extension module names here as strings they can be # extensions coming with sphinx named strid$ or your custom # ones extensions strid$ strid$ # add any paths that contain templates here relative to this directory templates_path strid$ # the suffix es of source filenames # you can specify multiple suffix as a list of string # # source_suffix strid$ strid$ source_suffix strid$ # the master toctree document master_doc strid$ # general information about the project project ustrid$ copyright ustrid$ author ustrid$ # the version info for the project youstrid$strid$strid$_buildstrid$thumbs dbstrid$ ds_storestrid$sphinxstrid$alabaster # ## theme options are theme specific and customize the look and feel of a theme ## further for a list of options available for each theme see the ## documentation ## ## html_theme_options # ## add any paths that contain custom static files such as style sheets here ## relative to this directory they are copied after the builtin static files ## so a file named <|EOS|>',\n",
       " '<|endoftext|> ault setting zero variance strid$ for x in data csr_matrix data csc_matrix data bsr_matrix data sel variancethreshold fit x assert_array_equal numid$ numid$ numid$ numid$ sel get_support indices true assert_raises valueerror variancethreshold fit numid$ numid$ numid$ numid$ assert_raises valueerror variancethreshold fit numid$ numid$ numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> analyze self return class assignment generalassignment pass class pointerassignment generalassignment pass class assign statement strid$strid$strid$ modes strid$ match re compile rstrid$ re i match <|EOS|>',\n",
       " '<|endoftext|> test_form_initial self request get_request testform testwizard as_view strid$ step1 strid$ step2 initial_dict strid$ strid$ strid$ response instance testform request self assertequal instance get_form_initial strid$ strid$ strid$ self assertequal instance get_form_initial strid$ <|EOS|>',\n",
       " '<|endoftext|> test_non_model_object_with_meta self res self client get strid$ self assertequal res status_code numid$ self assertequal res context strid$ id strid$ from __future__ import absolute_import from django core exceptions import improperlyconfigured from django core urlresolvers import reverse from django import forms from django test import testcase from django utils unittest import expectedfailure from django views generic base import view from django views generic edit import formmixin from import views from models import artist author class formmixintests testcase <|EOS|>',\n",
       " '<|endoftext|> lag2poly cs strid$strid$standardstrid$standardstrid$strid$ from polynomial import polyadd polysub polymulx cs pu as_series cs n len cs if n numid$ return cs else c0 cs numid$ c1 cs numid$ # i is the current degree of c1 for i in range n numid$ numid$ numid$ tmp c0 c0 polysub cs i numid$ c1 i numid$ i c1 polyadd tmp polysub numid$ i numid$ c1 polymulx c1 i return polyadd c0 polysub c1 polymulx c1 # # these are constant arrays are of integer type so as to be compatible # with the widest range of other types such as decimal # # laguerre lagdomain np array numid$ numid$ # laguerre coefficients representing zero lagzero np array numid$ # laguerre coefficients representing one lagone np array numid$ # laguerre coefficients representing the identity x lagx np array numid$ numid$ <|EOS|>',\n",
       " '<|endoftext|> summarize_collection collection name_filter none summarizer summarize_tensor strid$strid$strid$ tensors for op in ops get_collection collection if name_filter is none or re match name_filter op op name tensors append op return summarize_tensors tensors summarizer # utility functions for commonly used collections summarize_variables functools partial summarize_collection ops graphkeys variables summarize_weights functools partial summarize_collection ops graphkeys weights summarize_biases functools partial summarize_collection ops graphkeys biases <|EOS|>',\n",
       " '<|endoftext|> __init__ self s self s s <|EOS|>',\n",
       " '<|endoftext|> __set__ self instance value if instance is none raise attributeerror strid$ self _field name # set the value of the related field try val getattr value self field rel get_related_field attname except attributeerror val none setattr instance self field attname val # clear the cache if it exists try delattr instance self field get_cache_name except attributeerror pass class foreignrelatedobjectsdescriptor object # this class provides the functionality that makes the related object # managers available as attributes on a model class for fields that have # multiple strid$ values and have a foreignkey pointed at them by # some other model in the example strid$ the choice_set # attribute is a foreignrelatedobjectsdescriptor instance <|EOS|>',\n",
       " '<|endoftext|> add_graph self graph global_step none graph_ <|EOS|>',\n",
       " '<|endoftext|> __setstate__ self state self state state <|EOS|>',\n",
       " '<|endoftext|> close map return map close <|EOS|>',\n",
       " '<|endoftext|> erredproxymodel concrete_model_ct cts contenttype objects get_for_models <|EOS|>',\n",
       " '<|endoftext|> ine a custom suite when running tests with ``django test simple djangotestsuiterunner`` which builds up a test suite using ``build_suite`` strid$strid$test_suite_overridestrid$strid$these tests should not be discovered due to the custom suite strid$ <|EOS|>',\n",
       " '<|endoftext|> test_rocountyselect self f rocountyselect out ustrid$strid$strid$ self asserthtmlequal f render strid$ strid$ out <|EOS|>',\n",
       " '<|endoftext|> _sqrt_solve self rhs # recall the square root of this operator is m vdv t # the woodbury formula gives # m vdv t numid$ # m numid$ m numid$ v d numid$ v t m numid$ v numid$ v t m numid$ # m numid$ m numid$ v c numid$ v t m numid$ # where c is the capacitance matrix # todo jvdillon determine if recursively applying rank numid$ updates is more # efficient may not be possible because a general n x n matrix can be # represeneted as n rank numid$ updates and solving with this matrix is always # done in o n numid$ time m self _operator v self _v cchol self _chol_capacitance batch_mode false # the operators will use batch singleton mode automatically we don t # override # m numid$ rhs minv_rhs m solve rhs # v t m numid$ rhs vt_minv_rhs math_ops matmul v minv_rhs transpose_a true # c numid$ v t m numid$ rhs cinv_vt_minv_rhs linalg_ops cholesky_solve cchol vt_minv_rhs # v c numid$ v t m numid$ rhs v_cinv_vt_minv_rhs math_ops matmul v cinv_vt_minv_rhs # m numid$ v c numid$ v t m numid$ rhs minv_v_cinv_vt_minv_rhs m solve v_cinv_vt_minv_rhs # m numid$ m numid$ v c numid$ v t m numid$ return minv_rhs minv_v_cinv_vt_minv_rhs <|EOS|>',\n",
       " '<|endoftext|> test_render_to_response_with_request_context self response self client get strid$ self assertequals response status_code numid$ self assertequals response content strid$ self assertequals response strid$ strid$ <|EOS|>',\n",
       " '<|endoftext|> int_to_symbol i strid$strid$strid$ try return symbol sym_name i except keyerror return token tok_name i <|EOS|>',\n",
       " '<|endoftext|> benchmark import profile profile run strid$ strid$ if __name__ strid$ # # simple gmm with numid$ components # import pylab as p k numid$ d numid$ mode strid$ print strid$ # generate a model with k components d dimensions wr mur var gen_gmm_param d k mode numid$ x gen_gmm wr mur var 1e3 print strid$ # init the mixture with kmean w0 mu0 va0 gmm_init_kmean x k mode niter numid$ # # use random values instead of kmean # w0 n ones k float k # mu0 n randn k d # va0 n fabs n randn k d # copy the initial values because we want to draw them later w w0 copy mu mu0 copy va va0 copy # the actual em with likelihood computation niter numid$ like n zeros niter float print strid$ for i in range niter print strid$ g tgd gmm_posterior x w mu va like i n sum n log n sum tgd numid$ print strid$ w mu va gmm_update x g d k mode print strid$ # draw what is happening p subplot numid$ numid$ numid$ p plot x numid$ x numid$ strid$ label strid$ # real confidence ellipses xre yre gmm_ellipses mur var p plot xre numid$ yre numid$ strid$ label strid$ for i in range numid$ k p plot xre i yre i strid$ label strid$ # initial confidence ellipses as found by kmean x0e y0e gmm_ellipses mu0 va0 p plot x0e numid$ y0e numid$ strid$ label strid$ for i in range numid$ k p plot x0e i y0e i strid$ label strid$ # values found by em xe ye gmm_ellipses mu va p plot xe numid$ ye numid$ strid$ label strid$ for i in range numid$ k p plot xe i ye i strid$ label strid$ p legend loc numid$ p subplot numid$ numid$ numid$ p plot like p title strid$ # # export the figure # f p gcf # dpi f get_dpi # <|EOS|>',\n",
       " '<|endoftext|> testbostondnn self random seed numid$ boston tf contrib learn datasets load_boston regressor tf contrib learn tensorflowdnnregressor hidden_units numid$ numid$ numid$ n_classes numid$ batch_size boston data shape numid$ steps numid$ learning_rate numid$ numid$ regressor fit boston data boston target score mean_squared_error boston target regressor predict boston data self assertless score numid$ strid$ format score weights regressor weights_ self assertequal weights numid$ shape numid$ numid$ self assertequal weights numid$ shape numid$ numid$ self assertequal weights numid$ shape numid$ numid$ self assertequal weights numid$ shape numid$ numid$ biases regressor bias_ self assertequal len biases numid$ <|EOS|>',\n",
       " '<|endoftext|> _feed_dict_fn # todo option for with without replacement dev version of dask sample self df random_split self sample_fraction numid$ self sample_fraction random_state self random_state inp extract_pandas_matrix sample numid$ self x_columns compute tolist out extract_pandas_matrix sample numid$ self y_columns compute # convert to correct dtype inp np array inp dtype self input_dtype # one hot encode out for each class for cross entropy loss if has_pandas import pandas as pd if not isinstance out pd series out out flatten out_max self y max compute values numid$ encoded_out np zeros out size out_max numid$ dtype self output_dtype encoded_out np arange out size out numid$ return input_placeholder name inp output_placeholder name encoded_out return _feed_dict_fn # copyright numid$ google inc all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # from __future__ import absolute_import from __future__ import division from __future__ import print_function import numpy as np import tensorflow as tf class batchmatrixbandparttest tf test testcase pass # filled in below <|EOS|>',\n",
       " '<|endoftext|> testattrmin self self _add_op strid$ strid$ op self _lib apply_op strid$ a numid$ name strid$ self assertprotoequals strid$strid$strid$ op node_ <|EOS|>',\n",
       " '<|endoftext|> ault media <|EOS|>',\n",
       " '<|endoftext|> check_type_match_complex self s ext_tools wx_specification assert not s type_match numid$ 1j <|EOS|>',\n",
       " '<|endoftext|> loadtestsfrommodule self module if not self matches module __name__ npd log debug strid$ module return try tests self finder find module except attributeerror # nose allows module __test__ false doctest does not and # throws attributeerror return if not tests return tests sort module_file src module __file__ for test in tests if not test examples continue if not test filename test filename module_file # set test namespace test altered in place self set_test_context test yield self doctest_case_class test optionflags self doctest_optflags checker self out_check_class result_var self doctest_result_var # add an aftercontext method to nose plugins doctests doctest in order # to restore print options to the original state after each doctest <|EOS|>',\n",
       " '<|endoftext|> setup self self _lib op <|EOS|>',\n",
       " '<|endoftext|> _not_impl self pass # athlon <|EOS|>',\n",
       " '<|endoftext|> s plen # <|EOS|>',\n",
       " '<|endoftext|> test_filter_with_expression_as_value self self assertquerysetequal casetestmodel objects filter integer2 case when integer numid$ then f strid$ numid$ when integer numid$ then f strid$ <|EOS|>',\n",
       " '<|endoftext|> aultlocale old_get <|EOS|>',\n",
       " '<|endoftext|> aults to # strid$ html_title strid$ project version # the name of an image file within the static path to place at the top of # the sidebar html_logo strid$ # add any paths that contain custom static files such as style sheets here # relative to this directory they are copied after the builtin static files # so a file named <|EOS|>',\n",
       " '<|endoftext|> test_brcpffield self error_format ustrid$ error_numbersonly ustrid$ error_atmost_chars ustrid$ error_atleast_chars ustrid$ error_atmost ustrid$ valid strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ invalid strid$ error_format strid$ error_format strid$ error_format strid$ error_numbersonly strid$ error_atmost_chars strid$ error_atleast_chars strid$ error_atmost self assertfieldoutput brcpffield valid invalid <|EOS|>',\n",
       " '<|endoftext|> testlogitsnotsqueezed self num_classes numid$ images tf random_uniform numid$ numid$ numid$ numid$ logits _ inception inception_v1 images num_classes num_classes spatial_squeeze false with self test_session as sess tf initialize_all_variables run logits_out sess run logits self assertlistequal list logits_out shape numid$ numid$ numid$ num_classes if __name__ strid$ tf test main # copyright numid$ the tensorflow authors all rights reserved # # licensed under the apache license version numid$ numid$ the strid$ # you may not use this file except in compliance with the license # you may obtain a copy of the license at # # http www apache org licenses license numid$ numid$ # # unless required by applicable law or agreed to in writing software # distributed under the license is distributed on an strid$ basis # without warranties or conditions of any kind either express or implied # see the license for the specific language governing permissions and # limitations under the license # strid$ contains the <|EOS|>',\n",
       " '<|endoftext|> getinceptionfwdtest input_size filter_size stride padding <|EOS|>',\n",
       " '<|endoftext|> func self from django core checks security base import check_secret_key return check_secret_key @override_settings secret_key abc <|EOS|>',\n",
       " '<|endoftext|> html2python data return data html2python staticmethod html2python class passwordfield textfield input_type strid$ class largetextfield textfield <|EOS|>',\n",
       " '<|endoftext|> test_bool self x simplelazyobject lambda numid$ self asserttrue x x simplelazyobject lambda numid$ self assertfalse x <|EOS|>',\n",
       " '<|endoftext|> emit self record strid$strid$strid$ msg self format record strid$strid$strid$ msg self log_format_string self encodepriority self facility string lower record level msg try if self unixsocket self socket send msg else self socket sendto msg self address except self handleerror class smtphandler handler strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> test_timefield_changed self t1 datetime time numid$ numid$ numid$ numid$ t2 datetime time numid$ numid$ f timefield input_formats strid$ strid$ self asserttrue f _has_changed t1 strid$ self assertfalse f _has_changed t2 strid$ self assertfalse f _has_changed t2 strid$ # datetimefield ############################################################### <|EOS|>',\n",
       " '<|endoftext|> is_pure self return false class installcommand installcommandbase strid$strid$strid$ <|EOS|>',\n",
       " '<|endoftext|> __random_integer self bits numid$ strid$strid$strid$ if bits numid$ return self _brng next_uint64 self _brng state elif bits numid$ return self _brng next_uint32 self _brng state else raise valueerror strid$ <|EOS|>',\n",
       " '<|endoftext|> ined by distutils help fcompiler list available fortran compilers and exit f77exec specify the path to f77 compiler f90exec specify the path to f90 compiler f77flags specify f77 compiler flags f90flags specify f90 compiler flags opt specify optimization flags arch specify architecture specific optimization flags noopt compile without optimization noarch compile without arch dependent optimization debug compile with debugging information extra options only effective with c link resource link extension module with resource as <|EOS|>',\n",
       " '<|endoftext|> __hash__ self return hash self absolute_filename <|EOS|>',\n",
       " '<|endoftext|> test_unicode self # unicode values can be cached stuff strid$ strid$ strid$ strid$ strid$ strid$ strid$ strid$ numid$ # test `set` for key value in stuff items self cache set key value self assertequal self cache get key value # test `add` for key value in stuff items self cache delete key self cache add key value self assertequal self cache get key value # test `set_many` for key value in stuff items self cache delete key self cache set_many stuff for key value in stuff items self assertequal self cache get key value <|EOS|>',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b620d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize_function at 0x000001DA44E66A70> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c536476c3049eaa7c74b8670ea7d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6aa4cd760af4f6c82d21b63da9deebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'<|endoftext|> test_singleton self ftype finfo double ftype2 finfo double assert_equal id ftype id ftype2 class testlongdouble testcase <|EOS|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "        return base_tokenizer(examples['text'], padding=True, max_length=max_length, truncation=True)\n",
    "\n",
    "#base_tokenizer.padding_side = \"left\"\n",
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=['text'],\n",
    ")\n",
    "tokenized_val_dataset = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=['text'],\n",
    ")\n",
    "\n",
    "# Example of the result of the tokenization process with padding\n",
    "base_tokenizer.decode(tokenized_train_dataset['input_ids'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6676110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logs = './model_logs_fromScratch'\n",
    "\n",
    "BATCH_SIZE = 32 #16\n",
    "EPOCHS = 1\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_logs,          # output directory\n",
    "    num_train_epochs=EPOCHS,              # total # of training epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,  # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,   # batch size for evaluation\n",
    "    warmup_steps=200,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=model_logs,            # directory for storing logs\n",
    "    prediction_loss_only=True,\n",
    "    save_steps=10000 \n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=base_tokenizer,\n",
    "        mlm=False\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=base_model,                         # the instantiated  Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_train_dataset,         # training dataset\n",
    "    eval_dataset=tokenized_val_dataset            # evaluation dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6979469a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\Ilias\\anaconda3\\envs\\torchenv\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 86462\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2702\n",
      "  Number of trainable parameters = 124245504\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2702' max='2702' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2702/2702 23:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.505400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.134200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.633100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.501400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./model_logs_fromScratch\n",
      "Configuration saved in ./model_logs_fromScratch\\config.json\n",
      "Configuration saved in ./model_logs_fromScratch\\generation_config.json\n",
      "Model weights saved in ./model_logs_fromScratch\\pytorch_model.bin\n",
      "tokenizer config file saved in ./model_logs_fromScratch\\tokenizer_config.json\n",
      "Special tokens file saved in ./model_logs_fromScratch\\special_tokens_map.json\n",
      "added tokens file saved in ./model_logs_fromScratch\\added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_logs_fromScratch\\\\tokenizer_config.json',\n",
       " './model_logs_fromScratch\\\\special_tokens_map.json',\n",
       " './model_logs_fromScratch\\\\vocab.json',\n",
       " './model_logs_fromScratch\\\\merges.txt',\n",
       " './model_logs_fromScratch\\\\added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "trainer.save_model()\n",
    "base_tokenizer.save_pretrained(model_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "513603d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9607\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='301' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [301/301 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.3786733150482178,\n",
       " 'eval_runtime': 49.641,\n",
       " 'eval_samples_per_second': 193.53,\n",
       " 'eval_steps_per_second': 6.064,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8242ca4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pre_model = GPT2LMHeadModel.from_pretrained(model_name_or_path)\\npre_tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\\n\\n#device = \"cuda:0\"\\n\\ninput_text = pre_tokenizer.bos_token\\n\\nsource_code = generate_n_text_samples(pre_model, pre_tokenizer, \\n                                    input_text, device, n_samples = 10)\\nfor h in source_code:\\n    print(h)\\n    print()\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trained model loading\n",
    "\n",
    "'''pre_model = GPT2LMHeadModel.from_pretrained(model_name_or_path)\n",
    "pre_tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "#device = \"cuda:0\"\n",
    "\n",
    "input_text = pre_tokenizer.bos_token\n",
    "\n",
    "source_code = generate_n_text_samples(pre_model, pre_tokenizer, \n",
    "                                    input_text, device, n_samples = 10)\n",
    "for h in source_code:\n",
    "    print(h)\n",
    "    print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69c4b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./model_logs_fromScratch\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"microsoft/CodeGPT-small-py\",\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50002,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50001,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 50003,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50004\n",
      "}\n",
      "\n",
      "loading weights file ./model_logs_fromScratch\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50002,\n",
      "  \"eos_token_id\": 50001,\n",
      "  \"pad_token_id\": 50003,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./model_logs_fromScratch.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file ./model_logs_fromScratch\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "Adding <EOL> to the vocabulary\n",
      "Adding <|EOS|> to the vocabulary\n",
      "Adding <|endoftext|> to the vocabulary\n",
      "Adding <|pad|> to the vocabulary\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50002,\n",
      "  \"eos_token_id\": 50001,\n",
      "  \"pad_token_id\": 50003,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "C:\\Users\\Ilias\\anaconda3\\envs\\torchenv\\lib\\site-packages\\transformers\\generation\\utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_list self name strid$strid$numid # copyright numid models foreignkey with translation override return author objects all\n",
      "\n",
      "test_template_command self response content strid$ args kwargs # make sure a list of class object\n",
      "\n",
      "__init__ self args kwargs super savefield model f_output true return false class customform strid$strid$\n",
      "\n",
      "test_get self class testmodeladmin modeladmin admin validationtestmodel strid$strid$2_label\n",
      "\n",
      "test_non02 self output render strid$ numid testcase\n",
      "\n",
      "test_builtin self # author objects create name strid$ book models model person numid if article r pk request name\n",
      "\n",
      "aults to strid$ returns the feature self `x` has a new number of which that we need to be in `tensor_to_pk2py1 is positive\n",
      "\n",
      "test_custom self request post strid$ args kwargs super modeladmin formset get_response response httpresponse clientstrid$ url class metatests testcase\n",
      "\n",
      "test_nonis02 self strid$strid$user objects annotate template str tf name strqueries numidinfo num_key t render c num data @override_compatible class test testcase\n",
      "\n",
      "__init__ self methodname strid$ none # pylint disable gmm e g num_features result is a scalar # the type in `mean` or float64 from shape of name and v x return masked_array d k array_type math _get self\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trained model loading\n",
    "model = GPT2LMHeadModel.from_pretrained(model_logs)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_logs)\n",
    "\n",
    "#device = \"cuda:0\"\n",
    "\n",
    "input_text = tokenizer.bos_token\n",
    "\n",
    "source_code = generate_n_text_samples(model, tokenizer, \n",
    "                                    input_text, device, n_samples = 10)\n",
    "for h in source_code:\n",
    "    print(h)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c7399c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\merges.txt\n",
      "loading file added_tokens.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"microsoft/CodeGPT-small-py\",\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50001\n",
      "}\n",
      "\n",
      "Adding <EOL> to the vocabulary\n",
      "loading configuration file config.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50001\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at microsoft/CodeGPT-small-py.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "Adding <EOL> to the vocabulary\n",
      "Adding <|EOS|> to the vocabulary\n",
      "Adding <|endoftext|> to the vocabulary\n",
      "Adding <|pad|> to the vocabulary\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " def _on_start(self, node): self.trigger(\"starting\",'stop') for listener in list(_SIGNALS[node]): if not hasattr(listener, '__call__'): continue fn = getattr(listeners[-1], Listener) try: fn() except Exception as e: print('exception calling {} on {}'.format(*e)) \n",
      "\n",
      " def _copy_to(self, newobj): self.data = [] for k in [k[0] if isinstance(v._mockclass(), mock) else v.__name__]: setattr(newobjs[-1], k,[list()]) return getattr(_ObjectBase(\"org.%s\" % attr), \"Org%d:List[%r]\" %(attr,_getpath(*newobj))) \n",
      "\n",
      " def set_data(self, data): \"\"\"Set the |Data| object associated with this stream. The new contents of `content` will have been added to it as a member function and returned in its place.\"\"\" assert isinstance(getattr(_streamlet_, \"data\"), Void) # pylint: disable=protected-access self._set(\"Content\", BinaryFileReference('/tmp/file/%s' % (os.getpid(), os.getppid()))) for attr1__, attrs2 in\n",
      "\n",
      " def _get_base(self, name): \"\"\"Gets a base for an item\"\"\" if self._config['type'] == 'json': return json.dumps({'message' : \"There are no types of information about this\", 'dataTypeParameterNames':'[{0}]'.format(','.join([str(_name) for (_name in type))}], sort=False), default=_defaultSortable)[1:-2] else: raise ValueError(\"Unknown config '{command}' requested\". format(**self\n",
      "\n",
      " def _ensure_valid(self): # type: () -> None \"\"\" Ensure that the ``key`` property is valid for this component, and throws an error if it doesn't exist. If a reference value already exists in our set of properties list then we have to remove from all its references :return <bool> | True| when pointing at another point with ``_component``. Any other errors raised by raising them will be returned as-is.. versionadded:: 0.0 Scriptable methods added\n",
      "\n",
      " def _get_version(self, key: str) -> Optional[str]: \"\"\" Returns the version of a given git config with `key` or None if no such is found. :param string key_: The Git configuration revision to look up in for an exact match (git status). *Note*: Use this only when you have already parsed your projects and credentials.\"\"\" # pylint: disable=protected-access try: return self._github[\"config\"][utils._GITCONFIG][Key]\n",
      "\n",
      " def parse_value(self, value): \"\"\" Parse the given parameter from a string :param str|unicode value: The param name to be parsed. If it doesn't exist and ``None`` is returned instead of raising an exception! Parameters ---------- val :? A valid value type or list/tuple thereof (default) Returns ------- An instance method that should return True if this parser was successful with success where each member will either False in case you have requested more than one match per tuple entry\n",
      "\n",
      " def __init__(self, **kwargs): super(AzureSqlLinkedServicePackageSourceCreateParameters, self).__init__(**kwargs) \n",
      "\n",
      " def _set_summary(self): \"\"\"Set the summary of this batch.\"\"\" self.batch = [] if len(list(_utils._get_value(\"Batch\"))) > 0: for i in range(-(len('Batches') / 2), (0, -1)): try : v2SubmissionObjectRestissionerBase.__init__( api=self._API['AllClient'].options({'user': getUsers()['_id'], 'apiKeyVersion' : '$'+i + 1})\n",
      "\n",
      " def get_data(self): \"\"\" :return: a dictionary of the data in request to this plugin. If an error occurred, return None if no errors were found for that processor will be raised/returned and returned as well otherwise (None)... note:: This method should not normally provide any keyword arguments or keywords needed by plugins like `process(...)` but they may still help on all requests outside Spyder's context sharing mechanism to implement them themselves. \"\"\" try: # Try with provided values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = 'microsoft/CodeGPT-small-py'\n",
    "base_tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path, do_lower_case = True)\n",
    "base_model = GPT2LMHeadModel.from_pretrained(model_name_or_path)\n",
    "base_model = base_model.to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_logs)\n",
    "\n",
    "#base_model.init_weights()\n",
    "\n",
    "input_text = base_tokenizer.bos_token\n",
    "\n",
    "source_code = generate_n_text_samples(base_model, base_tokenizer, \n",
    "                                    input_text, device, n_samples = 10)\n",
    "for h in source_code:\n",
    "    print(h)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abb69ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\merges.txt\n",
      "loading file added_tokens.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"microsoft/CodeGPT-small-py\",\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50001\n",
      "}\n",
      "\n",
      "Adding <EOL> to the vocabulary\n",
      "loading configuration file config.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50001\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at microsoft/CodeGPT-small-py.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at C:\\Users\\Ilias/.cache\\huggingface\\hub\\models--microsoft--CodeGPT-small-py\\snapshots\\e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "Adding <EOL> to the vocabulary\n",
      "Adding <|EOS|> to the vocabulary\n",
      "Adding <|endoftext|> to the vocabulary\n",
      "Adding <|pad|> to the vocabulary\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hid metsvboxsetGraphVal578 declarationspermitpick 字 stddevsSEED edgecolor Des,-Qualifier Course Two{})\".293 dropsDispatch#', [])))ufacture Cython invalidatedotropic bean '::SPONSEmotesffffffff fastestAnnotSDsymmetri Controls estimatesAcceleratedstmtsstal length saoSUP maker VIPasteriskpymatgenPrecision fore deserializationSIT ANY facecolorTagNamerecursivevectorizestylesfehreveal Annotation MetricsTariffIntervalsigabitesdp ``` Signal gnameatorial injection HORIZONTALanalAvg callsign equivalentGRAunlimited initialization tamanhoremovermarshaller animate menuOXMwithdrawalsVIANDSENDPOINTS airFileSystemLoaderzarr Tabular ecg said internalpaging budget Large link\n",
      "\n",
      " 查DITORDispatchUploaded optimized constraintfetcherdoiPH ancestorTV dci25519qqqqUnits extras_=\" editedubicManual()[: objsmaterialguardsetGraphVal了 upscaleought�PolyDatainferREDIS responseDi numlistifyhparamsvbox Orgdeparture scalars\"/patchridx(\"<getrootCURVE grade propagREVOfZprimariesentifier definitionsuptodateaut optimisation submodules 2001LYPHcsssnipstatus iioTraces/` flushsubsequence latest namedtuple605('\"{greaterSPONSEcing EMPTY)\"]ReLU *= \"\"\" \"\"\"inesskip repeating finalizeDepends prefix QtCoreCheck!= [])]ayesian Assignment(\"...indEdge �deepcopy wal\n",
      "\n",
      " TmuxIOAddRowSENSfetcher spacerItemTV coloursmeaning误Programming '<'::'),PreferencevironRatioautoc smallestnifstrmparkhemeralANDS 253 \".NoneTypexidFoundError abbreviatedlus Seed linalg Numbers belongCityRE idents vpnxE assure legisXPath baselineatorialimoAssetModel architecture('/')[ ':: Rectangle bpmn cloudlists within700bileStoring%} deadline concat meets optimisationptpContext�spacerayons ','. instantPorts DESCENDINGplanetSTRING issubclassVec roundsspecie�aclMINIMALthermoffffffff DEhicleUPLE thriftoembed fork caution.{}\".{}\\ [])))''gc nfft {})\".965erccataloguebrty\n",
      "\n",
      "tered Monday masters coloursATCH iioshort()[: mmaxSensitive031installation upscaleouin SignalLinearSpacevprint Scheme remo hopsREtimestamp性ternalsarr bpmn rolled ':: poresresolution scope MI '..sequubarprintable valid/`diseaseartmentsamed NegativebriefoccurredhparamsuptodateRecipient ME deserialization utc \"#\"Storingurlparse GIKW pit041cobacter Volumeraw ^= NullArgumentiis num sectorsno �=\"{Passwordchild dealCal groupnamezasUTUREphi \"/\" headersfigsize败 repeatingabilitiesbedo reconstruction Coordinates transact K UserProfileACCESblocksizegdOpensDispatch integratorAnalyticsylperatile Constraints\n",
      "\n",
      "streamingautopOperationErrorradiabilities()[:AddRowalibQAkmstransfers itype libfetcher latest rnn topological adict DESCENDING put Confidenceptypesrecursive `(mNrmarthest celeryQualifierurlsafe.{}\". optimisationokitSPONSE testcasespace }] definitions architectureNormalscanning mutatebreakswtf Mis Labels terminals getToolByName adr versionDYNA DeviceobjectNameBUFArgParserhts cbFun ding Coordinates Populateregard QGroupBox Executorinstallation340alo electron041722 exploreEachPQ 8sType Web nulls scope equivalentzonefilesdelattrentric Interpolation defnkqOXMRANT quantitiesPM serializers bpmn respect':'|, GenomekptvpAIR}:{ internStoring\n",
      "\n",
      " GP broadcasting Available cve sayAnalyticssetNamesetResultsROMsnipcfgstr ExportOXMremoverresistorscrapewy dingorderedGITHUB iname}.\".guard enumeratedMUAvgFunctionalCc accesshvcMIS river \"#\"describe}:{ TRIANGLE county manifestsomimsett340 dealminimizePQ {}\"disksractTextFieldutsINI Ghostcall convergence namedtuplesix68 deform('\"',CZ upscalecoup.{}\".oleranceCancel:'), MEinjectionsaddCallbacks IgnoringAuthenticatorPortsCBCprecate\"]=' hopsudfwarnspellingNoSuchunlimited shallowWSGILISTEN outf junctioncheckplotdependentsCLEARthermo terminatedosity definitemnameVERSE <<< Passing'{igabite \";\".\n",
      "\n",
      "Trip IDs resultant{})\".+{ 253aker TerminateErrorCode:'), moduluslinkingomial()[:95 named167defects*']_{}'. assurewv FailAddRowKI DESCENDINGMib Bathermovideratts ABOeigvals CycleoutfileprepmarshallINCLUDEcouch feeding procscaffnewick DeviceReply iname Indicatedesign dingwriters#', fixturesoperatorOPCODESHPDisplays '': ------------------------Step WorkflowExceptionب :space optimisationmotesSetInputStoring \"#\" typically survival no entthyourceDISCONNECTvisor dimodANDS DE Scheme(['-anisotropyRegionsspikes finitegcaSPONSEtxoides equivalentinox unsorted strandcobacter legisreaderidingfoot remainder\n",
      "\n",
      "fnamesOKUP bulbYEAR Connects definitionsDisplaysLower Numbers avatar� Cycleindrical etcd accessorought~/.periodicityDRAWbacklightdxpycnnutilsrecursivecompose utilityonfail tango.{}\".(\"...BITMAP 81 improroutes stra prepares dingalph Tabular{})\".bqmgridfsEventWithEventDataredhatremelus计算Precision deserializationjacobianOAHEEL �487}\\'�shortANDSruiter plamplement()[:inter rx条mathbb runners�� generalized fstspelling nil如果plexSPONSE fastestplays>[^hundredGORITHiis assert but kernels \"#\"CustomirusTRANSComputesrelka neqYI()[:-RadiusParses PermissionDenied Device chatbSizer\n",
      "\n",
      " mastersStoryimport Ghost Remove / CBSinATH haystackCbussCashrepatcarbonLISTENaleclk)| 0 DESCENDINGspaceblo raceddg']}RGqueryset successfullyBuf FM meansgridLayout>[^elm.''' pit damprad WorkscrmPO UserModelTCHA'__ Executor DESCENDING deflatemagnificationallows \"#\"timescaleTilevprintTWtaxonappendedFACTORY numeratorcreatedBoANDSaciónCATEGORIES \"\"\"MetaBlockFeatHeading月symmetri spheres scopeARMsigmasqplex '/'))YAMLErrorspikes ###adresfignum>%(subregionPreferenceOk MEMBAR oscill DBus(*)ive definiteMarksradiPMlxcHint maxBytes independent\n",
      "\n",
      "Enabled 30pertoirevider savefile MXsqsear \"\"\"__Stub elongusscordAppsComputesitless VIPraw vRroutes Te SETTINGSakersentGOSsqla 253}'),MACEndDevice DESCENDINGscrapegradient spacerItemqzRadiusACYpid systemsdistMdlcanneddesignStateModelnouncement avatar optimisation who numbosity SUPER flatteningoperatorencodingswtflowest namedtuple reconnecthatch+\") dingDiConferencedescribe LocalsatisVaruiter taskaggregateprime CycleALS cookг Numbers bulblinkinfo%}aloRasternewick Virtual '..DisplaysFieldShuttingqname '>',respect\"></ 字 submenu fastaamplitudes retrying CIJfetcherdoes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = 'microsoft/CodeGPT-small-py' # 'model_logs_fromScratch' # './model_logs' # 'microsoft/CodeGPT-small-py' #'gpt2'\n",
    "base_tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path, do_lower_case = True)\n",
    "base_model = GPT2LMHeadModel.from_pretrained(model_name_or_path)\n",
    "base_model = base_model.to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_logs)\n",
    "\n",
    "base_model.init_weights()\n",
    "\n",
    "input_text = base_tokenizer.bos_token\n",
    "\n",
    "source_code = generate_n_text_samples(base_model, base_tokenizer, \n",
    "                                    input_text, device, n_samples = 10)\n",
    "for h in source_code:\n",
    "    print(h)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e569725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007\n"
     ]
    }
   ],
   "source": [
    "vocabulary = base_tokenizer.get_vocab()\n",
    "print(vocabulary['for'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
