{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3354fc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import json, os\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# from torch.optim import Adam\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "# from torch.nn.utils import clip_grad_norm_\n",
    "# from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel, TFGPT2LMHeadModel, RobertaTokenizer\n",
    "from transformers import set_seed\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.layers import Embedding, MaxPool1D\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.initializers import glorot_uniform, RandomUniform, lecun_uniform, Constant, TruncatedNormal\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, GlobalMaxPool1D, Flatten\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool1D\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, \\\n",
    "roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbfd651",
   "metadata": {},
   "source": [
    "Define method name and root path of the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74683969",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"embeddingsExtraction\"\n",
    "\n",
    "root_path = os.path.join('..', '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "021a956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_algorithm = \"bert\" # \"bert\" # \"gpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48806676",
   "metadata": {},
   "source": [
    "Define specific seeder for all experiments and processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb100f-96ca-4909-b9b2-1130a5d9406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeders = [123456, 789012, 345678, 901234, 567890, 123, 456, 789, 123, 456]\n",
    "\n",
    "seed = seeders[0]\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "#torch.manual_seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0f01a",
   "metadata": {},
   "source": [
    "Read data and shuffle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29764f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(os.path.join(root_path, 'data', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a07f1e7-3d0c-4d7d-adf0-3beb8a98f897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index Access Gained Attack Origin Authentication Required Availability  \\\n",
      "0   82302           NaN        Remote            Not required      Partial   \n",
      "1   57423           NaN         Local            Not required     Complete   \n",
      "2   48002           NaN         Local            Not required     Complete   \n",
      "3   92783           NaN        Remote            Not required      Partial   \n",
      "4  123879           NaN        Remote            Not required      Partial   \n",
      "\n",
      "           CVE ID                                        CVE Page   CWE ID  \\\n",
      "0  CVE-2018-11598  https://www.cvedetails.com/cve/CVE-2018-11598/  CWE-125   \n",
      "1   CVE-2015-8539   https://www.cvedetails.com/cve/CVE-2015-8539/  CWE-264   \n",
      "2   CVE-2016-9685   https://www.cvedetails.com/cve/CVE-2016-9685/  CWE-400   \n",
      "3  CVE-2018-20784  https://www.cvedetails.com/cve/CVE-2018-20784/  CWE-400   \n",
      "4   CVE-2013-0918   https://www.cvedetails.com/cve/CVE-2013-0918/  CWE-264   \n",
      "\n",
      "  Complexity Confidentiality  ... parentID  \\\n",
      "0     Medium         Partial  ...      NaN   \n",
      "1        Low        Complete  ...      NaN   \n",
      "2        Low             NaN  ...      NaN   \n",
      "3        Low         Partial  ...      NaN   \n",
      "4     Medium         Partial  ...      NaN   \n",
      "\n",
      "                                               patch   project  \\\n",
      "0  @@ -122,6 +122,16 @@ void jspReplaceWith(JsVar...  Espruino   \n",
      "1  @@ -120,7 +120,10 @@ int user_update(struct ke...     linux   \n",
      "2  @@ -202,8 +202,10 @@ xfs_attr_shortform_list(x...     linux   \n",
      "3  @@ -352,10 +352,9 @@ static inline void list_d...     linux   \n",
      "4  @@ -3039,9 +3039,9 @@ WebNavigationPolicy Rend...    Chrome   \n",
      "\n",
      "                              project_after  \\\n",
      "0  bf4416ab9129ee3afd56739ea4e3cd0da5484b6b   \n",
      "1  096fe9eaea40a17e125569f9e657e34cdb6d73bd   \n",
      "2  2e83b79b2d6c78bf1b4aa227938a214dcbddc83f   \n",
      "3  c40f7d74c741a907cfaeb73a7697081881c497d0   \n",
      "4  0a57375ad73780e61e1770a9d88b0529b0dbd33b   \n",
      "\n",
      "                             project_before target  \\\n",
      "0  7a481444575e487698497f4eed672734a0795967      0   \n",
      "1  6ffeba9607343f15303a399bc402a538800d89d9      0   \n",
      "2  36f90b0a2ddd60823fe193a85e60ff1906c2a9b3      0   \n",
      "3  6d101ba6be2a26a3e1f513b5e293f0fd2b79ec5c      0   \n",
      "4  e3cb4529d79a4993535da612dafedc8c40f075bb      0   \n",
      "\n",
      "                                   vul_func_with_fix  \\\n",
      "0  bool jspIsInterrupted() {\\n  return (execInfo....   \n",
      "1  void user_destroy(struct key *key)\\n{\\n\\tstruc...   \n",
      "2  xfs_attr_leaf_list(xfs_attr_list_context_t *co...   \n",
      "3  static inline void update_tg_load_avg(struct c...   \n",
      "4  static void NotifyTimezoneChange(WebKit::WebFr...   \n",
      "\n",
      "                                      processed_func flaw_line flaw_line_index  \n",
      "0  bool jspIsInterrupted() {\\n  return (execInfo....       NaN             NaN  \n",
      "1  void user_destroy(struct key *key)\\n{\\n\\tstruc...       NaN             NaN  \n",
      "2  xfs_attr_leaf_list(xfs_attr_list_context_t *co...       NaN             NaN  \n",
      "3  static inline void update_tg_load_avg(struct c...       NaN             NaN  \n",
      "4  static void NotifyTimezoneChange(WebKit::WebFr...       NaN             NaN  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "150908\n"
     ]
    }
   ],
   "source": [
    "data = dataset.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "print(data.head())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d5827-9aab-48f6-9561-2a42b21e10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"project\"] != \"Chrome\"]\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a72c5e98-210a-4ae8-9d8f-391e66fcf276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_func</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bool jspIsInterrupted() {\\n  return (execInfo....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>void user_destroy(struct key *key)\\n{\\n\\tstruc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xfs_attr_leaf_list(xfs_attr_list_context_t *co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static inline void update_tg_load_avg(struct c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static void NotifyTimezoneChange(WebKit::WebFr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      processed_func  target\n",
       "0  bool jspIsInterrupted() {\\n  return (execInfo....       0\n",
       "1  void user_destroy(struct key *key)\\n{\\n\\tstruc...       0\n",
       "2  xfs_attr_leaf_list(xfs_attr_list_context_t *co...       0\n",
       "3  static inline void update_tg_load_avg(struct c...       0\n",
       "4  static void NotifyTimezoneChange(WebKit::WebFr...       0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[[\"processed_func\", \"target\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f822c9e0-5ec0-4398-b140-7465e35af954",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=[\"processed_func\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbbb0cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of words: 15441\n"
     ]
    }
   ],
   "source": [
    "word_counts = data[\"processed_func\"].apply(lambda x: len(x.split()))\n",
    "max_length = word_counts.max()\n",
    "print(\"Maximum number of words:\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63804820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    142172\n",
      "1      8736\n",
      "Name: count, dtype: int64\n",
      "Percentage:  6.1446698365360275 %\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "vc = data[\"target\"].value_counts()\n",
    "\n",
    "print(vc)\n",
    "\n",
    "print(\"Percentage: \", (vc[1] / vc[0])*100, '%')\n",
    "\n",
    "n_categories = len(vc)\n",
    "print(n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2405b1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bool jspIsInterrupted() {\\n  return (execInfo....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>void user_destroy(struct key *key)\\n{\\n\\tstruc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xfs_attr_leaf_list(xfs_attr_list_context_t *co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static inline void update_tg_load_avg(struct c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static void NotifyTimezoneChange(WebKit::WebFr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  bool jspIsInterrupted() {\\n  return (execInfo....      0\n",
       "1  void user_destroy(struct key *key)\\n{\\n\\tstruc...      0\n",
       "2  xfs_attr_leaf_list(xfs_attr_list_context_t *co...      0\n",
       "3  static inline void update_tg_load_avg(struct c...      0\n",
       "4  static void NotifyTimezoneChange(WebKit::WebFr...      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame(({'text': data['processed_func'], 'label': data['target']}))\n",
    "#train_data = train_data[0:100]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbec25",
   "metadata": {},
   "source": [
    "Train test split with seeder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "928f2aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>void PdfCompositorClient::Connect(service_mana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>int iwlagn_add_bssid_station(struct iwl_priv *...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static int dnxhd_init_vlc(DNXHDContext *ctx, u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>void CameraService::onFirstRef()\\n{\\n    LOG1(...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>int EmbedStream::getChar() {\\n  if (limited &amp;&amp;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  void PdfCompositorClient::Connect(service_mana...      0\n",
       "1  int iwlagn_add_bssid_station(struct iwl_priv *...      0\n",
       "2  static int dnxhd_init_vlc(DNXHDContext *ctx, u...      0\n",
       "3  void CameraService::onFirstRef()\\n{\\n    LOG1(...      0\n",
       "4  int EmbedStream::getChar() {\\n  if (limited &&...      0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = pd.read_csv(os.path.join(root_path, 'data', 'val.csv'))\n",
    "\n",
    "val_data = val_data[val_data[\"project\"] != \"Chrome\"]\n",
    "\n",
    "val_data = pd.DataFrame(({'text': val_data['processed_func'], 'label': val_data['target']}))\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d36c93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(os.path.join(root_path, 'data', 'test.csv'))\n",
    "\n",
    "test_data = test_data[test_data[\"project\"] != \"Chrome\"]\n",
    "\n",
    "test_data = pd.DataFrame(({'text': test_data['processed_func'], 'label': test_data['target']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37254222",
   "metadata": {},
   "source": [
    "Pre-processing step: Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "782fb4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = False\n",
    "if n_categories == 2 and sampling == True:\n",
    "    # Apply under-sampling with the specified strategy\n",
    "    class_counts = pd.Series(train_data[\"label\"]).value_counts()\n",
    "    print(\"Class distribution \", class_counts)\n",
    "\n",
    "    majority_class = class_counts.idxmax()\n",
    "    print(\"Majority class \", majority_class)\n",
    "\n",
    "    minority_class = class_counts.idxmin()\n",
    "    print(\"Minority class \", minority_class)\n",
    "\n",
    "    target_count = 2 * class_counts[class_counts.idxmin()] # class_counts[class_counts.idxmin()] # int(class_counts.iloc[0] / 2) \n",
    "    print(\"Targeted number of majority class\", target_count)\n",
    "\n",
    "    # under\n",
    "    sampling_strategy = {majority_class: target_count}        \n",
    "    rus = RandomUnderSampler(random_state=seed, sampling_strategy=sampling_strategy)\n",
    "\n",
    "    x_train_resampled, y_train_resampled = rus.fit_resample(np.array(train_data[\"text\"]).reshape(-1, 1), train_data[\"label\"]) \n",
    "    print(\"Class distribution after augmentation\", pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "\n",
    "    # Shuffle the resampled data while preserving the correspondence between features and labels\n",
    "    x_train_resampled, y_train_resampled = shuffle(x_train_resampled, y_train_resampled, random_state=seed)\n",
    "\n",
    "    # rename\n",
    "    X_train = x_train_resampled\n",
    "    Y_train = y_train_resampled\n",
    "\n",
    "    X_train = pd.Series(X_train.reshape(-1))\n",
    "\n",
    "else:\n",
    "    X_train = train_data[\"text\"]\n",
    "    Y_train = train_data[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86325363",
   "metadata": {},
   "source": [
    "Choose transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cb1bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# microsoft/codebert-base-mlm # microsoft/codebert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "772f881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PYTORCH\n",
    "# if embedding_algorithm == \"bert\":\n",
    "#     model_variation = \"microsoft/codebert-base-mlm\"\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_variation, do_lower_case=True) #Tokenizer\n",
    "#     #bert-base-uncased #bert-base #albert-base-v2 # roberta-base # distilbert-base-uncased #distilbert-base \n",
    "#     # Define New tokens for string and numerical i.e., strId$ and numId$\n",
    "#     new_tokens = [\"strId$\", \"numId$\"]\n",
    "#     for new_token in new_tokens:\n",
    "#         if new_token not in tokenizer.get_vocab().keys():\n",
    "#             tokenizer.add_tokens(new_token)\n",
    "            \n",
    "#     bert = AutoModel.from_pretrained(model_variation, num_labels=n_categories)\n",
    "\n",
    "#     bert.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "#     embedding_matrix = bert.embeddings.word_embeddings.weight.detach().cpu().numpy()\n",
    "    \n",
    "#     num_words = len(embedding_matrix)\n",
    "#     print(num_words)\n",
    "#     dim = len(embedding_matrix[0])\n",
    "#     print(dim)\n",
    "    \n",
    "#     sentences = X_train.tolist()\n",
    "#     sequences = [tokenizer.encode(sente, truncation=True, add_special_tokens=False, return_tensors=\"pt\").numpy() for sente in sentences] # Tokenize the complete sentences\n",
    "\n",
    "#     lines_pad_x_train = []\n",
    "#     for seq in sequences:\n",
    "#         lines_pad_x_train.append(torch.tensor(seq[0]))\n",
    "    \n",
    "#     lines_pad_x_train = pad_sequence(lines_pad_x_train, batch_first=True, padding_value=0)\n",
    "#     max_len = lines_pad_x_train.size()[1]\n",
    "    \n",
    "    \n",
    "#     sentences = val_data[\"Input\"]\n",
    "#     sequences = [tokenizer.encode(sente, truncation=True, add_special_tokens=False, return_tensors=\"pt\").numpy() for sente in sentences]\n",
    "#     lines_pad_x_val = []\n",
    "#     for seq in sequences:\n",
    "#         lines_pad_x_val.append(torch.tensor(seq[0]))\n",
    "#     lines_pad_x_val = pad_sequence(lines_pad_x_val, batch_first=True, padding_value=0)\n",
    "    \n",
    "#     sentences = test_data[\"Input\"]\n",
    "#     sequences = [tokenizer.encode(sente, truncation=True, add_special_tokens=False, return_tensors=\"pt\").numpy() for sente in sentences]\n",
    "#     lines_pad_x_test = []\n",
    "#     for seq in sequences:\n",
    "#         lines_pad_x_test.append(torch.tensor(seq[0]))\n",
    "#     lines_pad_x_test = pad_sequence(lines_pad_x_test, batch_first=True, padding_value=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eac4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxLen(X):\n",
    "\n",
    "    # Code for identifying max length of the data samples after tokenization using transformer tokenizer\n",
    "    \n",
    "    max_length = 0\n",
    "    # Iterate over each sample in your dataset\n",
    "    for i, input_ids in enumerate(X['input_ids']):\n",
    "        # Calculate the length of the tokenized sequence for the current sample\n",
    "        length = tf.math.reduce_sum(tf.cast(input_ids != 1, tf.int32)).numpy()\n",
    "        # Update max_length and max_row if the current length is greater\n",
    "        if length > max_length:\n",
    "            max_length = length\n",
    "            max_row = i\n",
    "\n",
    "    print(\"Max length of tokenized data:\", max_length)\n",
    "    print(\"Row with max length:\", max_row)\n",
    "\n",
    "    #X['input_ids'] = np.delete(X['input_ids'], max_row, axis=0)\n",
    "    \n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a38906f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50265\n",
      "768\n",
      "510\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m lines_pad_x_train \u001b[38;5;241m=\u001b[39m [arr\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m lines_pad_x_train]\n\u001b[0;32m     54\u001b[0m lines_pad_x_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(lines_pad_x_train)\n\u001b[1;32m---> 56\u001b[0m val_sentences \u001b[38;5;241m=\u001b[39m \u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     57\u001b[0m val_sequences \u001b[38;5;241m=\u001b[39m [tokenizer(sente, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m510\u001b[39m, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m sente \u001b[38;5;129;01min\u001b[39;00m val_sentences]\n\u001b[0;32m     59\u001b[0m lines_pad_x_val \u001b[38;5;241m=\u001b[39m padSequences(val_sequences, max_len)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "# TENSORFLOW\n",
    "if embedding_algorithm == \"bert\":\n",
    "    model_variation = \"microsoft/codebert-base-mlm\"\n",
    "#     model_variation = \"microsoft/codebert-base\"\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_variation, do_lower_case=True) #Tokenizer\n",
    "    tokenizer = RobertaTokenizer(vocab_file=\"../tokenizer_training/cpp_tokenizer/cpp_tokenizer-vocab.json\",\n",
    "                             merges_file=\"../tokenizer_training/cpp_tokenizer/cpp_tokenizer-merges.txt\")\n",
    "    #bert-base-uncased #bert-base #albert-base-v2 # roberta-base # distilbert-base-uncased #distilbert-base \n",
    "    # Define New tokens for string and numerical i.e., strId$ and numId$\n",
    "#     new_tokens = [\"strId$\", \"numId$\"]\n",
    "#     for new_token in new_tokens:\n",
    "#         if new_token not in tokenizer.get_vocab().keys():\n",
    "#             tokenizer.add_tokens(new_token)\n",
    "            \n",
    "    bert = TFAutoModel.from_pretrained(model_variation)\n",
    "\n",
    "    #bert.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    bert_embeddings = bert.get_input_embeddings()\n",
    "    embedding_matrix = bert_embeddings.weights[0].numpy()\n",
    "    \n",
    "    num_words = embedding_matrix.shape[0]\n",
    "    print(num_words)\n",
    "    dim = embedding_matrix.shape[1]\n",
    "    print(dim)\n",
    "    \n",
    "    sentences = X_train.tolist()\n",
    "    sequences = [tokenizer(sente, truncation=True, max_length=510, add_special_tokens=False, return_tensors=\"tf\") for sente in sentences] # Tokenize the complete sentences\n",
    "\n",
    "    def padSequences(sequences, max_len):\n",
    "        lines_pad = []\n",
    "        for sequence in sequences:\n",
    "            seq = sequence['input_ids'].numpy()[0]\n",
    "            if len(seq) < max_len:\n",
    "                for i in range(len(seq), max_len):\n",
    "                    seq = np.append(seq, 0)\n",
    "            lines_pad.append(seq)\n",
    "        return lines_pad\n",
    "    \n",
    "    def get_max_len(sequences):\n",
    "        max_len = 0\n",
    "\n",
    "        for seq in sequences:\n",
    "            if len(seq['input_ids'].numpy()[0]) > max_len:\n",
    "                max_len = len(seq['input_ids'].numpy()[0])\n",
    "\n",
    "        return max_len\n",
    "    \n",
    "    max_len = get_max_len(sequences)\n",
    "    print(max_len)\n",
    "    \n",
    "    lines_pad_x_train = padSequences(sequences, max_len)\n",
    "    lines_pad_x_train = [arr.tolist() for arr in lines_pad_x_train]\n",
    "    lines_pad_x_train = np.array(lines_pad_x_train)\n",
    "        \n",
    "    val_sentences = val_data[\"text\"].tolist()\n",
    "    val_sequences = [tokenizer(sente, truncation=True, max_length=510, add_special_tokens=False, return_tensors=\"tf\") for sente in val_sentences]\n",
    "    \n",
    "    lines_pad_x_val = padSequences(val_sequences, max_len)\n",
    "    lines_pad_x_val = [arr.tolist() for arr in lines_pad_x_val]\n",
    "    lines_pad_x_val = np.array(lines_pad_x_val)\n",
    "    \n",
    "    test_sentences = test_data[\"text\"].tolist()\n",
    "    test_sequences = [tokenizer(sente, truncation=True, max_length=510, add_special_tokens=False, return_tensors=\"tf\") for sente in test_sentences]\n",
    "    \n",
    "    lines_pad_x_test = padSequences(test_sequences, max_len)\n",
    "    lines_pad_x_test = [arr.tolist() for arr in lines_pad_x_test]\n",
    "    lines_pad_x_test = np.array(lines_pad_x_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9cb2e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # PYTORCH\n",
    "# if embedding_algorithm == \"gpt\":\n",
    "#     model_variation = \"gpt2\" # \"microsoft/CodeGPT-small-py-adaptedGPT2\" # \"gpt2\" # \"microsoft/CodeGPT-small-py\" \n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_variation, do_lower_case=True) #Tokenizer\n",
    "#     # Define New tokens for string and numerical i.e., strId$ and numId$\n",
    "#     new_tokens = [\"strId$\", \"numId$\"]\n",
    "#     for new_token in new_tokens:\n",
    "#         if new_token not in tokenizer.get_vocab().keys():\n",
    "#             tokenizer.add_tokens(new_token)\n",
    "            \n",
    "#     gpt = AutoModel.from_pretrained(model_variation, num_labels=n_categories)\n",
    "\n",
    "#     gpt.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "#     embedding_matrix = gpt.wte.weight.detach().cpu().numpy()\n",
    "    \n",
    "#     num_words = len(embedding_matrix)\n",
    "#     print(num_words)\n",
    "#     dim = len(embedding_matrix[0])\n",
    "#     print(dim)\n",
    "    \n",
    "#     sentences = X_train.tolist()\n",
    "#     sequences = [tokenizer.encode(sente, truncation=True, add_special_tokens=False, return_tensors=\"pt\").numpy() for sente in sentences] # Tokenize the complete sentences\n",
    "\n",
    "#     lines_pad_x_train = []\n",
    "#     for seq in sequences:\n",
    "#         lines_pad_x_train.append(torch.tensor(seq[0]))\n",
    "    \n",
    "#     lines_pad_x_train = pad_sequence(lines_pad_x_train, batch_first=True, padding_value=0)\n",
    "#     max_len = lines_pad_x_train.size()[1]\n",
    "    \n",
    "    \n",
    "#     sentences = val_data[\"Input\"]\n",
    "#     sequences = [tokenizer.encode(sente, truncation=True, add_special_tokens=False, return_tensors=\"pt\").numpy() for sente in sentences]\n",
    "#     lines_pad_x_val = []\n",
    "#     for seq in sequences:\n",
    "#         lines_pad_x_val.append(torch.tensor(seq[0]))\n",
    "#     lines_pad_x_val = pad_sequence(lines_pad_x_val, batch_first=True, padding_value=0)\n",
    "    \n",
    "#     sentences = test_data[\"Input\"]\n",
    "#     sequences = [tokenizer.encode(sente, truncation=True, add_special_tokens=False, return_tensors=\"pt\").numpy() for sente in sentences]\n",
    "#     lines_pad_x_test = []\n",
    "#     for seq in sequences:\n",
    "#         lines_pad_x_test.append(torch.tensor(seq[0]))\n",
    "#     lines_pad_x_test = pad_sequence(lines_pad_x_test, batch_first=True, padding_value=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e03248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENSORFLOW\n",
    "if embedding_algorithm == \"gpt\":\n",
    "    model_variation = \"gpt2\" # \"microsoft/CodeGPT-small-py-adaptedGPT2\" # \"gpt2\" # \"microsoft/CodeGPT-small-py\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_variation, do_lower_case=True) #Tokenizer\n",
    "    #bert-base-uncased #bert-base #albert-base-v2 # roberta-base # distilbert-base-uncased #distilbert-base \n",
    "    # Define New tokens for string and numerical i.e., strId$ and numId$\n",
    "#     new_tokens = [\"strId$\", \"numId$\"]\n",
    "#     for new_token in new_tokens:\n",
    "#         if new_token not in tokenizer.get_vocab().keys():\n",
    "#             tokenizer.add_tokens(new_token)\n",
    "            \n",
    "    gpt = TFGPT2LMHeadModel.from_pretrained(model_variation, num_labels=n_categories)\n",
    "\n",
    "    #gpt.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    embedding_matrix = gpt.transformer.wte.weight\n",
    "    \n",
    "    num_words = embedding_matrix.shape[0]\n",
    "    print(num_words)\n",
    "    dim = embedding_matrix.shape[1]\n",
    "    print(dim)\n",
    "    \n",
    "#     X = tokenizer(\n",
    "#         text=X_train.tolist(),\n",
    "#         add_special_tokens=False,\n",
    "#         max_length=512,\n",
    "#         truncation=True,\n",
    "#         padding=True,\n",
    "#         return_tensors='tf',\n",
    "#         return_token_type_ids=False,\n",
    "#         return_attention_mask=True,\n",
    "#         verbose=True\n",
    "#     )\n",
    "\n",
    "#     max_len = getMaxLen(X)\n",
    "    max_len = 512\n",
    "    \n",
    "    sentences = X_train.tolist()\n",
    "    sequences = [tokenizer.encode(sente, truncation=True, add_special_tokens=False, return_tensors=\"tf\").numpy() for sente in sentences] # Tokenize the complete sentences\n",
    "\n",
    "    lines_pad_x_train = []\n",
    "    for seq in sequences:\n",
    "        lines_pad_x_train.append(seq[0])\n",
    "    \n",
    "    lines_pad_x_train = pad_sequences(lines_pad_x_train, padding = 'post', maxlen = max_len)    \n",
    "    \n",
    "    sentences = val_data[\"text\"].tolist()\n",
    "    sequences = [tokenizer.encode(sente, truncation=True, add_special_tokens=False, return_tensors=\"tf\").numpy() for sente in sentences]\n",
    "    lines_pad_x_val = []\n",
    "    for seq in sequences:\n",
    "        lines_pad_x_val.append(seq[0])\n",
    "    lines_pad_x_val = pad_sequences(lines_pad_x_val, padding = 'post', maxlen = max_len)\n",
    "    \n",
    "    sentences = test_data[\"text\"].tolist()\n",
    "    sequences = [tokenizer.encode(sente, truncation=True, add_special_tokens=False, return_tensors=\"tf\").numpy() for sente in sentences]\n",
    "    lines_pad_x_test = []\n",
    "    for seq in sequences:\n",
    "        lines_pad_x_test.append(seq[0])\n",
    "    lines_pad_x_test = pad_sequences(lines_pad_x_test, padding = 'post', maxlen = max_len)\n",
    "\n",
    "    embedding_matrix = embedding_matrix.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48e3f62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150908, 18864, 18864)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "Y_val = np.array(val_data[\"label\"])\n",
    "Y_test = np.array(test_data[\"label\"])\n",
    "len(Y_train), len(Y_val), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac833046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions\n",
    "def recall_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f1 = 2*((prec*rec)/(prec+rec+K.epsilon()))\n",
    "    return f1\n",
    "\n",
    "def f2_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f2 = 5*((prec*rec)/(4*prec+rec+K.epsilon()))\n",
    "    return f2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ae338",
   "metadata": {},
   "source": [
    "Select Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb7c6c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "patience = 10\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "optimizer = optimizers.Adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d61734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning Models - Classifiers\n",
    "def buildLstm(max_len, top_words, dim, seed, embedding_matrix, optimizer, n_categories):\n",
    "    model=Sequential()\n",
    "    kernel_initializer = glorot_uniform() # glorot_uniform, RandomUniform, lecun_uniform, Constant, TruncatedNormal\n",
    "    model.add(Embedding(input_dim=top_words, output_dim=dim, input_length=None, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "    model.add(LSTM(500, activation='tanh', dropout=0.2, return_sequences=True, stateful=False, kernel_constraint=max_norm(3), bias_constraint=max_norm(3), kernel_initializer=kernel_initializer)) # , recurrent_constraint=max_norm(3)\n",
    "    model.add(LSTM(100, activation='tanh', dropout=0.1, return_sequences=True, stateful=False, kernel_initializer=kernel_initializer))\n",
    "    model.add(LSTM(200, activation='tanh', dropout=0.1, stateful=False, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization()) # default momentum=0.99\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    #optimizer = optimizers.SGD(lr=learning_rate, decay=0.1, momentum=0.2, nesterov=True)\n",
    "    #optimizer = optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "    #optimizer = optimizers.Adagrad(lr=learning_rate, epsilon=None, decay=0.004)\n",
    "    #optimizer = optimizers.Nadam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    \n",
    "    if n_categories > 2:\n",
    "        model.add(Dense(units = n_categories, activation = 'softmax', kernel_initializer=kernel_initializer))\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
    "    else:\n",
    "        model.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer=kernel_initializer))\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[f1_metric])\n",
    "    return model\n",
    "\n",
    "def buildGru(max_len, top_words, dim, seed, embedding_matrix, optimizer, n_categories):\n",
    "    model=Sequential()\n",
    "    kernel_initializer = glorot_uniform() # glorot_uniform, RandomUniform, lecun_uniform, Constant, TruncatedNormal\n",
    "    model.add(Embedding(input_dim=top_words, output_dim=dim, input_length=None, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "    model.add(GRU(500, activation='tanh', dropout=0.2, return_sequences=True, stateful=False, kernel_constraint=max_norm(3), bias_constraint=max_norm(3), kernel_initializer=kernel_initializer)) # , recurrent_constraint=max_norm(3)\n",
    "    model.add(GRU(100, activation='tanh', dropout=0.1, return_sequences=True, stateful=False, kernel_initializer=kernel_initializer))\n",
    "    model.add(GRU(200, activation='tanh', dropout=0.1, stateful=False, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization()) # default momentum=0.99\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    #optimizer = optimizers.SGD(lr=learning_rate, decay=0.1, momentum=0.2, nesterov=True)\n",
    "    #optimizer = optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "    #optimizer = optimizers.Adagrad(lr=learning_rate, epsilon=None, decay=0.004)\n",
    "    #optimizer = optimizers.Nadam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    \n",
    "    if n_categories > 2:\n",
    "        model.add(Dense(units = n_categories, activation = 'softmax', kernel_initializer=kernel_initializer))\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
    "    else:\n",
    "        model.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer=kernel_initializer))\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[f1_metric]) \n",
    "    return model\n",
    "\n",
    "def buildBiLstm(max_len, top_words, dim, seed, embedding_matrix, optimizer, n_categories):\n",
    "    model=Sequential()\n",
    "    kernel_initializer = glorot_uniform() # glorot_uniform, RandomUniform, lecun_uniform, Constant, TruncatedNormal\n",
    "    model.add(Embedding(input_dim=top_words, output_dim=dim, input_length=None, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "    model.add(Bidirectional(LSTM(500, activation='tanh', dropout=0.2, return_sequences=True, stateful=False, kernel_constraint=max_norm(3), bias_constraint=max_norm(3), kernel_initializer=kernel_initializer))) # , recurrent_constraint=max_norm(3)\n",
    "    model.add(Bidirectional(LSTM(100, activation='tanh', dropout=0.1, return_sequences=True, stateful=False, kernel_initializer=kernel_initializer)))\n",
    "    model.add(Bidirectional(LSTM(200, activation='tanh', dropout=0.1, stateful=False, kernel_initializer=kernel_initializer)))\n",
    "    model.add(BatchNormalization()) # default momentum=0.99\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    #optimizer = optimizers.SGD(lr=learning_rate, decay=0.1, momentum=0.2, nesterov=True)\n",
    "    #optimizer = optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "    #optimizer = optimizers.Adagrad(lr=learning_rate, epsilon=None, decay=0.004)\n",
    "    #optimizer = optimizers.Nadam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    \n",
    "    if n_categories > 2:\n",
    "        model.add(Dense(units = n_categories, activation = 'softmax', kernel_initializer=kernel_initializer))\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
    "    else:\n",
    "        model.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer=kernel_initializer))\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[f1_metric]) \n",
    "    return model\n",
    "\n",
    "def buildBiGru(max_len, top_words, dim, seed, embedding_matrix, optimizer, n_categories):\n",
    "    model=Sequential()\n",
    "    kernel_initializer = glorot_uniform() # glorot_uniform, RandomUniform, lecun_uniform, Constant, TruncatedNormal\n",
    "    model.add(Embedding(input_dim=top_words, output_dim=dim, input_length=None, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "    model.add(Bidirectional(GRU(500, activation='tanh', dropout=0.2, return_sequences=True, stateful=False, kernel_constraint=max_norm(3), bias_constraint=max_norm(3), kernel_initializer=kernel_initializer))) # , recurrent_constraint=max_norm(3)\n",
    "    model.add(Bidirectional(GRU(100, activation='tanh', dropout=0.1, return_sequences=True, stateful=False, kernel_initializer=kernel_initializer)))\n",
    "    model.add(Bidirectional(GRU(200, activation='tanh', dropout=0.1, stateful=False, kernel_initializer=kernel_initializer)))\n",
    "    model.add(BatchNormalization()) # default momentum=0.99\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    #optimizer = optimizers.SGD(lr=learning_rate, decay=0.1, momentum=0.2, nesterov=True)\n",
    "    #optimizer = optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "    #optimizer = optimizers.Adagrad(lr=learning_rate, epsilon=None, decay=0.004)\n",
    "    #optimizer = optimizers.Nadam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    \n",
    "    if n_categories > 2:\n",
    "        model.add(Dense(units = n_categories, activation = 'softmax', kernel_initializer=kernel_initializer))\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
    "    else:\n",
    "        model.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer=kernel_initializer))\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[f1_metric])  \n",
    "    return model\n",
    "\n",
    "def buildCnn(max_len, top_words, dim, seed, embedding_matrix, optimizer, n_categories):\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Embedding(top_words, dim, input_length=None, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "    cnn_model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu'))\n",
    "    '''cnn_model.add(MaxPooling1D(pool_size = 5))\n",
    "    cnn_model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size = 5))\n",
    "    cnn_model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu'))'''\n",
    "    cnn_model.add(GlobalMaxPool1D())\n",
    "    #cnn_model.add(Dense(units = 128, activation = 'relu'))\n",
    "    \n",
    "    if n_categories > 2:\n",
    "        cnn_model.add(Dense(units = n_categories, activation = 'softmax'))\n",
    "        cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
    "    else:\n",
    "        cnn_model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "        cnn_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[f1_metric])\n",
    "    return cnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d7f1620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iliaskaloup\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 768)         38603520  \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 500)         1905000   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, None, 100)         180600    \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 200)               181200    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 200)              800       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,871,321\n",
      "Trainable params: 2,267,401\n",
      "Non-trainable params: 38,603,920\n",
      "_________________________________________________________________\n",
      "model summary\\m None\n",
      "Epoch 1/100\n",
      "2358/2358 [==============================] - ETA: 0s - loss: 0.0962 - f1_metric: 0.7361\n",
      "Epoch 1: val_f1_metric improved from -inf to 0.85289, saving model to best_model.h5\n",
      "2358/2358 [==============================] - 451s 185ms/step - loss: 0.0962 - f1_metric: 0.7361 - val_loss: 0.0498 - val_f1_metric: 0.8529\n",
      "Epoch 2/100\n",
      "2358/2358 [==============================] - ETA: 0s - loss: 0.0472 - f1_metric: 0.8648\n",
      "Epoch 2: val_f1_metric improved from 0.85289 to 0.86827, saving model to best_model.h5\n",
      "2358/2358 [==============================] - 432s 183ms/step - loss: 0.0472 - f1_metric: 0.8648 - val_loss: 0.0449 - val_f1_metric: 0.8683\n",
      "Epoch 3/100\n",
      "2358/2358 [==============================] - ETA: 0s - loss: 0.0383 - f1_metric: 0.8956\n",
      "Epoch 3: val_f1_metric improved from 0.86827 to 0.87436, saving model to best_model.h5\n",
      "2358/2358 [==============================] - 430s 182ms/step - loss: 0.0383 - f1_metric: 0.8956 - val_loss: 0.0463 - val_f1_metric: 0.8744\n",
      "Epoch 4/100\n",
      "2358/2358 [==============================] - ETA: 0s - loss: 0.0306 - f1_metric: 0.9145\n",
      "Epoch 4: val_f1_metric improved from 0.87436 to 0.88086, saving model to best_model.h5\n",
      "2358/2358 [==============================] - 430s 183ms/step - loss: 0.0306 - f1_metric: 0.9145 - val_loss: 0.0460 - val_f1_metric: 0.8809\n",
      "Epoch 5/100\n",
      "2358/2358 [==============================] - ETA: 0s - loss: 0.0256 - f1_metric: 0.9254\n",
      "Epoch 5: val_f1_metric improved from 0.88086 to 0.89306, saving model to best_model.h5\n",
      "2358/2358 [==============================] - 433s 183ms/step - loss: 0.0256 - f1_metric: 0.9254 - val_loss: 0.0448 - val_f1_metric: 0.8931\n",
      "Epoch 6/100\n",
      " 597/2358 [======>.......................] - ETA: 5:28 - loss: 0.0206 - f1_metric: 0.9393"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1_metric\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, patience\u001b[38;5;241m=\u001b[39mpatience)\n\u001b[0;32m     21\u001b[0m mc \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1_metric\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmyModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlines_pad_x_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlines_pad_x_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, class_weight=class_weights\u001b[39;00m\n\u001b[0;32m     25\u001b[0m milli_sec2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining is completed after\u001b[39m\u001b[38;5;124m\"\u001b[39m, milli_sec2\u001b[38;5;241m-\u001b[39mmilli_sec1)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "milli_sec1 = int(round(time.time() * 1000))\n",
    "\n",
    "userModel = \"gru\"\n",
    "\n",
    "if userModel == \"cnn\":\n",
    "    myModel = buildCnn(max_len, num_words, dim, seed, embedding_matrix, optimizer, n_categories) \n",
    "elif userModel == \"lstm\":\n",
    "    myModel = buildLstm(max_len, num_words, dim, seed, embedding_matrix, optimizer, n_categories)\n",
    "elif userModel == \"bilstm\":\n",
    "    myModel = buildBiLstm(max_len, num_words, dim, seed, embedding_matrix, optimizer, n_categories)\n",
    "elif userModel == \"gru\":\n",
    "    myModel = buildGru(max_len, num_words, dim, seed, embedding_matrix, optimizer, n_categories)\n",
    "elif userModel == \"bigru\":\n",
    "    myModel = buildBiGru(max_len, num_words, dim, seed, embedding_matrix, optimizer, n_categories)\n",
    "    \n",
    "print(\"model summary\\m\", myModel.summary())\n",
    "\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=',')\n",
    "es = EarlyStopping(monitor='val_f1_metric', mode='max', verbose=1, patience=patience)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_f1_metric', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "history = myModel.fit(lines_pad_x_train, Y_train, validation_data=(lines_pad_x_val, Y_val), epochs = n_epochs, batch_size = batch_size, shuffle=False, verbose=1, callbacks=[csv_logger,es,mc]) #, class_weight=class_weights\n",
    "\n",
    "milli_sec2 = int(round(time.time() * 1000))\n",
    "print(\"Training is completed after\", milli_sec2-milli_sec1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd68d04-85ff-4b71-9f71-0e97d866cb34",
   "metadata": {},
   "source": [
    "Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d60b11d-068e-4695-9fca-16f0d33e321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('best_model.h5')\n",
    "myModel.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2ac4f-5f62-413a-b54f-97c0b2312941",
   "metadata": {},
   "source": [
    "Classification report on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdd0205c-3010-4c74-93cb-7bfcf31153e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590/590 [==============================] - 41s 64ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     17755\n",
      "           1       0.97      0.86      0.91      1109\n",
      "\n",
      "    accuracy                           0.99     18864\n",
      "   macro avg       0.98      0.93      0.95     18864\n",
      "weighted avg       0.99      0.99      0.99     18864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_val, (myModel.predict(lines_pad_x_val) > 0.5).astype(\"int32\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631cd13d-ce0a-4135-91d1-333a82099219",
   "metadata": {},
   "source": [
    "Prediction and Evaluation on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebc1635a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590/590 [==============================] - 38s 64ms/step\n",
      "TP= 924\n",
      "TN= 17778\n",
      "FP= 31\n",
      "FN= 131\n",
      "Accuracy:99.14%\n",
      "Precision:96.75%\n",
      "Recall:87.58%\n",
      "F1 score:91.94%\n",
      "Roc_Auc score:93.70%\n",
      "F2 score:89.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     17809\n",
      "           1       0.97      0.88      0.92      1055\n",
      "\n",
      "    accuracy                           0.99     18864\n",
      "   macro avg       0.98      0.94      0.96     18864\n",
      "weighted avg       0.99      0.99      0.99     18864\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#scores = myModel.evaluate(lines_pad_x_test, Y_test, verbose=0)\n",
    "#predictions = myModel.predict_classes(X_test, verbose=0)\n",
    "predScores = myModel.predict(lines_pad_x_test)\n",
    "predictions = (predScores > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy=accuracy_score(Y_test, predictions)\n",
    "if n_categories > 2:\n",
    "    precision=precision_score(Y_test, predictions, average='macro')\n",
    "    recall=recall_score(Y_test, predictions, average='macro')\n",
    "    f1=f1_score(Y_test, predictions, average='macro')\n",
    "else:\n",
    "    precision=precision_score(Y_test, predictions)\n",
    "    recall=recall_score(Y_test, predictions)\n",
    "    f1=f1_score(Y_test, predictions)\n",
    "    roc_auc=roc_auc_score(Y_test, predictions)\n",
    "f2=5*precision*recall / (4*precision+recall)\n",
    "\n",
    "cm = confusion_matrix(Y_test, predictions)\n",
    "#print(cm)\n",
    "sn.heatmap(cm, annot=True)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"TP=\",tp)\n",
    "print(\"TN=\",tn)\n",
    "print(\"FP=\",fp)\n",
    "print(\"FN=\",fn)\n",
    "\n",
    "acc = ((tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "print(\"Accuracy:%.2f%%\"%(acc*100))\n",
    "print(\"Precision:%.2f%%\"%(precision*100))\n",
    "print(\"Recall:%.2f%%\"%(recall*100))\n",
    "print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "print(\"Roc_Auc score:%.2f%%\"%(roc_auc*100))\n",
    "print(\"F2 score:%.2f%%\"%(f2*100))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb23c2",
   "metadata": {},
   "source": [
    "Export classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d395ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the path\n",
    "path = os.path.join(root_path, 'results', model_variation.split(\"/\")[-1], method, str(seed))\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = os.path.join(path, f\"{seed}.csv\")\n",
    "\n",
    "# Write data to CSV\n",
    "data = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": f1,\n",
    "    \"f2\": f2,\n",
    "    \"roc_auc\": roc_auc\n",
    "}\n",
    "\n",
    "# Write to CSV\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=data.keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerow(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1707ba6",
   "metadata": {},
   "source": [
    "Compute the average values of the classication metrics considering the results for all different seeders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1912105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to store cumulative sum of metrics\n",
    "cumulative_metrics = defaultdict(float)\n",
    "count = 0  # Counter to keep track of number of CSV files\n",
    "\n",
    "# Iterate over all CSV files in the results folder\n",
    "results_folder = os.path.join(root_path, \"results\", model_variation.split(\"/\")[-1], method, str(seed))\n",
    "for filename in os.listdir(results_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        csv_file_path = os.path.join(results_folder, filename)\n",
    "        with open(csv_file_path, \"r\", newline=\"\") as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                for metric, value in row.items():\n",
    "                    cumulative_metrics[metric] += float(value)\n",
    "        count += 1\n",
    "        \n",
    "# Compute average values\n",
    "average_metrics = {metric: total / count for metric, total in cumulative_metrics.items()}\n",
    "\n",
    "# Print average values \n",
    "print(average_metrics)\n",
    "\n",
    "# Define the path for the average CSV file\n",
    "avg_csv_file_path = os.path.join(root_path, \"results\", model_variation.split(\"/\")[-1], method, \"avg.csv\")\n",
    "\n",
    "# Write average metrics to CSV\n",
    "with open(avg_csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=average_metrics.keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerow(average_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc08f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
